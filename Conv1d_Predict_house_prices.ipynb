{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "sBtnKdYEFcVh"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subbu27iitb/Deep-Learning/blob/DL_Regression/Conv1d_Predict_house_prices.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIdT9iu_Z4Rb"
      },
      "source": [
        "# 1 Dimensional Convolution (Conv1D) for Regression: Predict house prices \n",
        "\n",
        "[In a previous tutorial](https://youtu.be/WZdxt9xatrY), we focus on  **1 Dimensional Convolution (Conv1D)** and discuss how it works in a simple example. ***As I received several questions*** about how to apply 1 Dimensional Convolution onto a regression problem, I develop this notebook. If you need to **refresh your information** about 1 Dimensional Convolution, please **watch** the previous tutorial [on my Youtube channel](https://youtu.be/WZdxt9xatrY)\n",
        "\n",
        "Thus, today, we will use **Keras Conv1d** layer for a regression problem. \n",
        "As you might know, **Boston House Prices** data set is a well known data set. Below, we will **first** train a **Multi-Layer Perceptron (MLP) model** to predict house prices. Then, we will develop a model using **Keras Conv1D** layer. To train and test the Conv1D model, we will **reshape the train and test data** such that Conv1D can work on them.\n",
        "\n",
        "If you are interested in **Deep Neural Networks** and want to **learn them by coding**, please **subcribe** to [my YouTube Channel](https://www.youtube.com/channel/UCrCxCxTFL2ytaDrDYrN4_eA/playlists) or **follow** [my blog on Medium](https://medium.com/@kmkarakaya). Do not forget to turn on **Notifications** so that you will be notified when ***new content is uploaded***.\n",
        "\n",
        "You can access this **Colab Notebook** using [the link](https://colab.research.google.com/drive/1zjh0tUPYJYgJJunpLC9fW5uf--O0LKeZ?usp=sharing) given in the video descriptions below.\n",
        "\n",
        "If you are ready, let's get started!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1_ClZgzs6Qc"
      },
      "source": [
        "##You can watch this notebook:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "Epsf8ORc3WQs",
        "outputId": "2f8535a7-2289-4697-f7d3-96e130820a06"
      },
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('JzoIHdkFcQU', width=800, height=450) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"450\"\n",
              "            src=\"https://www.youtube.com/embed/JzoIHdkFcQU\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.YouTubeVideo at 0x7f26b9d304e0>"
            ],
            "image/jpeg": "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\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy4cJ5Asqv0b"
      },
      "source": [
        "https://youtu.be/JzoIHdkFcQU\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBtnKdYEFcVh"
      },
      "source": [
        "# Include Libraries and Auxiliary Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rRo8oNqZ-Rj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "373a38c1-ccd3-422c-9a73-3fc6bfe8caaa"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Model\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA26DoVLwSKU"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_history(history):\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error [1000$]')\n",
        "  plt.plot(history.epoch, np.array(history.history['mae']), \n",
        "           label='Train')\n",
        "  plt.plot(history.epoch, np.array(history.history['val_mae']),\n",
        "           label = 'Val')\n",
        "  plt.legend()\n",
        "  plt.ylim([0,max(history.history['val_mae'])])\n",
        "\n",
        "def plot_prediction(test_labels, test_predictions):\n",
        "  plt.figure()\n",
        "  plt.scatter(test_labels, test_predictions)\n",
        "  plt.xlabel('True Values [1000$]')\n",
        "  plt.ylabel('Predictions [1000$]')\n",
        "  plt.axis('equal')\n",
        "  plt.xlim(plt.xlim())\n",
        "  plt.ylim(plt.ylim())\n",
        "  _ = plt.plot([-100, 100],[-100,100])\n",
        "\n",
        "  plt.figure()\n",
        "  error = test_predictions - test_labels\n",
        "  plt.hist(error, bins = 50)\n",
        "  plt.xlabel(\"Prediction Error [1000$]\")\n",
        "  _ = plt.ylabel(\"Count\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdecPqz1F6wx"
      },
      "source": [
        "# Notice\n",
        "***As a base model***, I will use the **TensorFlow official example** for ***MLP model*** and compare its performance with **my Conv1D model**. Thus, we will be able to observe the relative success of **Conv1D model** with respect to **a professional sample model**.\n",
        "\n",
        "You can access the original notebook [\"Predict house prices: regression\" with Multi-layer Perceptron here.](https://colab.research.google.com/github/MarkDaoust/models/blob/add-regression-plots/samples/core/tutorials/keras/basic_regression.ipynb) \n",
        "\n",
        "If you run this notebook,  you would generate mean absolute error values different than the reported ones here due to stochastic nature of ANNs.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9xy7IeeFuKI"
      },
      "source": [
        "# What is regression? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHp3M9ZmrIxj"
      },
      "source": [
        "In a *regression* problem, we aim to predict the output of a continuous value, like a price or a probability. Contrast this with a *classification* problem, where we aim to predict a discrete label (for example, where a picture contains an apple or an orange). \n",
        "\n",
        "This notebook builds two different models to predict the median price of homes in a Boston suburb during the mid-1970s. To do this, I'll provide the models with some data points about the suburb, such as the crime rate and the local property tax rate.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_72b0LCNbjx"
      },
      "source": [
        "## The Boston Housing Prices dataset\n",
        "\n",
        "This [dataset](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html) is accessible directly in TensorFlow. Download and shuffle the training set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9kxxgzvzlyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd616fbe-e390-4a16-9c9e-0de5e8cbbeb6"
      },
      "source": [
        "boston_housing = tf.keras.datasets.boston_housing\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = boston_housing.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwEKwRJgsgJ6"
      },
      "source": [
        "### Examples and features \n",
        "\n",
        "This dataset has 506 total examples which are split between **404** training examples and **102** test examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ujqcgkipr65P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84332dd6-6adf-4388-893e-d20ca5103ea4"
      },
      "source": [
        "print(\"Training set: {}\".format(train_data.shape))  # 404 examples, 13 features\n",
        "print(\"Testing set:  {}\".format(test_data.shape))   # 102 examples, 13 features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set: (404, 13)\n",
            "Testing set:  (102, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LRPXE3Oz3Nq"
      },
      "source": [
        "The dataset contains 13 different features:\n",
        "\n",
        "1.   Per capita crime rate.\n",
        "2.   The proportion of residential land zoned for lots over 25,000 square feet.\n",
        "3.   The proportion of non-retail business acres per town.\n",
        "4.   Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
        "5.   Nitric oxides concentration (parts per 10 million).\n",
        "6.   The average number of rooms per dwelling.\n",
        "7.   The proportion of owner-occupied units built before 1940.\n",
        "8.   Weighted distances to five Boston employment centers.\n",
        "9.   Index of accessibility to radial highways.\n",
        "10.  Full-value property-tax rate per $10,000.\n",
        "11.  Pupil-teacher ratio by town.\n",
        "12.  1000 * (Bk - 0.63) ** 2 where Bk is the proportion of Black people by town.\n",
        "13.  Percentage lower status of the population.\n",
        "\n",
        "Each one of these input data features is stored using a different scale. Some features are represented by a proportion between 0 and 1, other features are ranges between 1 and 12, some are ranges between 0 and 100, and so on. This is often the case with real-world data, and understanding how to explore and clean such data is an important skill to develop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tYsm8Gs03J4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eb9c37e-297d-4c6c-8f76-b0c1af3ac3ea"
      },
      "source": [
        "print(train_data[0])  # Display sample features, notice the different scales"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  1.23247   0.        8.14      0.        0.538     6.142    91.7\n",
            "   3.9769    4.      307.       21.      396.9      18.72   ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7muNf-d1-ne"
      },
      "source": [
        "Use the [pandas](https://pandas.pydata.org) library to display the first few rows of the dataset in a nicely formatted table:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYVyGhdyCpIM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "0ce993e5-7b70-43e3-fb78-15a72757e68a"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
        "                'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
        "\n",
        "df = pd.DataFrame(train_data, columns=column_names)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.23247</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.142</td>\n",
              "      <td>91.7</td>\n",
              "      <td>3.9769</td>\n",
              "      <td>4.0</td>\n",
              "      <td>307.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>18.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02177</td>\n",
              "      <td>82.5</td>\n",
              "      <td>2.03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.415</td>\n",
              "      <td>7.610</td>\n",
              "      <td>15.7</td>\n",
              "      <td>6.2700</td>\n",
              "      <td>2.0</td>\n",
              "      <td>348.0</td>\n",
              "      <td>14.7</td>\n",
              "      <td>395.38</td>\n",
              "      <td>3.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.89822</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.631</td>\n",
              "      <td>4.970</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1.3325</td>\n",
              "      <td>24.0</td>\n",
              "      <td>666.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>375.52</td>\n",
              "      <td>3.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03961</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.515</td>\n",
              "      <td>6.037</td>\n",
              "      <td>34.5</td>\n",
              "      <td>5.9853</td>\n",
              "      <td>5.0</td>\n",
              "      <td>224.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>396.90</td>\n",
              "      <td>8.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.69311</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.713</td>\n",
              "      <td>6.376</td>\n",
              "      <td>88.4</td>\n",
              "      <td>2.5671</td>\n",
              "      <td>24.0</td>\n",
              "      <td>666.0</td>\n",
              "      <td>20.2</td>\n",
              "      <td>391.43</td>\n",
              "      <td>14.65</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX  ...   RAD    TAX  PTRATIO       B  LSTAT\n",
              "0  1.23247   0.0   8.14   0.0  0.538  ...   4.0  307.0     21.0  396.90  18.72\n",
              "1  0.02177  82.5   2.03   0.0  0.415  ...   2.0  348.0     14.7  395.38   3.11\n",
              "2  4.89822   0.0  18.10   0.0  0.631  ...  24.0  666.0     20.2  375.52   3.26\n",
              "3  0.03961   0.0   5.19   0.0  0.515  ...   5.0  224.0     20.2  396.90   8.01\n",
              "4  3.69311   0.0  18.10   0.0  0.713  ...  24.0  666.0     20.2  391.43  14.65\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wb9S7Mia2lpf"
      },
      "source": [
        "### Labels\n",
        "\n",
        "The labels are the house prices in thousands of dollars. (You may notice the mid-1970s prices.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8NwI2ND2t4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2455033-f18f-4057-a676-ce1a4df75d90"
      },
      "source": [
        "print(train_labels[0:10])  # Display first 10 entries"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[15.2 42.3 50.  21.1 17.7 18.5 11.3 15.6 15.6 14.4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRklxK5s388r"
      },
      "source": [
        "## Normalize features\n",
        "\n",
        "It's recommended to normalize features that use different scales and ranges. For each feature, subtract the mean of the feature and divide by the standard deviation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze5WQP8R1TYg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eda6a49-5fb6-4a60-dc12-d8eaa1a2f833"
      },
      "source": [
        "# Test data is *not* used when calculating the mean and std.\n",
        "mean = train_data.mean(axis=0)\n",
        "std = train_data.std(axis=0)\n",
        "train_data = (train_data - mean) / std\n",
        "test_data = (test_data - mean) / std\n",
        "\n",
        "print(train_data[0])  # First training sample, normalized"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.27224633 -0.48361547 -0.43576161 -0.25683275 -0.1652266  -0.1764426\n",
            "  0.81306188  0.1166983  -0.62624905 -0.59517003  1.14850044  0.44807713\n",
            "  0.8252202 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuiClDk45eS4"
      },
      "source": [
        "Although the model *might* converge without feature normalization, it makes training more difficult, and it makes the resulting model more dependant on the choice of units used in the input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmjdzxKzEu1-"
      },
      "source": [
        "## Create the MLP model\n",
        "\n",
        "Let's build an MLP model. Here, we'll use a `Sequential` model with two densely connected hidden layers, and an output layer that returns a single, continuous value. The model building steps are wrapped in a function, `build_model`, since we'll create a second model, later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c26juK7ZG8j-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9edd109-0cd6-48fc-e3da-3355c380375d"
      },
      "source": [
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    keras.layers.Input(shape=(train_data.shape[1],)),                  \n",
        "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(1)\n",
        "  ], name=\"MLP_model\")\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"MLP_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                896       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-qWCsh6DlyH"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "The model is trained for 500 epochs, and record the training and validation accuracy in the `history` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD7qHCmNIOY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ddb3d30-6eb3-45bd-c99c-deffe58177ee"
      },
      "source": [
        "EPOCHS = 500\n",
        "# Store training stats\n",
        "history = model.fit(train_data, train_labels, epochs=EPOCHS,\n",
        "                    validation_split=0.2, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 521.7044 - mae: 20.8216 - val_loss: 546.8928 - val_mae: 21.4270\n",
            "Epoch 2/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 448.9357 - mae: 18.9392 - val_loss: 473.1917 - val_mae: 19.6619\n",
            "Epoch 3/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 376.8356 - mae: 16.9719 - val_loss: 389.3438 - val_mae: 17.5452\n",
            "Epoch 4/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 298.2760 - mae: 14.8077 - val_loss: 297.4583 - val_mae: 14.9618\n",
            "Epoch 5/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 220.3994 - mae: 12.3777 - val_loss: 222.0084 - val_mae: 12.5341\n",
            "Epoch 6/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 154.2872 - mae: 10.0912 - val_loss: 143.0147 - val_mae: 9.3707\n",
            "Epoch 7/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 99.7582 - mae: 7.6772 - val_loss: 105.8633 - val_mae: 7.6031\n",
            "Epoch 8/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 72.8655 - mae: 6.2615 - val_loss: 80.3566 - val_mae: 6.3112\n",
            "Epoch 9/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 56.0755 - mae: 5.3779 - val_loss: 60.0779 - val_mae: 5.3412\n",
            "Epoch 10/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 44.2093 - mae: 4.7273 - val_loss: 47.9171 - val_mae: 4.8014\n",
            "Epoch 11/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 36.8074 - mae: 4.2500 - val_loss: 39.0493 - val_mae: 4.3396\n",
            "Epoch 12/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 31.7818 - mae: 3.9082 - val_loss: 33.3452 - val_mae: 3.8575\n",
            "Epoch 13/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 27.9622 - mae: 3.6081 - val_loss: 29.6847 - val_mae: 3.6095\n",
            "Epoch 14/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 25.2835 - mae: 3.3418 - val_loss: 25.4708 - val_mae: 3.4857\n",
            "Epoch 15/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 23.0713 - mae: 3.2152 - val_loss: 23.2623 - val_mae: 3.4185\n",
            "Epoch 16/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 21.1504 - mae: 3.1024 - val_loss: 22.7429 - val_mae: 3.3376\n",
            "Epoch 17/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 20.0008 - mae: 2.9899 - val_loss: 23.5527 - val_mae: 3.6838\n",
            "Epoch 18/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 19.2525 - mae: 2.9446 - val_loss: 19.0134 - val_mae: 3.2130\n",
            "Epoch 19/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 17.8311 - mae: 2.8345 - val_loss: 18.0522 - val_mae: 3.0473\n",
            "Epoch 20/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 16.7210 - mae: 2.7170 - val_loss: 17.7757 - val_mae: 3.1447\n",
            "Epoch 21/500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 16.2533 - mae: 2.7335 - val_loss: 16.6394 - val_mae: 3.0018\n",
            "Epoch 22/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 15.2918 - mae: 2.6241 - val_loss: 16.2580 - val_mae: 3.0944\n",
            "Epoch 23/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 14.6662 - mae: 2.6142 - val_loss: 16.2437 - val_mae: 3.0332\n",
            "Epoch 24/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 14.3934 - mae: 2.5746 - val_loss: 15.0110 - val_mae: 2.9747\n",
            "Epoch 25/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 13.5009 - mae: 2.5023 - val_loss: 15.9101 - val_mae: 3.1240\n",
            "Epoch 26/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 13.3076 - mae: 2.5532 - val_loss: 14.5555 - val_mae: 2.8952\n",
            "Epoch 27/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 12.9144 - mae: 2.4522 - val_loss: 14.0455 - val_mae: 2.9361\n",
            "Epoch 28/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 12.4443 - mae: 2.4175 - val_loss: 13.6783 - val_mae: 2.8886\n",
            "Epoch 29/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 12.1536 - mae: 2.4140 - val_loss: 14.5068 - val_mae: 3.0497\n",
            "Epoch 30/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 12.1066 - mae: 2.3690 - val_loss: 14.8980 - val_mae: 3.0514\n",
            "Epoch 31/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 11.7397 - mae: 2.3830 - val_loss: 13.0918 - val_mae: 2.7341\n",
            "Epoch 32/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 11.3963 - mae: 2.3989 - val_loss: 15.3934 - val_mae: 3.0752\n",
            "Epoch 33/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 11.3400 - mae: 2.3791 - val_loss: 12.4596 - val_mae: 2.6939\n",
            "Epoch 34/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 11.0658 - mae: 2.3420 - val_loss: 13.2506 - val_mae: 2.8425\n",
            "Epoch 35/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 10.8529 - mae: 2.3020 - val_loss: 12.3596 - val_mae: 2.6901\n",
            "Epoch 36/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 10.7200 - mae: 2.2389 - val_loss: 12.2394 - val_mae: 2.7152\n",
            "Epoch 37/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 10.4296 - mae: 2.2575 - val_loss: 12.1885 - val_mae: 2.6159\n",
            "Epoch 38/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.4503 - mae: 2.2176 - val_loss: 12.6783 - val_mae: 2.6451\n",
            "Epoch 39/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.0129 - mae: 2.2267 - val_loss: 13.3994 - val_mae: 2.8592\n",
            "Epoch 40/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.0751 - mae: 2.2065 - val_loss: 12.5909 - val_mae: 2.7076\n",
            "Epoch 41/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 9.7434 - mae: 2.1741 - val_loss: 12.7661 - val_mae: 2.7452\n",
            "Epoch 42/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 9.6718 - mae: 2.2226 - val_loss: 12.9949 - val_mae: 2.8484\n",
            "Epoch 43/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 9.4386 - mae: 2.1497 - val_loss: 13.2190 - val_mae: 2.7710\n",
            "Epoch 44/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 9.6210 - mae: 2.1810 - val_loss: 13.2395 - val_mae: 2.6393\n",
            "Epoch 45/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 9.3892 - mae: 2.1561 - val_loss: 13.6363 - val_mae: 2.6489\n",
            "Epoch 46/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 9.4885 - mae: 2.2063 - val_loss: 13.4586 - val_mae: 2.6536\n",
            "Epoch 47/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.0378 - mae: 2.1432 - val_loss: 13.3536 - val_mae: 2.7200\n",
            "Epoch 48/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.1857 - mae: 2.1365 - val_loss: 14.0620 - val_mae: 2.6618\n",
            "Epoch 49/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 9.2065 - mae: 2.1527 - val_loss: 14.3189 - val_mae: 2.6933\n",
            "Epoch 50/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 9.0231 - mae: 2.1521 - val_loss: 14.6479 - val_mae: 2.9371\n",
            "Epoch 51/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 8.9311 - mae: 2.1020 - val_loss: 13.4026 - val_mae: 2.7733\n",
            "Epoch 52/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 8.7803 - mae: 2.0844 - val_loss: 12.7943 - val_mae: 2.6563\n",
            "Epoch 53/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.7362 - mae: 2.0524 - val_loss: 12.7405 - val_mae: 2.6350\n",
            "Epoch 54/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 8.4557 - mae: 2.0532 - val_loss: 13.8969 - val_mae: 2.8561\n",
            "Epoch 55/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 8.4688 - mae: 2.0616 - val_loss: 12.5766 - val_mae: 2.7387\n",
            "Epoch 56/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.6433 - mae: 2.0286 - val_loss: 13.0530 - val_mae: 2.6432\n",
            "Epoch 57/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.4106 - mae: 2.0193 - val_loss: 13.6977 - val_mae: 2.7722\n",
            "Epoch 58/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.3029 - mae: 1.9953 - val_loss: 13.4482 - val_mae: 2.7176\n",
            "Epoch 59/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.3274 - mae: 1.9930 - val_loss: 13.2347 - val_mae: 2.6626\n",
            "Epoch 60/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 7.9882 - mae: 1.9684 - val_loss: 13.6353 - val_mae: 2.8189\n",
            "Epoch 61/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 8.3268 - mae: 1.9893 - val_loss: 13.5975 - val_mae: 2.6873\n",
            "Epoch 62/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 8.2128 - mae: 2.0124 - val_loss: 12.6855 - val_mae: 2.6369\n",
            "Epoch 63/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 7.9451 - mae: 1.9510 - val_loss: 13.8310 - val_mae: 2.7497\n",
            "Epoch 64/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.0230 - mae: 1.9718 - val_loss: 13.6323 - val_mae: 2.7288\n",
            "Epoch 65/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 7.7528 - mae: 1.9611 - val_loss: 13.6694 - val_mae: 2.7055\n",
            "Epoch 66/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 7.7232 - mae: 1.9034 - val_loss: 14.9111 - val_mae: 2.8414\n",
            "Epoch 67/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 7.8552 - mae: 1.9596 - val_loss: 13.6283 - val_mae: 2.8034\n",
            "Epoch 68/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 7.8550 - mae: 1.9467 - val_loss: 13.4444 - val_mae: 2.7401\n",
            "Epoch 69/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 7.7343 - mae: 1.9189 - val_loss: 14.3002 - val_mae: 2.6229\n",
            "Epoch 70/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 7.7785 - mae: 1.9299 - val_loss: 14.7540 - val_mae: 2.6695\n",
            "Epoch 71/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 7.6711 - mae: 1.9682 - val_loss: 13.8458 - val_mae: 2.7030\n",
            "Epoch 72/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.4396 - mae: 1.9052 - val_loss: 15.4846 - val_mae: 2.9260\n",
            "Epoch 73/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.5334 - mae: 1.9275 - val_loss: 14.4089 - val_mae: 2.7389\n",
            "Epoch 74/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 7.4195 - mae: 1.8981 - val_loss: 14.0801 - val_mae: 2.6049\n",
            "Epoch 75/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 7.5041 - mae: 1.8814 - val_loss: 14.8716 - val_mae: 2.6873\n",
            "Epoch 76/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.2181 - mae: 1.8652 - val_loss: 14.4108 - val_mae: 2.7549\n",
            "Epoch 77/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 7.4355 - mae: 1.8970 - val_loss: 14.8567 - val_mae: 2.7832\n",
            "Epoch 78/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 7.1534 - mae: 1.8430 - val_loss: 15.4144 - val_mae: 2.8591\n",
            "Epoch 79/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 7.6912 - mae: 1.9354 - val_loss: 15.0298 - val_mae: 2.7323\n",
            "Epoch 80/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 7.4588 - mae: 1.8648 - val_loss: 14.2025 - val_mae: 2.8210\n",
            "Epoch 81/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.1196 - mae: 1.8244 - val_loss: 14.5993 - val_mae: 2.7057\n",
            "Epoch 82/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 7.0524 - mae: 1.8445 - val_loss: 15.6039 - val_mae: 3.0134\n",
            "Epoch 83/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.3421 - mae: 1.9083 - val_loss: 15.3067 - val_mae: 2.7749\n",
            "Epoch 84/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 7.0280 - mae: 1.8623 - val_loss: 14.0092 - val_mae: 2.6854\n",
            "Epoch 85/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 7.0501 - mae: 1.8257 - val_loss: 13.7421 - val_mae: 2.8268\n",
            "Epoch 86/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 6.9874 - mae: 1.7993 - val_loss: 15.1582 - val_mae: 2.8731\n",
            "Epoch 87/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 7.0039 - mae: 1.8529 - val_loss: 14.4156 - val_mae: 2.8731\n",
            "Epoch 88/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 7.0335 - mae: 1.8259 - val_loss: 15.8891 - val_mae: 2.9762\n",
            "Epoch 89/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 7.0852 - mae: 1.8219 - val_loss: 14.1137 - val_mae: 2.6561\n",
            "Epoch 90/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.8118 - mae: 1.7860 - val_loss: 16.6832 - val_mae: 3.0383\n",
            "Epoch 91/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 6.8151 - mae: 1.8160 - val_loss: 13.9015 - val_mae: 2.6867\n",
            "Epoch 92/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.7375 - mae: 1.7644 - val_loss: 15.2744 - val_mae: 2.7742\n",
            "Epoch 93/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.6469 - mae: 1.7851 - val_loss: 17.9156 - val_mae: 3.1249\n",
            "Epoch 94/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.9514 - mae: 1.8362 - val_loss: 15.1450 - val_mae: 2.9252\n",
            "Epoch 95/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 6.7255 - mae: 1.8226 - val_loss: 15.5563 - val_mae: 2.8409\n",
            "Epoch 96/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.7228 - mae: 1.7749 - val_loss: 16.2011 - val_mae: 2.6826\n",
            "Epoch 97/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.8796 - mae: 1.8528 - val_loss: 15.0511 - val_mae: 2.7493\n",
            "Epoch 98/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.4401 - mae: 1.7626 - val_loss: 14.9130 - val_mae: 2.8483\n",
            "Epoch 99/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 6.4726 - mae: 1.7558 - val_loss: 14.9666 - val_mae: 2.7639\n",
            "Epoch 100/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 6.3223 - mae: 1.7205 - val_loss: 16.7557 - val_mae: 2.8970\n",
            "Epoch 101/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 6.7755 - mae: 1.7947 - val_loss: 15.6259 - val_mae: 2.7627\n",
            "Epoch 102/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 6.4049 - mae: 1.7582 - val_loss: 15.9463 - val_mae: 2.8484\n",
            "Epoch 103/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.5337 - mae: 1.8032 - val_loss: 15.0846 - val_mae: 2.7336\n",
            "Epoch 104/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.3785 - mae: 1.7342 - val_loss: 15.8968 - val_mae: 2.8947\n",
            "Epoch 105/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.3853 - mae: 1.7590 - val_loss: 14.1986 - val_mae: 2.7289\n",
            "Epoch 106/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 6.2912 - mae: 1.7408 - val_loss: 14.9183 - val_mae: 2.7222\n",
            "Epoch 107/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 6.3388 - mae: 1.7345 - val_loss: 15.3590 - val_mae: 2.7970\n",
            "Epoch 108/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 6.2841 - mae: 1.7413 - val_loss: 14.4698 - val_mae: 2.7582\n",
            "Epoch 109/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 6.2490 - mae: 1.7001 - val_loss: 14.1372 - val_mae: 2.7166\n",
            "Epoch 110/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 6.1057 - mae: 1.6585 - val_loss: 13.9606 - val_mae: 2.7216\n",
            "Epoch 111/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.3035 - mae: 1.6964 - val_loss: 14.6429 - val_mae: 2.6324\n",
            "Epoch 112/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 6.2891 - mae: 1.7107 - val_loss: 14.2606 - val_mae: 2.6946\n",
            "Epoch 113/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 6.0971 - mae: 1.7032 - val_loss: 15.9933 - val_mae: 2.6786\n",
            "Epoch 114/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 6.0036 - mae: 1.7115 - val_loss: 14.3877 - val_mae: 2.7207\n",
            "Epoch 115/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 5.9961 - mae: 1.6633 - val_loss: 16.3998 - val_mae: 2.9360\n",
            "Epoch 116/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 6.1301 - mae: 1.6976 - val_loss: 15.1397 - val_mae: 2.6950\n",
            "Epoch 117/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 5.8978 - mae: 1.6744 - val_loss: 14.4508 - val_mae: 2.7224\n",
            "Epoch 118/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 5.7461 - mae: 1.6496 - val_loss: 15.1757 - val_mae: 2.6430\n",
            "Epoch 119/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.9405 - mae: 1.6738 - val_loss: 14.4666 - val_mae: 2.6082\n",
            "Epoch 120/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 5.8749 - mae: 1.6328 - val_loss: 15.9462 - val_mae: 2.7636\n",
            "Epoch 121/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 5.8324 - mae: 1.6580 - val_loss: 14.6033 - val_mae: 2.8230\n",
            "Epoch 122/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.1515 - mae: 1.6551 - val_loss: 14.0308 - val_mae: 2.6248\n",
            "Epoch 123/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 5.6208 - mae: 1.6276 - val_loss: 14.4931 - val_mae: 2.8442\n",
            "Epoch 124/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 5.9651 - mae: 1.6688 - val_loss: 13.6801 - val_mae: 2.6402\n",
            "Epoch 125/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 5.7151 - mae: 1.6327 - val_loss: 15.9898 - val_mae: 2.7790\n",
            "Epoch 126/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.8684 - mae: 1.6671 - val_loss: 13.9735 - val_mae: 2.6941\n",
            "Epoch 127/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.6650 - mae: 1.6207 - val_loss: 14.0435 - val_mae: 2.7700\n",
            "Epoch 128/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.6058 - mae: 1.6183 - val_loss: 13.8556 - val_mae: 2.6753\n",
            "Epoch 129/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 5.6472 - mae: 1.6067 - val_loss: 15.3480 - val_mae: 2.8019\n",
            "Epoch 130/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 5.5529 - mae: 1.6205 - val_loss: 16.1030 - val_mae: 2.8463\n",
            "Epoch 131/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 5.6916 - mae: 1.6354 - val_loss: 13.8663 - val_mae: 2.6501\n",
            "Epoch 132/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 5.6090 - mae: 1.6246 - val_loss: 16.5327 - val_mae: 2.6438\n",
            "Epoch 133/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.7008 - mae: 1.6666 - val_loss: 15.1141 - val_mae: 2.7032\n",
            "Epoch 134/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.5774 - mae: 1.6166 - val_loss: 13.9405 - val_mae: 2.6137\n",
            "Epoch 135/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.3639 - mae: 1.5698 - val_loss: 16.7201 - val_mae: 2.6934\n",
            "Epoch 136/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 5.8134 - mae: 1.6980 - val_loss: 14.6211 - val_mae: 2.6035\n",
            "Epoch 137/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 5.3875 - mae: 1.6178 - val_loss: 14.6448 - val_mae: 2.6419\n",
            "Epoch 138/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 5.2715 - mae: 1.5739 - val_loss: 14.2780 - val_mae: 2.6219\n",
            "Epoch 139/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.3124 - mae: 1.5761 - val_loss: 14.0927 - val_mae: 2.6720\n",
            "Epoch 140/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.3022 - mae: 1.5740 - val_loss: 14.4573 - val_mae: 2.8386\n",
            "Epoch 141/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.5782 - mae: 1.5898 - val_loss: 13.9571 - val_mae: 2.5688\n",
            "Epoch 142/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 5.3286 - mae: 1.5905 - val_loss: 14.7615 - val_mae: 2.6508\n",
            "Epoch 143/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.2788 - mae: 1.5841 - val_loss: 14.0943 - val_mae: 2.5901\n",
            "Epoch 144/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 5.2091 - mae: 1.5720 - val_loss: 13.5208 - val_mae: 2.6353\n",
            "Epoch 145/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 5.2465 - mae: 1.5597 - val_loss: 14.0583 - val_mae: 2.5333\n",
            "Epoch 146/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.1211 - mae: 1.5632 - val_loss: 14.4825 - val_mae: 2.5932\n",
            "Epoch 147/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.0601 - mae: 1.5379 - val_loss: 13.9921 - val_mae: 2.6508\n",
            "Epoch 148/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.3254 - mae: 1.5681 - val_loss: 14.9387 - val_mae: 2.6779\n",
            "Epoch 149/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.3310 - mae: 1.5600 - val_loss: 14.5139 - val_mae: 2.6056\n",
            "Epoch 150/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.0606 - mae: 1.5163 - val_loss: 14.0130 - val_mae: 2.6027\n",
            "Epoch 151/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 5.1461 - mae: 1.5169 - val_loss: 14.4092 - val_mae: 2.5266\n",
            "Epoch 152/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.2126 - mae: 1.5744 - val_loss: 14.4713 - val_mae: 2.6106\n",
            "Epoch 153/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.0225 - mae: 1.5216 - val_loss: 17.0116 - val_mae: 2.7083\n",
            "Epoch 154/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 5.1316 - mae: 1.5544 - val_loss: 15.4344 - val_mae: 2.6709\n",
            "Epoch 155/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.9403 - mae: 1.5282 - val_loss: 14.6122 - val_mae: 2.6837\n",
            "Epoch 156/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 5.0374 - mae: 1.5252 - val_loss: 14.9801 - val_mae: 2.5584\n",
            "Epoch 157/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.9276 - mae: 1.5241 - val_loss: 14.0222 - val_mae: 2.6409\n",
            "Epoch 158/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.9761 - mae: 1.5279 - val_loss: 14.8415 - val_mae: 2.7144\n",
            "Epoch 159/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.9069 - mae: 1.5167 - val_loss: 14.7590 - val_mae: 2.5976\n",
            "Epoch 160/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.7912 - mae: 1.5072 - val_loss: 15.5310 - val_mae: 2.6436\n",
            "Epoch 161/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.0555 - mae: 1.5652 - val_loss: 14.8517 - val_mae: 2.8582\n",
            "Epoch 162/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.1371 - mae: 1.5328 - val_loss: 14.9049 - val_mae: 2.5894\n",
            "Epoch 163/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.7688 - mae: 1.4749 - val_loss: 15.6474 - val_mae: 2.6307\n",
            "Epoch 164/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.8477 - mae: 1.5187 - val_loss: 14.3078 - val_mae: 2.5665\n",
            "Epoch 165/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.7988 - mae: 1.5108 - val_loss: 16.1310 - val_mae: 2.7693\n",
            "Epoch 166/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.7331 - mae: 1.5174 - val_loss: 14.7342 - val_mae: 2.8273\n",
            "Epoch 167/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.7884 - mae: 1.4951 - val_loss: 14.4361 - val_mae: 2.7318\n",
            "Epoch 168/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.8252 - mae: 1.5163 - val_loss: 16.0134 - val_mae: 2.8326\n",
            "Epoch 169/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.6541 - mae: 1.4805 - val_loss: 14.3617 - val_mae: 2.5486\n",
            "Epoch 170/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.5200 - mae: 1.4679 - val_loss: 14.7127 - val_mae: 2.7225\n",
            "Epoch 171/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.7605 - mae: 1.4959 - val_loss: 16.5999 - val_mae: 2.6417\n",
            "Epoch 172/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.6346 - mae: 1.4825 - val_loss: 15.2226 - val_mae: 2.5551\n",
            "Epoch 173/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.6345 - mae: 1.4909 - val_loss: 15.3264 - val_mae: 2.5701\n",
            "Epoch 174/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.5701 - mae: 1.4630 - val_loss: 14.6598 - val_mae: 2.5811\n",
            "Epoch 175/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.7311 - mae: 1.4628 - val_loss: 14.6469 - val_mae: 2.5117\n",
            "Epoch 176/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.5026 - mae: 1.4469 - val_loss: 14.3445 - val_mae: 2.6199\n",
            "Epoch 177/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.5895 - mae: 1.4548 - val_loss: 13.9629 - val_mae: 2.6884\n",
            "Epoch 178/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.6234 - mae: 1.4598 - val_loss: 14.6365 - val_mae: 2.6070\n",
            "Epoch 179/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.6539 - mae: 1.4909 - val_loss: 14.4785 - val_mae: 2.7250\n",
            "Epoch 180/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.5278 - mae: 1.4540 - val_loss: 15.5187 - val_mae: 2.5864\n",
            "Epoch 181/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.6886 - mae: 1.4497 - val_loss: 14.7035 - val_mae: 2.6220\n",
            "Epoch 182/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.4052 - mae: 1.4171 - val_loss: 14.0520 - val_mae: 2.5334\n",
            "Epoch 183/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.4979 - mae: 1.4371 - val_loss: 13.8661 - val_mae: 2.5896\n",
            "Epoch 184/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.3992 - mae: 1.4306 - val_loss: 15.1454 - val_mae: 2.5778\n",
            "Epoch 185/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.3345 - mae: 1.4058 - val_loss: 14.2858 - val_mae: 2.5125\n",
            "Epoch 186/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4.5349 - mae: 1.4242 - val_loss: 14.9836 - val_mae: 2.5410\n",
            "Epoch 187/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.2863 - mae: 1.4181 - val_loss: 14.1554 - val_mae: 2.5546\n",
            "Epoch 188/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.4058 - mae: 1.4312 - val_loss: 14.6089 - val_mae: 2.5415\n",
            "Epoch 189/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 4.3304 - mae: 1.4251 - val_loss: 14.1551 - val_mae: 2.5830\n",
            "Epoch 190/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.4098 - mae: 1.4377 - val_loss: 16.5973 - val_mae: 2.8182\n",
            "Epoch 191/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.4153 - mae: 1.4720 - val_loss: 17.9279 - val_mae: 2.8718\n",
            "Epoch 192/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.4682 - mae: 1.4935 - val_loss: 15.4028 - val_mae: 2.6148\n",
            "Epoch 193/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 4.2962 - mae: 1.4072 - val_loss: 14.5392 - val_mae: 2.5471\n",
            "Epoch 194/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.2592 - mae: 1.4028 - val_loss: 14.5972 - val_mae: 2.5745\n",
            "Epoch 195/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.2040 - mae: 1.4304 - val_loss: 14.5311 - val_mae: 2.5164\n",
            "Epoch 196/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 4.4688 - mae: 1.4480 - val_loss: 13.8117 - val_mae: 2.5195\n",
            "Epoch 197/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 4.2411 - mae: 1.3945 - val_loss: 14.4479 - val_mae: 2.5212\n",
            "Epoch 198/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.1219 - mae: 1.3850 - val_loss: 15.4369 - val_mae: 2.7433\n",
            "Epoch 199/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.1289 - mae: 1.4043 - val_loss: 16.4330 - val_mae: 2.9726\n",
            "Epoch 200/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.4184 - mae: 1.4633 - val_loss: 15.0368 - val_mae: 2.6426\n",
            "Epoch 201/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 4.1633 - mae: 1.3991 - val_loss: 14.2351 - val_mae: 2.6410\n",
            "Epoch 202/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 4.2639 - mae: 1.3753 - val_loss: 13.6633 - val_mae: 2.5280\n",
            "Epoch 203/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.0846 - mae: 1.3734 - val_loss: 13.4674 - val_mae: 2.4602\n",
            "Epoch 204/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.0098 - mae: 1.3290 - val_loss: 14.4670 - val_mae: 2.5393\n",
            "Epoch 205/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 3.9796 - mae: 1.3552 - val_loss: 17.3946 - val_mae: 3.0400\n",
            "Epoch 206/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 4.5548 - mae: 1.4996 - val_loss: 17.3616 - val_mae: 2.8174\n",
            "Epoch 207/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.2354 - mae: 1.4080 - val_loss: 14.5915 - val_mae: 2.6643\n",
            "Epoch 208/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.1128 - mae: 1.3925 - val_loss: 15.2095 - val_mae: 2.5491\n",
            "Epoch 209/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.9665 - mae: 1.3267 - val_loss: 17.9107 - val_mae: 2.9945\n",
            "Epoch 210/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.3095 - mae: 1.4407 - val_loss: 15.0232 - val_mae: 2.5952\n",
            "Epoch 211/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.9591 - mae: 1.3671 - val_loss: 14.1256 - val_mae: 2.5218\n",
            "Epoch 212/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 4.0392 - mae: 1.3542 - val_loss: 14.9805 - val_mae: 2.6083\n",
            "Epoch 213/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 4.0823 - mae: 1.3845 - val_loss: 15.2490 - val_mae: 2.6058\n",
            "Epoch 214/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.9672 - mae: 1.3656 - val_loss: 13.6247 - val_mae: 2.5226\n",
            "Epoch 215/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.9958 - mae: 1.3660 - val_loss: 15.7660 - val_mae: 2.7168\n",
            "Epoch 216/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.8865 - mae: 1.3472 - val_loss: 14.4850 - val_mae: 2.5111\n",
            "Epoch 217/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 3.8417 - mae: 1.3408 - val_loss: 14.4742 - val_mae: 2.6061\n",
            "Epoch 218/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.9047 - mae: 1.3319 - val_loss: 13.7628 - val_mae: 2.5287\n",
            "Epoch 219/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.9573 - mae: 1.3388 - val_loss: 13.5312 - val_mae: 2.4403\n",
            "Epoch 220/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 3.9025 - mae: 1.3276 - val_loss: 15.1962 - val_mae: 2.5477\n",
            "Epoch 221/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.8272 - mae: 1.3306 - val_loss: 14.3081 - val_mae: 2.6049\n",
            "Epoch 222/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.8623 - mae: 1.3423 - val_loss: 14.2670 - val_mae: 2.5376\n",
            "Epoch 223/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 3.8237 - mae: 1.3226 - val_loss: 17.1184 - val_mae: 2.7208\n",
            "Epoch 224/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 4.1192 - mae: 1.3756 - val_loss: 14.6462 - val_mae: 2.5008\n",
            "Epoch 225/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.6641 - mae: 1.3133 - val_loss: 15.6950 - val_mae: 2.7231\n",
            "Epoch 226/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.9319 - mae: 1.3428 - val_loss: 13.8476 - val_mae: 2.4936\n",
            "Epoch 227/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.7928 - mae: 1.2868 - val_loss: 13.9983 - val_mae: 2.6021\n",
            "Epoch 228/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3.8427 - mae: 1.3044 - val_loss: 13.9347 - val_mae: 2.5399\n",
            "Epoch 229/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.7115 - mae: 1.2876 - val_loss: 14.7029 - val_mae: 2.5950\n",
            "Epoch 230/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 3.9665 - mae: 1.3541 - val_loss: 14.2493 - val_mae: 2.5165\n",
            "Epoch 231/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 3.8954 - mae: 1.3268 - val_loss: 14.4299 - val_mae: 2.6522\n",
            "Epoch 232/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.6991 - mae: 1.3060 - val_loss: 14.7799 - val_mae: 2.5167\n",
            "Epoch 233/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.7449 - mae: 1.3106 - val_loss: 17.2407 - val_mae: 2.7410\n",
            "Epoch 234/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 3.8934 - mae: 1.3522 - val_loss: 14.0905 - val_mae: 2.4558\n",
            "Epoch 235/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.5923 - mae: 1.2703 - val_loss: 17.4044 - val_mae: 2.8013\n",
            "Epoch 236/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.7197 - mae: 1.3180 - val_loss: 14.7483 - val_mae: 2.7371\n",
            "Epoch 237/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.6040 - mae: 1.2975 - val_loss: 15.3026 - val_mae: 2.5336\n",
            "Epoch 238/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.6925 - mae: 1.3104 - val_loss: 14.4363 - val_mae: 2.4829\n",
            "Epoch 239/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.5347 - mae: 1.2657 - val_loss: 15.2964 - val_mae: 2.7267\n",
            "Epoch 240/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 3.6388 - mae: 1.2780 - val_loss: 13.6589 - val_mae: 2.4777\n",
            "Epoch 241/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 3.7434 - mae: 1.2996 - val_loss: 13.9885 - val_mae: 2.5366\n",
            "Epoch 242/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.6094 - mae: 1.2753 - val_loss: 14.9551 - val_mae: 2.5461\n",
            "Epoch 243/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.5089 - mae: 1.2294 - val_loss: 16.6028 - val_mae: 2.6557\n",
            "Epoch 244/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 3.6164 - mae: 1.2893 - val_loss: 14.7643 - val_mae: 2.5861\n",
            "Epoch 245/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.5368 - mae: 1.2681 - val_loss: 14.5158 - val_mae: 2.6517\n",
            "Epoch 246/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.6070 - mae: 1.2842 - val_loss: 15.3032 - val_mae: 2.7372\n",
            "Epoch 247/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.6842 - mae: 1.2930 - val_loss: 13.7337 - val_mae: 2.6045\n",
            "Epoch 248/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.6515 - mae: 1.2764 - val_loss: 14.4242 - val_mae: 2.4872\n",
            "Epoch 249/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.4920 - mae: 1.2624 - val_loss: 17.0671 - val_mae: 2.9689\n",
            "Epoch 250/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.7472 - mae: 1.3024 - val_loss: 15.0681 - val_mae: 2.5525\n",
            "Epoch 251/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.3037 - mae: 1.2507 - val_loss: 13.7428 - val_mae: 2.5097\n",
            "Epoch 252/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 3.4771 - mae: 1.2554 - val_loss: 13.5204 - val_mae: 2.4802\n",
            "Epoch 253/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.5322 - mae: 1.2637 - val_loss: 15.3294 - val_mae: 2.5899\n",
            "Epoch 254/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.5729 - mae: 1.2935 - val_loss: 15.8982 - val_mae: 2.6234\n",
            "Epoch 255/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 3.5350 - mae: 1.3016 - val_loss: 14.9486 - val_mae: 2.6613\n",
            "Epoch 256/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.4047 - mae: 1.2455 - val_loss: 14.6920 - val_mae: 2.4983\n",
            "Epoch 257/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.3988 - mae: 1.2549 - val_loss: 14.0621 - val_mae: 2.5244\n",
            "Epoch 258/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.3848 - mae: 1.2484 - val_loss: 13.5619 - val_mae: 2.5307\n",
            "Epoch 259/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.2681 - mae: 1.2062 - val_loss: 16.5824 - val_mae: 2.8982\n",
            "Epoch 260/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 3.4505 - mae: 1.2737 - val_loss: 14.0599 - val_mae: 2.6502\n",
            "Epoch 261/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.5511 - mae: 1.2655 - val_loss: 13.9565 - val_mae: 2.5044\n",
            "Epoch 262/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.2820 - mae: 1.2317 - val_loss: 15.6549 - val_mae: 2.5417\n",
            "Epoch 263/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.3900 - mae: 1.2600 - val_loss: 15.7143 - val_mae: 2.6106\n",
            "Epoch 264/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.3596 - mae: 1.2277 - val_loss: 14.0179 - val_mae: 2.6243\n",
            "Epoch 265/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.2194 - mae: 1.1924 - val_loss: 13.9635 - val_mae: 2.4102\n",
            "Epoch 266/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.2385 - mae: 1.2395 - val_loss: 13.9433 - val_mae: 2.4015\n",
            "Epoch 267/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 3.0172 - mae: 1.1856 - val_loss: 18.1158 - val_mae: 2.8202\n",
            "Epoch 268/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.6641 - mae: 1.3046 - val_loss: 14.8844 - val_mae: 2.5140\n",
            "Epoch 269/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.2065 - mae: 1.2264 - val_loss: 14.7551 - val_mae: 2.5768\n",
            "Epoch 270/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.0969 - mae: 1.1834 - val_loss: 13.5064 - val_mae: 2.4850\n",
            "Epoch 271/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.2587 - mae: 1.2230 - val_loss: 14.1043 - val_mae: 2.4326\n",
            "Epoch 272/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.2221 - mae: 1.1791 - val_loss: 13.3921 - val_mae: 2.4280\n",
            "Epoch 273/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.2453 - mae: 1.2135 - val_loss: 15.2348 - val_mae: 2.7064\n",
            "Epoch 274/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.1946 - mae: 1.2208 - val_loss: 14.0879 - val_mae: 2.4219\n",
            "Epoch 275/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.2373 - mae: 1.2142 - val_loss: 13.7633 - val_mae: 2.4905\n",
            "Epoch 276/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.1572 - mae: 1.2105 - val_loss: 14.6033 - val_mae: 2.6263\n",
            "Epoch 277/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 3.1952 - mae: 1.2107 - val_loss: 13.7319 - val_mae: 2.4406\n",
            "Epoch 278/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.0689 - mae: 1.1971 - val_loss: 14.0542 - val_mae: 2.4786\n",
            "Epoch 279/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.1432 - mae: 1.1959 - val_loss: 13.4880 - val_mae: 2.4716\n",
            "Epoch 280/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.3446 - mae: 1.2509 - val_loss: 13.6099 - val_mae: 2.5182\n",
            "Epoch 281/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.0957 - mae: 1.2017 - val_loss: 14.4606 - val_mae: 2.4524\n",
            "Epoch 282/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.1121 - mae: 1.2025 - val_loss: 13.9638 - val_mae: 2.5350\n",
            "Epoch 283/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.0987 - mae: 1.1928 - val_loss: 13.4110 - val_mae: 2.4634\n",
            "Epoch 284/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.1461 - mae: 1.2009 - val_loss: 14.0170 - val_mae: 2.4418\n",
            "Epoch 285/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.9400 - mae: 1.1789 - val_loss: 14.7392 - val_mae: 2.5665\n",
            "Epoch 286/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.1017 - mae: 1.2215 - val_loss: 14.1120 - val_mae: 2.4869\n",
            "Epoch 287/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.9854 - mae: 1.1771 - val_loss: 13.7682 - val_mae: 2.3739\n",
            "Epoch 288/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.1150 - mae: 1.1916 - val_loss: 13.8015 - val_mae: 2.4209\n",
            "Epoch 289/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.9326 - mae: 1.1731 - val_loss: 14.2749 - val_mae: 2.4480\n",
            "Epoch 290/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.0390 - mae: 1.1591 - val_loss: 15.9877 - val_mae: 2.8180\n",
            "Epoch 291/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.0874 - mae: 1.2062 - val_loss: 14.5504 - val_mae: 2.4817\n",
            "Epoch 292/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8784 - mae: 1.1439 - val_loss: 14.3291 - val_mae: 2.5656\n",
            "Epoch 293/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.9226 - mae: 1.1745 - val_loss: 13.2823 - val_mae: 2.4639\n",
            "Epoch 294/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.9879 - mae: 1.1638 - val_loss: 15.4382 - val_mae: 2.5755\n",
            "Epoch 295/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.1401 - mae: 1.2010 - val_loss: 14.5760 - val_mae: 2.4893\n",
            "Epoch 296/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.9252 - mae: 1.1706 - val_loss: 13.3607 - val_mae: 2.5153\n",
            "Epoch 297/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8655 - mae: 1.1401 - val_loss: 14.2824 - val_mae: 2.4974\n",
            "Epoch 298/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.9036 - mae: 1.1498 - val_loss: 15.3884 - val_mae: 2.6304\n",
            "Epoch 299/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.1348 - mae: 1.1877 - val_loss: 12.8630 - val_mae: 2.3627\n",
            "Epoch 300/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.7984 - mae: 1.1069 - val_loss: 15.5977 - val_mae: 2.5523\n",
            "Epoch 301/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8870 - mae: 1.1787 - val_loss: 14.2253 - val_mae: 2.5566\n",
            "Epoch 302/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.9447 - mae: 1.1780 - val_loss: 14.3659 - val_mae: 2.5007\n",
            "Epoch 303/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.9036 - mae: 1.1914 - val_loss: 13.1948 - val_mae: 2.3830\n",
            "Epoch 304/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.7363 - mae: 1.1375 - val_loss: 13.7867 - val_mae: 2.3826\n",
            "Epoch 305/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8455 - mae: 1.1448 - val_loss: 14.0602 - val_mae: 2.4883\n",
            "Epoch 306/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8157 - mae: 1.1460 - val_loss: 16.5651 - val_mae: 2.7840\n",
            "Epoch 307/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.9537 - mae: 1.2053 - val_loss: 13.2712 - val_mae: 2.3690\n",
            "Epoch 308/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.7061 - mae: 1.1124 - val_loss: 13.9019 - val_mae: 2.5075\n",
            "Epoch 309/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.6501 - mae: 1.1116 - val_loss: 13.4112 - val_mae: 2.4794\n",
            "Epoch 310/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8525 - mae: 1.1463 - val_loss: 14.2803 - val_mae: 2.4808\n",
            "Epoch 311/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8887 - mae: 1.1831 - val_loss: 13.3105 - val_mae: 2.4985\n",
            "Epoch 312/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.7570 - mae: 1.1134 - val_loss: 14.2258 - val_mae: 2.4267\n",
            "Epoch 313/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8106 - mae: 1.1466 - val_loss: 13.7000 - val_mae: 2.5240\n",
            "Epoch 314/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.7500 - mae: 1.1190 - val_loss: 13.9220 - val_mae: 2.6627\n",
            "Epoch 315/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.9208 - mae: 1.1566 - val_loss: 13.2977 - val_mae: 2.3751\n",
            "Epoch 316/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.7151 - mae: 1.1483 - val_loss: 13.9345 - val_mae: 2.5098\n",
            "Epoch 317/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.7059 - mae: 1.1680 - val_loss: 14.5726 - val_mae: 2.4914\n",
            "Epoch 318/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.6536 - mae: 1.0985 - val_loss: 13.3891 - val_mae: 2.4066\n",
            "Epoch 319/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.6669 - mae: 1.1004 - val_loss: 14.6601 - val_mae: 2.4601\n",
            "Epoch 320/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.7922 - mae: 1.1578 - val_loss: 13.3264 - val_mae: 2.5706\n",
            "Epoch 321/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.7054 - mae: 1.1469 - val_loss: 16.6916 - val_mae: 2.6447\n",
            "Epoch 322/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 3.0414 - mae: 1.2136 - val_loss: 15.6633 - val_mae: 2.7640\n",
            "Epoch 323/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.6329 - mae: 1.1333 - val_loss: 14.3930 - val_mae: 2.4067\n",
            "Epoch 324/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.6416 - mae: 1.1228 - val_loss: 14.7369 - val_mae: 2.5902\n",
            "Epoch 325/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.4997 - mae: 1.1233 - val_loss: 13.3451 - val_mae: 2.5801\n",
            "Epoch 326/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8467 - mae: 1.1378 - val_loss: 13.5960 - val_mae: 2.3478\n",
            "Epoch 327/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.6852 - mae: 1.1159 - val_loss: 13.7954 - val_mae: 2.5145\n",
            "Epoch 328/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.6516 - mae: 1.1130 - val_loss: 12.8874 - val_mae: 2.5161\n",
            "Epoch 329/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.7320 - mae: 1.1215 - val_loss: 12.6304 - val_mae: 2.3682\n",
            "Epoch 330/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.5438 - mae: 1.0831 - val_loss: 12.8968 - val_mae: 2.3458\n",
            "Epoch 331/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.5266 - mae: 1.0831 - val_loss: 13.1262 - val_mae: 2.4160\n",
            "Epoch 332/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.6976 - mae: 1.1216 - val_loss: 13.6699 - val_mae: 2.5230\n",
            "Epoch 333/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.8517 - mae: 1.1733 - val_loss: 13.2337 - val_mae: 2.4892\n",
            "Epoch 334/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.7731 - mae: 1.1309 - val_loss: 13.7181 - val_mae: 2.4468\n",
            "Epoch 335/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.5803 - mae: 1.0685 - val_loss: 13.1682 - val_mae: 2.3474\n",
            "Epoch 336/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.4814 - mae: 1.0520 - val_loss: 12.9213 - val_mae: 2.4338\n",
            "Epoch 337/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.4987 - mae: 1.0779 - val_loss: 12.9679 - val_mae: 2.3486\n",
            "Epoch 338/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.4960 - mae: 1.0974 - val_loss: 12.3769 - val_mae: 2.4380\n",
            "Epoch 339/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.5498 - mae: 1.0945 - val_loss: 14.9002 - val_mae: 2.6138\n",
            "Epoch 340/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.6627 - mae: 1.1279 - val_loss: 13.1129 - val_mae: 2.4289\n",
            "Epoch 341/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.4881 - mae: 1.0879 - val_loss: 14.6124 - val_mae: 2.4362\n",
            "Epoch 342/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.7022 - mae: 1.1159 - val_loss: 13.3191 - val_mae: 2.4400\n",
            "Epoch 343/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.4512 - mae: 1.0789 - val_loss: 13.4362 - val_mae: 2.4431\n",
            "Epoch 344/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.3360 - mae: 1.0555 - val_loss: 13.7869 - val_mae: 2.4358\n",
            "Epoch 345/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.5389 - mae: 1.0900 - val_loss: 13.4767 - val_mae: 2.3291\n",
            "Epoch 346/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.4066 - mae: 1.0697 - val_loss: 13.0516 - val_mae: 2.4029\n",
            "Epoch 347/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.6067 - mae: 1.0846 - val_loss: 13.4704 - val_mae: 2.3896\n",
            "Epoch 348/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.4670 - mae: 1.0718 - val_loss: 13.1635 - val_mae: 2.4513\n",
            "Epoch 349/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.5614 - mae: 1.1112 - val_loss: 13.4316 - val_mae: 2.4333\n",
            "Epoch 350/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.4854 - mae: 1.0695 - val_loss: 13.4326 - val_mae: 2.5977\n",
            "Epoch 351/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.5433 - mae: 1.0870 - val_loss: 12.9142 - val_mae: 2.4348\n",
            "Epoch 352/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.5318 - mae: 1.0718 - val_loss: 12.6900 - val_mae: 2.3484\n",
            "Epoch 353/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.4179 - mae: 1.0755 - val_loss: 13.8690 - val_mae: 2.5389\n",
            "Epoch 354/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.4403 - mae: 1.0866 - val_loss: 14.0114 - val_mae: 2.5884\n",
            "Epoch 355/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.3243 - mae: 1.0462 - val_loss: 13.4334 - val_mae: 2.3859\n",
            "Epoch 356/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.4005 - mae: 1.0707 - val_loss: 13.0310 - val_mae: 2.4413\n",
            "Epoch 357/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.3511 - mae: 1.0876 - val_loss: 12.4467 - val_mae: 2.3298\n",
            "Epoch 358/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.4018 - mae: 1.0339 - val_loss: 14.2274 - val_mae: 2.4340\n",
            "Epoch 359/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.3623 - mae: 1.0760 - val_loss: 14.1998 - val_mae: 2.4077\n",
            "Epoch 360/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.4300 - mae: 1.0750 - val_loss: 12.6698 - val_mae: 2.3144\n",
            "Epoch 361/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.2662 - mae: 1.0333 - val_loss: 13.4665 - val_mae: 2.3527\n",
            "Epoch 362/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.3181 - mae: 1.0560 - val_loss: 13.7395 - val_mae: 2.6898\n",
            "Epoch 363/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.6092 - mae: 1.0865 - val_loss: 13.8015 - val_mae: 2.4790\n",
            "Epoch 364/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.3341 - mae: 1.0350 - val_loss: 13.0557 - val_mae: 2.3436\n",
            "Epoch 365/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.3080 - mae: 1.0738 - val_loss: 16.4241 - val_mae: 2.9590\n",
            "Epoch 366/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.7552 - mae: 1.1449 - val_loss: 13.5118 - val_mae: 2.6202\n",
            "Epoch 367/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.3000 - mae: 1.0598 - val_loss: 13.1478 - val_mae: 2.3244\n",
            "Epoch 368/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.2727 - mae: 1.0446 - val_loss: 12.8928 - val_mae: 2.3472\n",
            "Epoch 369/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.3685 - mae: 1.0538 - val_loss: 12.8542 - val_mae: 2.3591\n",
            "Epoch 370/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.3551 - mae: 1.0565 - val_loss: 14.8727 - val_mae: 2.7053\n",
            "Epoch 371/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.4541 - mae: 1.0884 - val_loss: 13.0946 - val_mae: 2.4326\n",
            "Epoch 372/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.4229 - mae: 1.0737 - val_loss: 14.4023 - val_mae: 2.5469\n",
            "Epoch 373/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.3931 - mae: 1.0796 - val_loss: 13.4423 - val_mae: 2.4546\n",
            "Epoch 374/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.4905 - mae: 1.0867 - val_loss: 13.4098 - val_mae: 2.3938\n",
            "Epoch 375/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.2309 - mae: 1.0157 - val_loss: 12.4360 - val_mae: 2.3218\n",
            "Epoch 376/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.3669 - mae: 1.0828 - val_loss: 12.8349 - val_mae: 2.3174\n",
            "Epoch 377/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.2780 - mae: 1.0307 - val_loss: 12.6408 - val_mae: 2.3532\n",
            "Epoch 378/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.3949 - mae: 1.0866 - val_loss: 12.6001 - val_mae: 2.3249\n",
            "Epoch 379/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.3136 - mae: 1.0503 - val_loss: 12.6699 - val_mae: 2.3339\n",
            "Epoch 380/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.3128 - mae: 1.0493 - val_loss: 13.0322 - val_mae: 2.5570\n",
            "Epoch 381/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.2667 - mae: 1.0408 - val_loss: 12.4398 - val_mae: 2.3242\n",
            "Epoch 382/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.1898 - mae: 1.0220 - val_loss: 13.2441 - val_mae: 2.3358\n",
            "Epoch 383/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 2.3552 - mae: 1.0496 - val_loss: 12.6659 - val_mae: 2.4063\n",
            "Epoch 384/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.2298 - mae: 1.0225 - val_loss: 12.1977 - val_mae: 2.3936\n",
            "Epoch 385/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.2919 - mae: 1.0521 - val_loss: 12.2799 - val_mae: 2.3277\n",
            "Epoch 386/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.2388 - mae: 1.0007 - val_loss: 14.6862 - val_mae: 2.6123\n",
            "Epoch 387/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.1543 - mae: 1.0136 - val_loss: 14.1063 - val_mae: 2.4433\n",
            "Epoch 388/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.2042 - mae: 1.0240 - val_loss: 12.2035 - val_mae: 2.3914\n",
            "Epoch 389/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.3823 - mae: 1.0887 - val_loss: 12.5468 - val_mae: 2.2932\n",
            "Epoch 390/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.2668 - mae: 1.0212 - val_loss: 12.6662 - val_mae: 2.3372\n",
            "Epoch 391/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.1654 - mae: 0.9899 - val_loss: 14.7265 - val_mae: 2.6341\n",
            "Epoch 392/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.4401 - mae: 1.0858 - val_loss: 13.9952 - val_mae: 2.4577\n",
            "Epoch 393/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.2651 - mae: 1.0349 - val_loss: 12.7869 - val_mae: 2.3749\n",
            "Epoch 394/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.1968 - mae: 1.0172 - val_loss: 12.7845 - val_mae: 2.4282\n",
            "Epoch 395/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.0978 - mae: 1.0021 - val_loss: 11.9935 - val_mae: 2.2545\n",
            "Epoch 396/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 2.2896 - mae: 1.0206 - val_loss: 12.4773 - val_mae: 2.3010\n",
            "Epoch 397/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.1570 - mae: 1.0132 - val_loss: 12.7122 - val_mae: 2.3803\n",
            "Epoch 398/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.2053 - mae: 1.0369 - val_loss: 12.9672 - val_mae: 2.3909\n",
            "Epoch 399/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.2206 - mae: 1.0194 - val_loss: 12.8458 - val_mae: 2.3595\n",
            "Epoch 400/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.2350 - mae: 1.0411 - val_loss: 13.3451 - val_mae: 2.3260\n",
            "Epoch 401/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.2949 - mae: 1.0304 - val_loss: 12.3881 - val_mae: 2.2768\n",
            "Epoch 402/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.0360 - mae: 0.9731 - val_loss: 13.0272 - val_mae: 2.3331\n",
            "Epoch 403/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.1497 - mae: 1.0212 - val_loss: 12.6693 - val_mae: 2.3122\n",
            "Epoch 404/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.1290 - mae: 1.0052 - val_loss: 12.8464 - val_mae: 2.3878\n",
            "Epoch 405/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.1596 - mae: 1.0067 - val_loss: 12.5228 - val_mae: 2.2945\n",
            "Epoch 406/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.1951 - mae: 0.9989 - val_loss: 12.6646 - val_mae: 2.4068\n",
            "Epoch 407/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.2865 - mae: 1.0385 - val_loss: 12.5255 - val_mae: 2.2650\n",
            "Epoch 408/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.0283 - mae: 0.9860 - val_loss: 12.3064 - val_mae: 2.2876\n",
            "Epoch 409/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.0948 - mae: 1.0164 - val_loss: 13.7579 - val_mae: 2.4713\n",
            "Epoch 410/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.2728 - mae: 1.0793 - val_loss: 12.3456 - val_mae: 2.3418\n",
            "Epoch 411/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.0595 - mae: 0.9901 - val_loss: 12.3383 - val_mae: 2.3181\n",
            "Epoch 412/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.0578 - mae: 0.9944 - val_loss: 12.1742 - val_mae: 2.3003\n",
            "Epoch 413/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.1768 - mae: 1.0230 - val_loss: 12.6663 - val_mae: 2.4665\n",
            "Epoch 414/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.1127 - mae: 1.0049 - val_loss: 13.1255 - val_mae: 2.3154\n",
            "Epoch 415/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.0200 - mae: 0.9646 - val_loss: 13.2181 - val_mae: 2.5044\n",
            "Epoch 416/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1305 - mae: 0.9781 - val_loss: 12.2648 - val_mae: 2.3509\n",
            "Epoch 417/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9876 - mae: 0.9507 - val_loss: 13.6630 - val_mae: 2.3637\n",
            "Epoch 418/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0694 - mae: 0.9610 - val_loss: 12.9881 - val_mae: 2.3667\n",
            "Epoch 419/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0832 - mae: 1.0108 - val_loss: 12.4098 - val_mae: 2.3870\n",
            "Epoch 420/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.1012 - mae: 0.9799 - val_loss: 12.0374 - val_mae: 2.3671\n",
            "Epoch 421/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9839 - mae: 0.9765 - val_loss: 12.6070 - val_mae: 2.3004\n",
            "Epoch 422/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.9797 - mae: 0.9662 - val_loss: 14.8032 - val_mae: 2.4368\n",
            "Epoch 423/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 2.2416 - mae: 1.0290 - val_loss: 13.0288 - val_mae: 2.3539\n",
            "Epoch 424/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8538 - mae: 0.9560 - val_loss: 12.4103 - val_mae: 2.4711\n",
            "Epoch 425/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9520 - mae: 0.9424 - val_loss: 12.8397 - val_mae: 2.3146\n",
            "Epoch 426/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.9274 - mae: 0.9827 - val_loss: 12.0860 - val_mae: 2.2789\n",
            "Epoch 427/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0034 - mae: 0.9671 - val_loss: 13.8803 - val_mae: 2.4163\n",
            "Epoch 428/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0412 - mae: 0.9844 - val_loss: 14.1082 - val_mae: 2.6132\n",
            "Epoch 429/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.0896 - mae: 0.9952 - val_loss: 15.0926 - val_mae: 2.6032\n",
            "Epoch 430/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0748 - mae: 1.0297 - val_loss: 12.1374 - val_mae: 2.2861\n",
            "Epoch 431/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.9297 - mae: 0.9414 - val_loss: 13.1889 - val_mae: 2.4559\n",
            "Epoch 432/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.1217 - mae: 1.0170 - val_loss: 13.4255 - val_mae: 2.4646\n",
            "Epoch 433/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.0168 - mae: 0.9873 - val_loss: 12.3388 - val_mae: 2.3633\n",
            "Epoch 434/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.0236 - mae: 0.9669 - val_loss: 12.9484 - val_mae: 2.3664\n",
            "Epoch 435/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.9270 - mae: 0.9657 - val_loss: 12.9299 - val_mae: 2.4189\n",
            "Epoch 436/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.8856 - mae: 0.9405 - val_loss: 13.0383 - val_mae: 2.3067\n",
            "Epoch 437/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0371 - mae: 0.9898 - val_loss: 13.7346 - val_mae: 2.5036\n",
            "Epoch 438/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0738 - mae: 0.9758 - val_loss: 13.8116 - val_mae: 2.5685\n",
            "Epoch 439/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9731 - mae: 0.9837 - val_loss: 12.4781 - val_mae: 2.4343\n",
            "Epoch 440/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8680 - mae: 0.9654 - val_loss: 12.7488 - val_mae: 2.4757\n",
            "Epoch 441/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9450 - mae: 0.9911 - val_loss: 12.4383 - val_mae: 2.4727\n",
            "Epoch 442/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2.0554 - mae: 0.9889 - val_loss: 12.4857 - val_mae: 2.4491\n",
            "Epoch 443/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.0393 - mae: 0.9877 - val_loss: 12.3918 - val_mae: 2.4239\n",
            "Epoch 444/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.9134 - mae: 0.9381 - val_loss: 13.2268 - val_mae: 2.4551\n",
            "Epoch 445/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.9902 - mae: 0.9534 - val_loss: 12.4043 - val_mae: 2.2873\n",
            "Epoch 446/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.0072 - mae: 0.9950 - val_loss: 12.6583 - val_mae: 2.3731\n",
            "Epoch 447/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8837 - mae: 0.9916 - val_loss: 12.1735 - val_mae: 2.2815\n",
            "Epoch 448/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.8726 - mae: 0.9201 - val_loss: 11.9540 - val_mae: 2.3380\n",
            "Epoch 449/500\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 1.8811 - mae: 0.9447 - val_loss: 14.8511 - val_mae: 2.6160\n",
            "Epoch 450/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.1917 - mae: 1.0162 - val_loss: 12.4836 - val_mae: 2.3211\n",
            "Epoch 451/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.7662 - mae: 0.9054 - val_loss: 12.7040 - val_mae: 2.4219\n",
            "Epoch 452/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9447 - mae: 0.9502 - val_loss: 12.3612 - val_mae: 2.2889\n",
            "Epoch 453/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.9012 - mae: 0.9629 - val_loss: 12.6213 - val_mae: 2.3629\n",
            "Epoch 454/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.8230 - mae: 0.9273 - val_loss: 13.2877 - val_mae: 2.3810\n",
            "Epoch 455/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.9500 - mae: 0.9685 - val_loss: 16.9619 - val_mae: 2.6610\n",
            "Epoch 456/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.3154 - mae: 1.0554 - val_loss: 13.1841 - val_mae: 2.3783\n",
            "Epoch 457/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.7636 - mae: 0.9259 - val_loss: 12.3571 - val_mae: 2.3166\n",
            "Epoch 458/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.8741 - mae: 0.9506 - val_loss: 13.0315 - val_mae: 2.3671\n",
            "Epoch 459/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.8498 - mae: 0.9536 - val_loss: 12.7697 - val_mae: 2.4604\n",
            "Epoch 460/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.9139 - mae: 0.9838 - val_loss: 13.6995 - val_mae: 2.3794\n",
            "Epoch 461/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.8511 - mae: 0.9369 - val_loss: 12.1087 - val_mae: 2.2971\n",
            "Epoch 462/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.8551 - mae: 0.9574 - val_loss: 12.5881 - val_mae: 2.3816\n",
            "Epoch 463/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.8736 - mae: 0.9153 - val_loss: 12.5087 - val_mae: 2.3655\n",
            "Epoch 464/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.0670 - mae: 1.0164 - val_loss: 13.6935 - val_mae: 2.6536\n",
            "Epoch 465/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.9524 - mae: 0.9826 - val_loss: 12.0593 - val_mae: 2.2811\n",
            "Epoch 466/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.8091 - mae: 0.9126 - val_loss: 12.4093 - val_mae: 2.3848\n",
            "Epoch 467/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.8341 - mae: 0.9260 - val_loss: 12.9777 - val_mae: 2.6122\n",
            "Epoch 468/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.0246 - mae: 0.9827 - val_loss: 12.3764 - val_mae: 2.2837\n",
            "Epoch 469/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.7184 - mae: 0.9018 - val_loss: 12.6940 - val_mae: 2.3345\n",
            "Epoch 470/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.8886 - mae: 0.9957 - val_loss: 12.8639 - val_mae: 2.4616\n",
            "Epoch 471/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.7793 - mae: 0.9422 - val_loss: 12.8367 - val_mae: 2.2953\n",
            "Epoch 472/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.6776 - mae: 0.8953 - val_loss: 12.3228 - val_mae: 2.3023\n",
            "Epoch 473/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.8971 - mae: 0.9587 - val_loss: 12.7431 - val_mae: 2.3709\n",
            "Epoch 474/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.7324 - mae: 0.9084 - val_loss: 12.4445 - val_mae: 2.3162\n",
            "Epoch 475/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.8202 - mae: 0.9123 - val_loss: 12.1407 - val_mae: 2.3004\n",
            "Epoch 476/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.8493 - mae: 0.9693 - val_loss: 11.8511 - val_mae: 2.2738\n",
            "Epoch 477/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.7446 - mae: 0.9114 - val_loss: 14.4738 - val_mae: 2.7191\n",
            "Epoch 478/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.8084 - mae: 0.9723 - val_loss: 12.6222 - val_mae: 2.3508\n",
            "Epoch 479/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.7775 - mae: 0.9055 - val_loss: 13.4060 - val_mae: 2.3643\n",
            "Epoch 480/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.8982 - mae: 0.9720 - val_loss: 14.6193 - val_mae: 2.4654\n",
            "Epoch 481/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.8951 - mae: 0.9595 - val_loss: 12.7674 - val_mae: 2.3220\n",
            "Epoch 482/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.6876 - mae: 0.8805 - val_loss: 12.7194 - val_mae: 2.4374\n",
            "Epoch 483/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.8030 - mae: 0.9136 - val_loss: 11.7978 - val_mae: 2.2666\n",
            "Epoch 484/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.7264 - mae: 0.8917 - val_loss: 12.1287 - val_mae: 2.3470\n",
            "Epoch 485/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.8297 - mae: 0.9383 - val_loss: 13.1375 - val_mae: 2.4854\n",
            "Epoch 486/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.8386 - mae: 0.9418 - val_loss: 12.9794 - val_mae: 2.3567\n",
            "Epoch 487/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.7735 - mae: 0.8912 - val_loss: 11.7226 - val_mae: 2.2948\n",
            "Epoch 488/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.9255 - mae: 0.9427 - val_loss: 12.0584 - val_mae: 2.3147\n",
            "Epoch 489/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.6020 - mae: 0.8558 - val_loss: 12.8978 - val_mae: 2.6211\n",
            "Epoch 490/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8964 - mae: 0.9438 - val_loss: 12.4744 - val_mae: 2.3598\n",
            "Epoch 491/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.7444 - mae: 0.9190 - val_loss: 12.1581 - val_mae: 2.2529\n",
            "Epoch 492/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.6680 - mae: 0.8912 - val_loss: 13.4983 - val_mae: 2.6281\n",
            "Epoch 493/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.7687 - mae: 0.9685 - val_loss: 13.1381 - val_mae: 2.3830\n",
            "Epoch 494/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.7676 - mae: 0.9160 - val_loss: 13.4983 - val_mae: 2.4198\n",
            "Epoch 495/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.7082 - mae: 0.9056 - val_loss: 12.3658 - val_mae: 2.5032\n",
            "Epoch 496/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8376 - mae: 0.9373 - val_loss: 12.0465 - val_mae: 2.2809\n",
            "Epoch 497/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.7914 - mae: 0.9360 - val_loss: 12.3174 - val_mae: 2.3571\n",
            "Epoch 498/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.7605 - mae: 0.9282 - val_loss: 12.5056 - val_mae: 2.3310\n",
            "Epoch 499/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.6271 - mae: 0.8859 - val_loss: 12.2801 - val_mae: 2.2705\n",
            "Epoch 500/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1.8642 - mae: 0.9358 - val_loss: 12.1476 - val_mae: 2.3353\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQm3pc0FYPQB"
      },
      "source": [
        "Visualize the model's training progress using the stats stored in the `history` object. We want to use this data to determine how long to train *before* the model stops making progress."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6XriGbVPh2t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "c1012669-a167-401e-d551-8bd08ad02b72"
      },
      "source": [
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3St8-DmrX8P4"
      },
      "source": [
        "The graph shows the average error **in Validation set** is about $2,600 dollars. Is this good? \n",
        "\n",
        "Well, \\$2,600 is not an insignificant amount when some of the labels are only $15,000.\n",
        "\n",
        "Let's see how did the model performs on the **Test set**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl_yNr5n1kms",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72e9e8c0-be6c-406a-8c85-a14e3d514397"
      },
      "source": [
        "[loss, mae] = model.evaluate(test_data, test_labels, verbose=0)\n",
        "print(\"Testing set Mean Abs Error: ${:7.2f}\".format(mae * 1000))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing set Mean Abs Error: $2544.50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft603OzXuEZC"
      },
      "source": [
        "## Predict\n",
        "\n",
        "Finally, predict some housing prices using data in the testing set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe7RXH3N3CWU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "dd10e30c-4d4f-408f-cb55-8678a3819993"
      },
      "source": [
        "test_predictions = model.predict(test_data).flatten()\n",
        "plot_prediction(test_labels, test_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgGQuV-yqYZH"
      },
      "source": [
        "## Observations\n",
        "\n",
        "So far, we implemented a MLP model to handle the \"**Boston House Prices**\" regression problem.\n",
        "\n",
        "Mean Absolute Error in Validation is around **\\$2,600** whereas in Testing, it is about **$2900**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JlpuqrDLRNH"
      },
      "source": [
        "## Create the Conv1D model\n",
        "\n",
        "Let's build an Conv1D model. Here, we'll use a `Sequential` model with 3 Conv1D layers, one MaxPooling1D layer, and an output layer that returns a single, continuous value. The model building steps are wrapped in a function, `build_model` as we did above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8btqTYvL4D7"
      },
      "source": [
        "## Reshape Data sets\n",
        "As you might remember, Conv1D layer expects input shape in 3D as\n",
        "\n",
        "  `[batch_size, time_steps, input_dimension]`\n",
        "\n",
        "However, current data is in the shape of\n",
        "\n",
        "`[batch_size, features]`\n",
        "\n",
        "See below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqqudq9qpxVj",
        "outputId": "f4a5142d-d985-4902-f63c-4b33e27f558c"
      },
      "source": [
        "print(train_data.shape)\n",
        "print(train_data[0].shape)\n",
        "print(train_data[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(404, 13)\n",
            "(13,)\n",
            "[-0.27224633 -0.48361547 -0.43576161 -0.25683275 -0.1652266  -0.1764426\n",
            "  0.81306188  0.1166983  -0.62624905 -0.59517003  1.14850044  0.44807713\n",
            "  0.8252202 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5pUZ4KXNJVM"
      },
      "source": [
        "That is, in the current data set each sample has 13 features and no timesteps!\n",
        "\n",
        "**Basically, we convert features to timesteps**\n",
        "\n",
        "To convert 2D of input data into a 3D input, we simply **reshape** as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WF55ueLqqBa6",
        "outputId": "3176f6af-1664-4e51-f00c-d6881d88bb7c"
      },
      "source": [
        "sample_size = train_data.shape[0] # number of samples in train set\n",
        "time_steps  = train_data.shape[1] # number of features in train set\n",
        "input_dimension = 1               # each feature is represented by 1 number\n",
        "\n",
        "train_data_reshaped = train_data.reshape(sample_size,time_steps,input_dimension)\n",
        "print(\"After reshape train data set shape:\\n\", train_data_reshaped.shape)\n",
        "print(\"1 Sample shape:\\n\",train_data_reshaped[0].shape)\n",
        "print(\"An example sample:\\n\", train_data_reshaped[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After reshape train data set shape:\n",
            " (404, 13, 1)\n",
            "1 Sample shape:\n",
            " (13, 1)\n",
            "An example sample:\n",
            " [[-0.27224633]\n",
            " [-0.48361547]\n",
            " [-0.43576161]\n",
            " [-0.25683275]\n",
            " [-0.1652266 ]\n",
            " [-0.1764426 ]\n",
            " [ 0.81306188]\n",
            " [ 0.1166983 ]\n",
            " [-0.62624905]\n",
            " [-0.59517003]\n",
            " [ 1.14850044]\n",
            " [ 0.44807713]\n",
            " [ 0.8252202 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydUsxRzwNl4-"
      },
      "source": [
        "After conversion, we have a train data set whose shape is\n",
        "\n",
        "  `[batch_size, time_steps, input_dimension]` ---> `[404, 13, 1]`\n",
        "\n",
        "That is, each sample has **13 time steps with 1 input dimension**. You can also think as `each sample has 13 rows 1 column`!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXLomVo5O0qQ"
      },
      "source": [
        "##Reminder\n",
        "* `Conv1D(filters=1, kernel_size=7, activation='relu')` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuyXqm-GZtJ-"
      },
      "source": [
        "<img src=\"https://github.com/kmkarakaya/ML_tutorials/blob/master/images/conv1d.gif?raw=true\" width=\"500\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUHhjsXaaWvN"
      },
      "source": [
        "We need to **reshape** the Test data as well:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCaXUzV-f-zN"
      },
      "source": [
        "test_data_reshaped = test_data.reshape(test_data.shape[0],test_data.shape[1],1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJlS3rd5Oevi"
      },
      "source": [
        "Now, we can create Conv1D model as below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4JNcPxXqrBo",
        "outputId": "29cba4ba-739d-4f64-f63a-eac9ec5b2f27"
      },
      "source": [
        "def build_conv1D_model():\n",
        "\n",
        "  n_timesteps = train_data_reshaped.shape[1] #13\n",
        "  n_features  = train_data_reshaped.shape[2] #1 \n",
        "  model = keras.Sequential(name=\"model_conv1D\")\n",
        "  model.add(keras.layers.Input(shape=(n_timesteps,n_features)))\n",
        "  model.add(keras.layers.Conv1D(filters=64, kernel_size=7, activation='relu', name=\"Conv1D_1\"))\n",
        "  model.add(keras.layers.Dropout(0.5))\n",
        "  model.add(keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu', name=\"Conv1D_2\"))\n",
        "  \n",
        "  model.add(keras.layers.Conv1D(filters=16, kernel_size=2, activation='relu', name=\"Conv1D_3\"))\n",
        "  \n",
        "  model.add(keras.layers.MaxPooling1D(pool_size=2, name=\"MaxPooling1D\"))\n",
        "  model.add(keras.layers.Flatten())\n",
        "  model.add(keras.layers.Dense(32, activation='relu', name=\"Dense_1\"))\n",
        "  model.add(keras.layers.Dense(n_features, name=\"Dense_2\"))\n",
        "\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mse',optimizer=optimizer,metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "model_conv1D = build_conv1D_model()\n",
        "model_conv1D.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_conv1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Conv1D_1 (Conv1D)            (None, 7, 64)             512       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 7, 64)             0         \n",
            "_________________________________________________________________\n",
            "Conv1D_2 (Conv1D)            (None, 5, 32)             6176      \n",
            "_________________________________________________________________\n",
            "Conv1D_3 (Conv1D)            (None, 4, 16)             1040      \n",
            "_________________________________________________________________\n",
            "MaxPooling1D (MaxPooling1D)  (None, 2, 16)             0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "Dense_1 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "Dense_2 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 8,817\n",
            "Trainable params: 8,817\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUXn_-Zis8iM"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "The model is trained for 500 epochs, and record the training and validation accuracy in the `history` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8Vufz-zDCVR",
        "outputId": "b9e17769-c766-4486-ed7e-6961e79d4779"
      },
      "source": [
        "# Store training stats\n",
        "history = model_conv1D.fit(train_data_reshaped, train_labels, epochs=EPOCHS,\n",
        "                    validation_split=0.2, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "11/11 [==============================] - 0s 20ms/step - loss: 551.9765 - mae: 21.6418 - val_loss: 570.7389 - val_mae: 22.0704\n",
            "Epoch 2/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 437.2314 - mae: 18.8166 - val_loss: 386.9020 - val_mae: 17.4391\n",
            "Epoch 3/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 229.0796 - mae: 12.4355 - val_loss: 162.9355 - val_mae: 9.8778\n",
            "Epoch 4/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 99.7150 - mae: 7.7738 - val_loss: 101.5060 - val_mae: 7.2353\n",
            "Epoch 5/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 80.2137 - mae: 6.7285 - val_loss: 85.3598 - val_mae: 6.6339\n",
            "Epoch 6/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 66.6075 - mae: 6.0787 - val_loss: 73.2253 - val_mae: 6.0379\n",
            "Epoch 7/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 61.5079 - mae: 5.7374 - val_loss: 62.6794 - val_mae: 5.5335\n",
            "Epoch 8/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 55.8161 - mae: 5.4081 - val_loss: 60.4959 - val_mae: 5.4173\n",
            "Epoch 9/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 52.3468 - mae: 5.1768 - val_loss: 71.7843 - val_mae: 5.9896\n",
            "Epoch 10/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 52.2663 - mae: 5.1287 - val_loss: 73.5027 - val_mae: 6.0830\n",
            "Epoch 11/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 53.1446 - mae: 5.1775 - val_loss: 50.5680 - val_mae: 5.1033\n",
            "Epoch 12/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 50.1135 - mae: 5.0067 - val_loss: 48.0623 - val_mae: 4.7987\n",
            "Epoch 13/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 48.7708 - mae: 4.9723 - val_loss: 48.9799 - val_mae: 4.9408\n",
            "Epoch 14/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 44.7304 - mae: 4.5627 - val_loss: 48.4432 - val_mae: 4.6611\n",
            "Epoch 15/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 44.5039 - mae: 4.6150 - val_loss: 52.3535 - val_mae: 4.8781\n",
            "Epoch 16/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 43.9223 - mae: 4.7561 - val_loss: 55.0146 - val_mae: 4.9677\n",
            "Epoch 17/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 43.6719 - mae: 4.5739 - val_loss: 44.7359 - val_mae: 4.7114\n",
            "Epoch 18/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 42.5292 - mae: 4.6986 - val_loss: 47.3148 - val_mae: 5.0002\n",
            "Epoch 19/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 43.3104 - mae: 4.6018 - val_loss: 50.6874 - val_mae: 4.7813\n",
            "Epoch 20/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 42.6938 - mae: 4.4326 - val_loss: 58.3834 - val_mae: 5.1575\n",
            "Epoch 21/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 41.5762 - mae: 4.4528 - val_loss: 47.7811 - val_mae: 4.8336\n",
            "Epoch 22/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 39.5701 - mae: 4.4279 - val_loss: 48.9076 - val_mae: 4.5873\n",
            "Epoch 23/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 39.2231 - mae: 4.2588 - val_loss: 43.8472 - val_mae: 4.4645\n",
            "Epoch 24/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 40.3883 - mae: 4.2930 - val_loss: 46.7332 - val_mae: 4.8326\n",
            "Epoch 25/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 36.3306 - mae: 4.3729 - val_loss: 48.8849 - val_mae: 4.4571\n",
            "Epoch 26/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 35.5213 - mae: 4.0488 - val_loss: 45.1427 - val_mae: 4.7328\n",
            "Epoch 27/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 37.3656 - mae: 4.1224 - val_loss: 45.4845 - val_mae: 4.3188\n",
            "Epoch 28/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 35.0429 - mae: 3.9833 - val_loss: 44.5963 - val_mae: 4.2921\n",
            "Epoch 29/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33.2337 - mae: 3.9701 - val_loss: 39.9268 - val_mae: 4.2719\n",
            "Epoch 30/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 30.0262 - mae: 3.6804 - val_loss: 37.9478 - val_mae: 4.3130\n",
            "Epoch 31/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 34.3509 - mae: 4.2016 - val_loss: 52.6123 - val_mae: 4.8846\n",
            "Epoch 32/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 33.0154 - mae: 4.0812 - val_loss: 35.7174 - val_mae: 4.0638\n",
            "Epoch 33/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 32.4914 - mae: 3.9838 - val_loss: 35.4287 - val_mae: 3.9633\n",
            "Epoch 34/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 32.3209 - mae: 3.8566 - val_loss: 36.0059 - val_mae: 3.9322\n",
            "Epoch 35/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 30.2274 - mae: 3.7211 - val_loss: 36.1357 - val_mae: 4.1944\n",
            "Epoch 36/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.8949 - mae: 3.7282 - val_loss: 42.9328 - val_mae: 4.3410\n",
            "Epoch 37/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 31.6242 - mae: 3.7781 - val_loss: 33.1103 - val_mae: 3.9001\n",
            "Epoch 38/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 30.3772 - mae: 3.8252 - val_loss: 33.2439 - val_mae: 3.8301\n",
            "Epoch 39/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 27.8800 - mae: 3.6169 - val_loss: 47.7971 - val_mae: 4.7649\n",
            "Epoch 40/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 31.3710 - mae: 3.7833 - val_loss: 32.0484 - val_mae: 3.8955\n",
            "Epoch 41/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 29.0484 - mae: 3.6856 - val_loss: 34.6579 - val_mae: 3.8786\n",
            "Epoch 42/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 29.3931 - mae: 3.6280 - val_loss: 35.0896 - val_mae: 3.9987\n",
            "Epoch 43/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 27.6611 - mae: 3.5120 - val_loss: 42.6704 - val_mae: 4.4772\n",
            "Epoch 44/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 27.4084 - mae: 3.7303 - val_loss: 45.6757 - val_mae: 4.7724\n",
            "Epoch 45/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.2060 - mae: 3.4045 - val_loss: 31.9777 - val_mae: 3.8433\n",
            "Epoch 46/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.7728 - mae: 3.4814 - val_loss: 33.0391 - val_mae: 3.8473\n",
            "Epoch 47/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.9527 - mae: 3.4642 - val_loss: 27.8879 - val_mae: 3.8928\n",
            "Epoch 48/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 25.1990 - mae: 3.4797 - val_loss: 29.8635 - val_mae: 3.8033\n",
            "Epoch 49/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 29.4555 - mae: 3.7447 - val_loss: 25.6029 - val_mae: 3.4997\n",
            "Epoch 50/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 26.2235 - mae: 3.5824 - val_loss: 26.8921 - val_mae: 3.8901\n",
            "Epoch 51/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 25.7049 - mae: 3.5521 - val_loss: 35.5073 - val_mae: 4.0710\n",
            "Epoch 52/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.1145 - mae: 3.4213 - val_loss: 36.6238 - val_mae: 4.1728\n",
            "Epoch 53/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 26.2260 - mae: 3.4710 - val_loss: 27.6931 - val_mae: 3.5491\n",
            "Epoch 54/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 26.8013 - mae: 3.6161 - val_loss: 27.4144 - val_mae: 3.5446\n",
            "Epoch 55/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 23.8930 - mae: 3.3608 - val_loss: 23.0132 - val_mae: 3.3678\n",
            "Epoch 56/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 25.2527 - mae: 3.5326 - val_loss: 27.6366 - val_mae: 3.5281\n",
            "Epoch 57/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.9979 - mae: 3.5457 - val_loss: 33.8286 - val_mae: 3.9819\n",
            "Epoch 58/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 23.1408 - mae: 3.3242 - val_loss: 32.8729 - val_mae: 3.9685\n",
            "Epoch 59/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 24.0480 - mae: 3.3912 - val_loss: 31.7736 - val_mae: 3.8980\n",
            "Epoch 60/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 24.7921 - mae: 3.4284 - val_loss: 38.6312 - val_mae: 4.6501\n",
            "Epoch 61/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 24.2239 - mae: 3.5160 - val_loss: 22.0178 - val_mae: 3.2334\n",
            "Epoch 62/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 23.3156 - mae: 3.4328 - val_loss: 31.4378 - val_mae: 3.9268\n",
            "Epoch 63/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 22.1088 - mae: 3.2737 - val_loss: 21.8629 - val_mae: 3.2234\n",
            "Epoch 64/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 21.9214 - mae: 3.3190 - val_loss: 21.7565 - val_mae: 3.5539\n",
            "Epoch 65/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 21.5894 - mae: 3.2640 - val_loss: 26.8577 - val_mae: 4.1640\n",
            "Epoch 66/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 21.6226 - mae: 3.3184 - val_loss: 22.7217 - val_mae: 3.2441\n",
            "Epoch 67/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 25.1489 - mae: 3.6083 - val_loss: 22.4493 - val_mae: 3.2198\n",
            "Epoch 68/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 23.8828 - mae: 3.2862 - val_loss: 20.9959 - val_mae: 3.3726\n",
            "Epoch 69/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 20.0609 - mae: 3.1013 - val_loss: 22.4753 - val_mae: 3.2629\n",
            "Epoch 70/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 22.0213 - mae: 3.2718 - val_loss: 20.3887 - val_mae: 3.2962\n",
            "Epoch 71/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 20.8117 - mae: 3.2559 - val_loss: 19.0226 - val_mae: 3.1207\n",
            "Epoch 72/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 24.0388 - mae: 3.4650 - val_loss: 20.4987 - val_mae: 3.2120\n",
            "Epoch 73/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 20.4394 - mae: 3.1920 - val_loss: 21.2561 - val_mae: 3.4935\n",
            "Epoch 74/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 21.8779 - mae: 3.3351 - val_loss: 40.4948 - val_mae: 4.7937\n",
            "Epoch 75/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 22.9913 - mae: 3.4095 - val_loss: 26.7606 - val_mae: 3.6202\n",
            "Epoch 76/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 20.8564 - mae: 3.1019 - val_loss: 26.4805 - val_mae: 4.2357\n",
            "Epoch 77/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 19.9311 - mae: 3.1538 - val_loss: 16.4948 - val_mae: 2.9383\n",
            "Epoch 78/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 18.7693 - mae: 3.1044 - val_loss: 18.9840 - val_mae: 3.3998\n",
            "Epoch 79/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 18.6199 - mae: 3.0381 - val_loss: 18.4115 - val_mae: 2.9885\n",
            "Epoch 80/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 20.4280 - mae: 3.1261 - val_loss: 18.2090 - val_mae: 3.0143\n",
            "Epoch 81/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 17.7345 - mae: 2.9273 - val_loss: 16.9185 - val_mae: 3.0588\n",
            "Epoch 82/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 19.7760 - mae: 3.1418 - val_loss: 18.5118 - val_mae: 3.0056\n",
            "Epoch 83/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 18.9713 - mae: 3.1961 - val_loss: 17.1957 - val_mae: 3.0948\n",
            "Epoch 84/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 19.1837 - mae: 3.1275 - val_loss: 17.1577 - val_mae: 3.0604\n",
            "Epoch 85/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 17.8135 - mae: 2.9561 - val_loss: 15.6568 - val_mae: 2.8205\n",
            "Epoch 86/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 17.1199 - mae: 2.9766 - val_loss: 19.1985 - val_mae: 3.4289\n",
            "Epoch 87/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 19.7336 - mae: 3.0921 - val_loss: 22.4672 - val_mae: 3.8041\n",
            "Epoch 88/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 18.1197 - mae: 3.0755 - val_loss: 16.1066 - val_mae: 2.9061\n",
            "Epoch 89/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 17.8281 - mae: 2.9299 - val_loss: 26.3878 - val_mae: 3.7159\n",
            "Epoch 90/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 16.9580 - mae: 2.9654 - val_loss: 16.2023 - val_mae: 3.0819\n",
            "Epoch 91/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.8926 - mae: 2.8513 - val_loss: 16.7526 - val_mae: 3.1225\n",
            "Epoch 92/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.9628 - mae: 2.8452 - val_loss: 15.6801 - val_mae: 2.8267\n",
            "Epoch 93/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 19.1909 - mae: 3.1996 - val_loss: 17.6567 - val_mae: 3.2971\n",
            "Epoch 94/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 18.3682 - mae: 3.1448 - val_loss: 15.0932 - val_mae: 2.8903\n",
            "Epoch 95/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 18.6592 - mae: 3.0484 - val_loss: 21.0372 - val_mae: 3.3359\n",
            "Epoch 96/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 17.7099 - mae: 2.9875 - val_loss: 19.7393 - val_mae: 3.1906\n",
            "Epoch 97/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 16.5228 - mae: 2.8921 - val_loss: 18.2910 - val_mae: 3.3731\n",
            "Epoch 98/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 16.3969 - mae: 2.9644 - val_loss: 18.6874 - val_mae: 3.0254\n",
            "Epoch 99/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 18.3492 - mae: 3.0372 - val_loss: 18.2461 - val_mae: 3.3692\n",
            "Epoch 100/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 18.6588 - mae: 3.0487 - val_loss: 18.3923 - val_mae: 3.0341\n",
            "Epoch 101/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.0686 - mae: 2.8575 - val_loss: 23.2106 - val_mae: 3.9098\n",
            "Epoch 102/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.3615 - mae: 2.9080 - val_loss: 14.6362 - val_mae: 2.8232\n",
            "Epoch 103/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.8858 - mae: 2.7795 - val_loss: 14.7499 - val_mae: 2.9374\n",
            "Epoch 104/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 15.2619 - mae: 2.7653 - val_loss: 26.9360 - val_mae: 4.2453\n",
            "Epoch 105/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.8769 - mae: 2.9576 - val_loss: 18.4276 - val_mae: 3.4421\n",
            "Epoch 106/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 17.5098 - mae: 3.0098 - val_loss: 15.7747 - val_mae: 3.1497\n",
            "Epoch 107/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.3011 - mae: 2.9416 - val_loss: 14.5784 - val_mae: 2.8257\n",
            "Epoch 108/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 16.7454 - mae: 2.9231 - val_loss: 17.7886 - val_mae: 3.3878\n",
            "Epoch 109/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 15.0114 - mae: 2.8128 - val_loss: 15.4681 - val_mae: 3.0320\n",
            "Epoch 110/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 15.5999 - mae: 2.8117 - val_loss: 19.2550 - val_mae: 3.2366\n",
            "Epoch 111/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 15.5914 - mae: 2.8059 - val_loss: 14.7326 - val_mae: 2.7889\n",
            "Epoch 112/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.7998 - mae: 2.7417 - val_loss: 17.3444 - val_mae: 3.2999\n",
            "Epoch 113/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.4445 - mae: 2.7919 - val_loss: 14.7194 - val_mae: 2.8684\n",
            "Epoch 114/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 15.8871 - mae: 2.8295 - val_loss: 14.5497 - val_mae: 2.8856\n",
            "Epoch 115/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.9935 - mae: 2.8888 - val_loss: 15.4981 - val_mae: 2.8359\n",
            "Epoch 116/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 16.2686 - mae: 2.8842 - val_loss: 14.5869 - val_mae: 2.9092\n",
            "Epoch 117/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 15.9508 - mae: 2.8137 - val_loss: 15.9642 - val_mae: 2.9028\n",
            "Epoch 118/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.5658 - mae: 2.7844 - val_loss: 22.2047 - val_mae: 3.8150\n",
            "Epoch 119/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 14.7464 - mae: 2.8602 - val_loss: 20.7900 - val_mae: 3.4721\n",
            "Epoch 120/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 16.0874 - mae: 2.8379 - val_loss: 15.9973 - val_mae: 2.8895\n",
            "Epoch 121/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.2645 - mae: 2.6376 - val_loss: 30.3787 - val_mae: 4.3367\n",
            "Epoch 122/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.4255 - mae: 2.6876 - val_loss: 18.6355 - val_mae: 3.2238\n",
            "Epoch 123/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 16.3884 - mae: 2.8840 - val_loss: 16.9854 - val_mae: 3.1662\n",
            "Epoch 124/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.5615 - mae: 2.5101 - val_loss: 12.9647 - val_mae: 2.6684\n",
            "Epoch 125/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.7519 - mae: 2.6475 - val_loss: 13.3154 - val_mae: 2.6731\n",
            "Epoch 126/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.3841 - mae: 2.6910 - val_loss: 20.5386 - val_mae: 3.6513\n",
            "Epoch 127/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 16.2488 - mae: 2.8137 - val_loss: 12.4843 - val_mae: 2.6283\n",
            "Epoch 128/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 15.0330 - mae: 2.7712 - val_loss: 13.3781 - val_mae: 2.7140\n",
            "Epoch 129/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 13.9075 - mae: 2.7818 - val_loss: 12.5630 - val_mae: 2.7396\n",
            "Epoch 130/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.1182 - mae: 2.6905 - val_loss: 14.8527 - val_mae: 2.8622\n",
            "Epoch 131/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.2419 - mae: 2.6269 - val_loss: 16.5674 - val_mae: 3.2327\n",
            "Epoch 132/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.1557 - mae: 2.6674 - val_loss: 18.4144 - val_mae: 3.2733\n",
            "Epoch 133/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.0098 - mae: 2.5368 - val_loss: 13.0222 - val_mae: 2.7409\n",
            "Epoch 134/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.9615 - mae: 2.6508 - val_loss: 18.4822 - val_mae: 3.4385\n",
            "Epoch 135/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.0177 - mae: 2.7585 - val_loss: 13.0258 - val_mae: 2.7132\n",
            "Epoch 136/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.2388 - mae: 2.6924 - val_loss: 19.8372 - val_mae: 3.3679\n",
            "Epoch 137/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.6562 - mae: 2.7917 - val_loss: 17.2879 - val_mae: 3.3251\n",
            "Epoch 138/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 14.5103 - mae: 2.8621 - val_loss: 21.7588 - val_mae: 3.6630\n",
            "Epoch 139/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 13.6099 - mae: 2.6737 - val_loss: 15.2566 - val_mae: 3.0350\n",
            "Epoch 140/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.2546 - mae: 2.5081 - val_loss: 14.7548 - val_mae: 2.9271\n",
            "Epoch 141/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.5702 - mae: 2.8071 - val_loss: 16.2652 - val_mae: 3.0288\n",
            "Epoch 142/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.8486 - mae: 2.7292 - val_loss: 13.4305 - val_mae: 2.8385\n",
            "Epoch 143/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.5908 - mae: 2.6364 - val_loss: 18.1299 - val_mae: 3.2678\n",
            "Epoch 144/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.8560 - mae: 2.6794 - val_loss: 12.5696 - val_mae: 2.7031\n",
            "Epoch 145/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.1655 - mae: 2.5333 - val_loss: 14.6386 - val_mae: 3.0344\n",
            "Epoch 146/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 13.0971 - mae: 2.7275 - val_loss: 22.6332 - val_mae: 3.8774\n",
            "Epoch 147/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.7405 - mae: 2.7354 - val_loss: 11.7516 - val_mae: 2.5990\n",
            "Epoch 148/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.9128 - mae: 2.5393 - val_loss: 19.8679 - val_mae: 3.4314\n",
            "Epoch 149/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.8602 - mae: 2.7959 - val_loss: 21.8103 - val_mae: 3.8033\n",
            "Epoch 150/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 14.0712 - mae: 2.7062 - val_loss: 13.8982 - val_mae: 2.9255\n",
            "Epoch 151/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 12.7849 - mae: 2.5649 - val_loss: 11.7517 - val_mae: 2.5849\n",
            "Epoch 152/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.4767 - mae: 2.4819 - val_loss: 13.7321 - val_mae: 2.7226\n",
            "Epoch 153/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 14.0348 - mae: 2.6976 - val_loss: 12.6682 - val_mae: 2.7169\n",
            "Epoch 154/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 12.7983 - mae: 2.6244 - val_loss: 14.4427 - val_mae: 2.8783\n",
            "Epoch 155/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.9086 - mae: 2.6588 - val_loss: 22.1118 - val_mae: 3.8383\n",
            "Epoch 156/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 12.4170 - mae: 2.5967 - val_loss: 13.6621 - val_mae: 2.8307\n",
            "Epoch 157/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.4798 - mae: 2.5610 - val_loss: 11.7932 - val_mae: 2.6187\n",
            "Epoch 158/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.6864 - mae: 2.3658 - val_loss: 12.5078 - val_mae: 2.7366\n",
            "Epoch 159/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.4460 - mae: 2.5500 - val_loss: 12.8469 - val_mae: 2.6814\n",
            "Epoch 160/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.9305 - mae: 2.5030 - val_loss: 29.6895 - val_mae: 4.5643\n",
            "Epoch 161/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14.4267 - mae: 2.7831 - val_loss: 11.8512 - val_mae: 2.6579\n",
            "Epoch 162/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.9146 - mae: 2.6206 - val_loss: 19.7699 - val_mae: 3.5053\n",
            "Epoch 163/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.0024 - mae: 2.6587 - val_loss: 11.5697 - val_mae: 2.5532\n",
            "Epoch 164/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13.7182 - mae: 2.7918 - val_loss: 16.7258 - val_mae: 3.1234\n",
            "Epoch 165/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.6600 - mae: 2.5370 - val_loss: 15.8439 - val_mae: 3.0238\n",
            "Epoch 166/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.0625 - mae: 2.6329 - val_loss: 12.4378 - val_mae: 2.6226\n",
            "Epoch 167/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.6768 - mae: 2.6506 - val_loss: 12.4811 - val_mae: 2.7070\n",
            "Epoch 168/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.4988 - mae: 2.4418 - val_loss: 21.7286 - val_mae: 3.7132\n",
            "Epoch 169/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 11.4719 - mae: 2.5004 - val_loss: 14.7485 - val_mae: 2.9717\n",
            "Epoch 170/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 12.9718 - mae: 2.5786 - val_loss: 11.7342 - val_mae: 2.6186\n",
            "Epoch 171/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.2488 - mae: 2.4634 - val_loss: 18.5735 - val_mae: 3.4166\n",
            "Epoch 172/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.2417 - mae: 2.6206 - val_loss: 12.0848 - val_mae: 2.6220\n",
            "Epoch 173/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.3268 - mae: 2.4463 - val_loss: 20.5273 - val_mae: 3.6596\n",
            "Epoch 174/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.3785 - mae: 2.4986 - val_loss: 16.6296 - val_mae: 3.1688\n",
            "Epoch 175/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 12.0885 - mae: 2.5180 - val_loss: 12.2520 - val_mae: 2.6607\n",
            "Epoch 176/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.5440 - mae: 2.4871 - val_loss: 13.9519 - val_mae: 2.9327\n",
            "Epoch 177/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 12.1840 - mae: 2.5620 - val_loss: 11.5641 - val_mae: 2.6508\n",
            "Epoch 178/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 12.9870 - mae: 2.6201 - val_loss: 14.4619 - val_mae: 2.9192\n",
            "Epoch 179/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 11.3077 - mae: 2.5232 - val_loss: 16.6473 - val_mae: 3.1925\n",
            "Epoch 180/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.5311 - mae: 2.5281 - val_loss: 21.8811 - val_mae: 3.7035\n",
            "Epoch 181/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.5114 - mae: 2.5059 - val_loss: 15.4687 - val_mae: 3.0929\n",
            "Epoch 182/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 11.7297 - mae: 2.5363 - val_loss: 10.7931 - val_mae: 2.5490\n",
            "Epoch 183/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 11.1113 - mae: 2.5120 - val_loss: 16.2151 - val_mae: 3.0839\n",
            "Epoch 184/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.4164 - mae: 2.2679 - val_loss: 14.8678 - val_mae: 3.0602\n",
            "Epoch 185/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.9173 - mae: 2.5405 - val_loss: 11.1339 - val_mae: 2.5675\n",
            "Epoch 186/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.9348 - mae: 2.4844 - val_loss: 12.4949 - val_mae: 2.7817\n",
            "Epoch 187/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 12.4803 - mae: 2.6330 - val_loss: 13.7160 - val_mae: 2.9477\n",
            "Epoch 188/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.0229 - mae: 2.4019 - val_loss: 11.3112 - val_mae: 2.5560\n",
            "Epoch 189/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.7021 - mae: 2.3696 - val_loss: 11.0634 - val_mae: 2.5246\n",
            "Epoch 190/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.5189 - mae: 2.6436 - val_loss: 15.2262 - val_mae: 2.9759\n",
            "Epoch 191/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 12.2403 - mae: 2.5228 - val_loss: 14.9569 - val_mae: 2.9582\n",
            "Epoch 192/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.6273 - mae: 2.3434 - val_loss: 11.7353 - val_mae: 2.6134\n",
            "Epoch 193/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.3694 - mae: 2.4266 - val_loss: 11.8103 - val_mae: 2.6300\n",
            "Epoch 194/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 11.2948 - mae: 2.4519 - val_loss: 11.7916 - val_mae: 2.6030\n",
            "Epoch 195/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.3396 - mae: 2.5361 - val_loss: 13.7945 - val_mae: 2.9111\n",
            "Epoch 196/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.1708 - mae: 2.5961 - val_loss: 12.0930 - val_mae: 2.5778\n",
            "Epoch 197/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.9260 - mae: 2.5581 - val_loss: 11.9909 - val_mae: 2.6186\n",
            "Epoch 198/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 14.0238 - mae: 2.6545 - val_loss: 11.7586 - val_mae: 2.6350\n",
            "Epoch 199/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.7405 - mae: 2.1778 - val_loss: 12.7923 - val_mae: 2.7304\n",
            "Epoch 200/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.2322 - mae: 2.4820 - val_loss: 24.0351 - val_mae: 3.9048\n",
            "Epoch 201/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.0972 - mae: 2.5841 - val_loss: 12.4936 - val_mae: 2.6704\n",
            "Epoch 202/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.7345 - mae: 2.3216 - val_loss: 18.8395 - val_mae: 3.4005\n",
            "Epoch 203/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.2279 - mae: 2.3691 - val_loss: 13.3381 - val_mae: 2.8041\n",
            "Epoch 204/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.2273 - mae: 2.4544 - val_loss: 14.6202 - val_mae: 2.9731\n",
            "Epoch 205/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.0201 - mae: 2.4180 - val_loss: 28.4594 - val_mae: 4.4132\n",
            "Epoch 206/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.7413 - mae: 2.5722 - val_loss: 14.3492 - val_mae: 2.8728\n",
            "Epoch 207/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.5666 - mae: 2.4298 - val_loss: 12.6986 - val_mae: 2.7685\n",
            "Epoch 208/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.5801 - mae: 2.3944 - val_loss: 11.0027 - val_mae: 2.5076\n",
            "Epoch 209/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.2005 - mae: 2.2633 - val_loss: 13.4026 - val_mae: 2.8215\n",
            "Epoch 210/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.4804 - mae: 2.3557 - val_loss: 15.4976 - val_mae: 3.0399\n",
            "Epoch 211/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.7162 - mae: 2.6136 - val_loss: 14.0912 - val_mae: 2.8912\n",
            "Epoch 212/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.8952 - mae: 2.4290 - val_loss: 11.5914 - val_mae: 2.6325\n",
            "Epoch 213/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.9244 - mae: 2.4267 - val_loss: 27.1577 - val_mae: 4.1828\n",
            "Epoch 214/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.3432 - mae: 2.5155 - val_loss: 16.5904 - val_mae: 3.2139\n",
            "Epoch 215/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.1587 - mae: 2.4043 - val_loss: 17.2770 - val_mae: 3.2395\n",
            "Epoch 216/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.6514 - mae: 2.5272 - val_loss: 11.5849 - val_mae: 2.5962\n",
            "Epoch 217/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.3142 - mae: 2.4055 - val_loss: 13.7747 - val_mae: 2.7756\n",
            "Epoch 218/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 12.3726 - mae: 2.6362 - val_loss: 12.6362 - val_mae: 2.7328\n",
            "Epoch 219/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.2601 - mae: 2.3819 - val_loss: 14.8482 - val_mae: 2.8208\n",
            "Epoch 220/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.4355 - mae: 2.3478 - val_loss: 16.0187 - val_mae: 3.1235\n",
            "Epoch 221/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.3426 - mae: 2.3860 - val_loss: 12.5105 - val_mae: 2.7015\n",
            "Epoch 222/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.4137 - mae: 2.2295 - val_loss: 12.8900 - val_mae: 2.7576\n",
            "Epoch 223/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.0895 - mae: 2.2867 - val_loss: 11.5823 - val_mae: 2.6595\n",
            "Epoch 224/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.4269 - mae: 2.4393 - val_loss: 11.8132 - val_mae: 2.6313\n",
            "Epoch 225/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.7292 - mae: 2.2508 - val_loss: 16.3633 - val_mae: 3.1374\n",
            "Epoch 226/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.8828 - mae: 2.4099 - val_loss: 19.1735 - val_mae: 3.4184\n",
            "Epoch 227/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.8399 - mae: 2.2452 - val_loss: 12.4124 - val_mae: 2.6903\n",
            "Epoch 228/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.3709 - mae: 2.3417 - val_loss: 12.8755 - val_mae: 2.7049\n",
            "Epoch 229/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.5970 - mae: 2.4887 - val_loss: 10.6139 - val_mae: 2.5307\n",
            "Epoch 230/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.8193 - mae: 2.3198 - val_loss: 15.6687 - val_mae: 3.0979\n",
            "Epoch 231/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.8158 - mae: 2.2761 - val_loss: 14.2478 - val_mae: 2.9267\n",
            "Epoch 232/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.8408 - mae: 2.5539 - val_loss: 10.7180 - val_mae: 2.4515\n",
            "Epoch 233/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.1393 - mae: 2.2557 - val_loss: 16.0408 - val_mae: 2.9077\n",
            "Epoch 234/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.9830 - mae: 2.4023 - val_loss: 11.6003 - val_mae: 2.5618\n",
            "Epoch 235/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.1678 - mae: 2.2017 - val_loss: 11.7409 - val_mae: 2.5414\n",
            "Epoch 236/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.9226 - mae: 2.3874 - val_loss: 28.0713 - val_mae: 4.4061\n",
            "Epoch 237/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.5090 - mae: 2.4787 - val_loss: 11.9178 - val_mae: 2.6217\n",
            "Epoch 238/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.8344 - mae: 2.2328 - val_loss: 14.6273 - val_mae: 2.9605\n",
            "Epoch 239/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.0778 - mae: 2.3396 - val_loss: 11.9402 - val_mae: 2.6563\n",
            "Epoch 240/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.1816 - mae: 2.3931 - val_loss: 11.9091 - val_mae: 2.6720\n",
            "Epoch 241/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.1676 - mae: 2.3258 - val_loss: 19.4969 - val_mae: 3.5506\n",
            "Epoch 242/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.2864 - mae: 2.3355 - val_loss: 14.0769 - val_mae: 2.9045\n",
            "Epoch 243/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.3485 - mae: 2.2413 - val_loss: 10.5823 - val_mae: 2.5432\n",
            "Epoch 244/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.6233 - mae: 2.3597 - val_loss: 10.7278 - val_mae: 2.5767\n",
            "Epoch 245/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 11.1414 - mae: 2.4449 - val_loss: 10.8659 - val_mae: 2.4583\n",
            "Epoch 246/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.1282 - mae: 2.3317 - val_loss: 13.3299 - val_mae: 2.7414\n",
            "Epoch 247/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.7856 - mae: 2.3402 - val_loss: 11.4606 - val_mae: 2.5879\n",
            "Epoch 248/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.0094 - mae: 2.1130 - val_loss: 11.7599 - val_mae: 2.5636\n",
            "Epoch 249/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.7666 - mae: 2.2936 - val_loss: 12.1634 - val_mae: 2.6754\n",
            "Epoch 250/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.9042 - mae: 2.2045 - val_loss: 18.6773 - val_mae: 3.3600\n",
            "Epoch 251/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.9819 - mae: 2.3531 - val_loss: 23.9747 - val_mae: 4.0624\n",
            "Epoch 252/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11.0756 - mae: 2.4586 - val_loss: 21.5762 - val_mae: 3.7704\n",
            "Epoch 253/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.8193 - mae: 2.3464 - val_loss: 11.5934 - val_mae: 2.5802\n",
            "Epoch 254/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.3079 - mae: 2.1539 - val_loss: 17.3741 - val_mae: 3.2860\n",
            "Epoch 255/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.7488 - mae: 2.2657 - val_loss: 10.9959 - val_mae: 2.5480\n",
            "Epoch 256/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.5180 - mae: 2.3979 - val_loss: 11.0205 - val_mae: 2.5177\n",
            "Epoch 257/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.3712 - mae: 2.3347 - val_loss: 12.6485 - val_mae: 2.6585\n",
            "Epoch 258/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.7983 - mae: 2.2830 - val_loss: 10.8865 - val_mae: 2.4769\n",
            "Epoch 259/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.6321 - mae: 2.3126 - val_loss: 11.8393 - val_mae: 2.6083\n",
            "Epoch 260/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.8536 - mae: 2.4212 - val_loss: 10.8029 - val_mae: 2.5343\n",
            "Epoch 261/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 10.7900 - mae: 2.2826 - val_loss: 27.9192 - val_mae: 4.4163\n",
            "Epoch 262/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.9246 - mae: 2.5733 - val_loss: 12.8664 - val_mae: 2.7939\n",
            "Epoch 263/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.1439 - mae: 2.1779 - val_loss: 17.0343 - val_mae: 3.1751\n",
            "Epoch 264/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.4350 - mae: 2.3919 - val_loss: 16.2210 - val_mae: 3.2252\n",
            "Epoch 265/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.0293 - mae: 2.2574 - val_loss: 11.9610 - val_mae: 2.6706\n",
            "Epoch 266/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.8606 - mae: 2.1693 - val_loss: 12.2924 - val_mae: 2.7230\n",
            "Epoch 267/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.5710 - mae: 2.1786 - val_loss: 10.7399 - val_mae: 2.5050\n",
            "Epoch 268/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.5759 - mae: 2.1397 - val_loss: 9.9209 - val_mae: 2.4316\n",
            "Epoch 269/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.4211 - mae: 2.4214 - val_loss: 10.7810 - val_mae: 2.5048\n",
            "Epoch 270/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.4078 - mae: 2.2011 - val_loss: 10.3169 - val_mae: 2.4748\n",
            "Epoch 271/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.7797 - mae: 2.2715 - val_loss: 14.6807 - val_mae: 2.9138\n",
            "Epoch 272/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.7329 - mae: 2.1921 - val_loss: 11.5778 - val_mae: 2.4856\n",
            "Epoch 273/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.9783 - mae: 2.2763 - val_loss: 12.8676 - val_mae: 2.7593\n",
            "Epoch 274/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.4896 - mae: 2.3561 - val_loss: 11.5348 - val_mae: 2.6053\n",
            "Epoch 275/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.6548 - mae: 2.1656 - val_loss: 14.9852 - val_mae: 3.1049\n",
            "Epoch 276/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.8239 - mae: 2.2268 - val_loss: 15.4888 - val_mae: 3.1813\n",
            "Epoch 277/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.5696 - mae: 2.1722 - val_loss: 10.3029 - val_mae: 2.4011\n",
            "Epoch 278/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.4564 - mae: 2.1620 - val_loss: 16.0514 - val_mae: 3.2722\n",
            "Epoch 279/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.4148 - mae: 2.2679 - val_loss: 9.3540 - val_mae: 2.3530\n",
            "Epoch 280/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.0305 - mae: 2.1732 - val_loss: 11.7731 - val_mae: 2.5613\n",
            "Epoch 281/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 9.5151 - mae: 2.2623 - val_loss: 12.6733 - val_mae: 2.7682\n",
            "Epoch 282/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.8696 - mae: 2.3328 - val_loss: 14.1910 - val_mae: 2.9235\n",
            "Epoch 283/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.0471 - mae: 2.1522 - val_loss: 13.6864 - val_mae: 2.9095\n",
            "Epoch 284/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.9535 - mae: 2.2640 - val_loss: 16.4301 - val_mae: 3.2659\n",
            "Epoch 285/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.8493 - mae: 2.1961 - val_loss: 11.7262 - val_mae: 2.6712\n",
            "Epoch 286/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.0275 - mae: 2.1230 - val_loss: 11.5433 - val_mae: 2.6065\n",
            "Epoch 287/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.4835 - mae: 2.2244 - val_loss: 11.9148 - val_mae: 2.6208\n",
            "Epoch 288/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.6696 - mae: 2.1609 - val_loss: 22.1832 - val_mae: 3.8725\n",
            "Epoch 289/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.9076 - mae: 2.3590 - val_loss: 10.8644 - val_mae: 2.4291\n",
            "Epoch 290/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.4917 - mae: 2.0832 - val_loss: 11.6214 - val_mae: 2.5483\n",
            "Epoch 291/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.5816 - mae: 2.0690 - val_loss: 17.6339 - val_mae: 3.3109\n",
            "Epoch 292/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.5792 - mae: 2.2842 - val_loss: 13.2588 - val_mae: 2.8285\n",
            "Epoch 293/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.2112 - mae: 2.2208 - val_loss: 10.1749 - val_mae: 2.3911\n",
            "Epoch 294/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.0274 - mae: 2.0804 - val_loss: 18.1588 - val_mae: 3.3960\n",
            "Epoch 295/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.5051 - mae: 2.2823 - val_loss: 11.1902 - val_mae: 2.5422\n",
            "Epoch 296/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.3511 - mae: 2.1245 - val_loss: 12.6825 - val_mae: 2.7139\n",
            "Epoch 297/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.0424 - mae: 2.3217 - val_loss: 19.4122 - val_mae: 3.5286\n",
            "Epoch 298/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.9275 - mae: 2.1782 - val_loss: 14.0306 - val_mae: 2.9171\n",
            "Epoch 299/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.0420 - mae: 2.2581 - val_loss: 11.2742 - val_mae: 2.6022\n",
            "Epoch 300/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 10.0014 - mae: 2.3178 - val_loss: 14.0964 - val_mae: 2.9678\n",
            "Epoch 301/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.4415 - mae: 2.1939 - val_loss: 17.4789 - val_mae: 3.3894\n",
            "Epoch 302/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.3783 - mae: 2.3501 - val_loss: 16.0602 - val_mae: 3.1007\n",
            "Epoch 303/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.5459 - mae: 2.2888 - val_loss: 15.9937 - val_mae: 3.1058\n",
            "Epoch 304/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.8205 - mae: 2.0595 - val_loss: 13.0245 - val_mae: 2.7314\n",
            "Epoch 305/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.0439 - mae: 2.1148 - val_loss: 12.5073 - val_mae: 2.5749\n",
            "Epoch 306/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.2893 - mae: 2.1393 - val_loss: 15.4049 - val_mae: 3.1764\n",
            "Epoch 307/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.5654 - mae: 2.2561 - val_loss: 15.8022 - val_mae: 3.0676\n",
            "Epoch 308/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.7080 - mae: 2.1902 - val_loss: 18.8053 - val_mae: 3.4926\n",
            "Epoch 309/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.4023 - mae: 2.2024 - val_loss: 16.4162 - val_mae: 3.2360\n",
            "Epoch 310/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.5706 - mae: 2.1461 - val_loss: 12.1070 - val_mae: 2.5487\n",
            "Epoch 311/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.2132 - mae: 1.9902 - val_loss: 15.8090 - val_mae: 3.1391\n",
            "Epoch 312/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.3374 - mae: 2.1959 - val_loss: 11.1556 - val_mae: 2.4769\n",
            "Epoch 313/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.7307 - mae: 2.1012 - val_loss: 17.3136 - val_mae: 3.1815\n",
            "Epoch 314/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10.0437 - mae: 2.3957 - val_loss: 10.3821 - val_mae: 2.3983\n",
            "Epoch 315/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.1573 - mae: 2.0150 - val_loss: 13.1274 - val_mae: 2.7447\n",
            "Epoch 316/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.2812 - mae: 2.1271 - val_loss: 10.1341 - val_mae: 2.3511\n",
            "Epoch 317/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.8245 - mae: 2.1490 - val_loss: 12.4347 - val_mae: 2.6940\n",
            "Epoch 318/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.7593 - mae: 2.1384 - val_loss: 12.2631 - val_mae: 2.6453\n",
            "Epoch 319/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 8.5038 - mae: 2.1200 - val_loss: 9.9597 - val_mae: 2.3866\n",
            "Epoch 320/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.7749 - mae: 2.0719 - val_loss: 16.4516 - val_mae: 3.2092\n",
            "Epoch 321/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.4032 - mae: 2.2610 - val_loss: 13.0494 - val_mae: 2.7824\n",
            "Epoch 322/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 9.1832 - mae: 2.2348 - val_loss: 10.2162 - val_mae: 2.3872\n",
            "Epoch 323/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.6736 - mae: 2.0646 - val_loss: 10.3587 - val_mae: 2.4537\n",
            "Epoch 324/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.0863 - mae: 2.0777 - val_loss: 10.8842 - val_mae: 2.5012\n",
            "Epoch 325/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.8144 - mae: 2.1903 - val_loss: 11.7791 - val_mae: 2.6935\n",
            "Epoch 326/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.6249 - mae: 2.1500 - val_loss: 16.7503 - val_mae: 3.1049\n",
            "Epoch 327/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.4134 - mae: 2.0877 - val_loss: 12.4773 - val_mae: 2.7562\n",
            "Epoch 328/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.1795 - mae: 2.1848 - val_loss: 9.4341 - val_mae: 2.3334\n",
            "Epoch 329/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.5078 - mae: 2.1966 - val_loss: 19.2750 - val_mae: 3.5042\n",
            "Epoch 330/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.1097 - mae: 2.3350 - val_loss: 10.4348 - val_mae: 2.4878\n",
            "Epoch 331/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.9252 - mae: 2.1693 - val_loss: 15.9119 - val_mae: 3.2370\n",
            "Epoch 332/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.2986 - mae: 2.2055 - val_loss: 10.3858 - val_mae: 2.3644\n",
            "Epoch 333/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.7835 - mae: 2.1629 - val_loss: 23.9784 - val_mae: 4.1021\n",
            "Epoch 334/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.3313 - mae: 2.2042 - val_loss: 12.0592 - val_mae: 2.6394\n",
            "Epoch 335/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.9606 - mae: 2.1083 - val_loss: 11.1412 - val_mae: 2.4451\n",
            "Epoch 336/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.5746 - mae: 2.0929 - val_loss: 12.4442 - val_mae: 2.5998\n",
            "Epoch 337/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.4580 - mae: 2.1514 - val_loss: 12.4212 - val_mae: 2.7134\n",
            "Epoch 338/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.4349 - mae: 2.1842 - val_loss: 12.3543 - val_mae: 2.6916\n",
            "Epoch 339/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.1187 - mae: 2.0658 - val_loss: 9.1029 - val_mae: 2.2960\n",
            "Epoch 340/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.1876 - mae: 2.1140 - val_loss: 12.4627 - val_mae: 2.7851\n",
            "Epoch 341/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.8115 - mae: 2.1092 - val_loss: 14.1742 - val_mae: 2.9890\n",
            "Epoch 342/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.1679 - mae: 2.2669 - val_loss: 18.1821 - val_mae: 3.4487\n",
            "Epoch 343/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.7046 - mae: 2.2249 - val_loss: 9.8764 - val_mae: 2.3153\n",
            "Epoch 344/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.9206 - mae: 1.9794 - val_loss: 12.7358 - val_mae: 2.8184\n",
            "Epoch 345/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.5244 - mae: 2.1797 - val_loss: 25.4245 - val_mae: 4.1244\n",
            "Epoch 346/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.8885 - mae: 2.2443 - val_loss: 12.2823 - val_mae: 2.6598\n",
            "Epoch 347/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.0686 - mae: 1.9624 - val_loss: 16.1366 - val_mae: 3.2164\n",
            "Epoch 348/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.4575 - mae: 2.0564 - val_loss: 16.8262 - val_mae: 3.2151\n",
            "Epoch 349/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.6331 - mae: 2.1370 - val_loss: 9.1487 - val_mae: 2.2033\n",
            "Epoch 350/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.4243 - mae: 2.1564 - val_loss: 9.9229 - val_mae: 2.3263\n",
            "Epoch 351/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 9.2028 - mae: 2.1660 - val_loss: 12.1059 - val_mae: 2.6848\n",
            "Epoch 352/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.5700 - mae: 1.9505 - val_loss: 8.8707 - val_mae: 2.2780\n",
            "Epoch 353/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.5547 - mae: 2.0114 - val_loss: 16.4374 - val_mae: 3.2736\n",
            "Epoch 354/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.3320 - mae: 2.0493 - val_loss: 13.0571 - val_mae: 2.7813\n",
            "Epoch 355/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.4196 - mae: 2.0735 - val_loss: 14.5320 - val_mae: 3.0101\n",
            "Epoch 356/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.2568 - mae: 2.1757 - val_loss: 17.7600 - val_mae: 3.3848\n",
            "Epoch 357/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.8016 - mae: 2.0810 - val_loss: 9.7206 - val_mae: 2.2966\n",
            "Epoch 358/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.1005 - mae: 1.9943 - val_loss: 22.5963 - val_mae: 3.9363\n",
            "Epoch 359/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.9477 - mae: 2.0832 - val_loss: 11.0220 - val_mae: 2.5405\n",
            "Epoch 360/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.0488 - mae: 2.1320 - val_loss: 11.2710 - val_mae: 2.5039\n",
            "Epoch 361/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.0088 - mae: 1.9428 - val_loss: 11.7261 - val_mae: 2.6427\n",
            "Epoch 362/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.2955 - mae: 2.0622 - val_loss: 9.7017 - val_mae: 2.3661\n",
            "Epoch 363/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.1025 - mae: 1.9891 - val_loss: 12.6789 - val_mae: 2.6803\n",
            "Epoch 364/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.5828 - mae: 2.1007 - val_loss: 12.8722 - val_mae: 2.8091\n",
            "Epoch 365/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.3568 - mae: 2.0267 - val_loss: 9.0375 - val_mae: 2.2458\n",
            "Epoch 366/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.5241 - mae: 1.8834 - val_loss: 10.7149 - val_mae: 2.4730\n",
            "Epoch 367/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.4064 - mae: 2.1612 - val_loss: 9.4330 - val_mae: 2.2610\n",
            "Epoch 368/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.9724 - mae: 1.9757 - val_loss: 20.1915 - val_mae: 3.6518\n",
            "Epoch 369/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.9527 - mae: 2.2577 - val_loss: 9.6089 - val_mae: 2.3582\n",
            "Epoch 370/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.2598 - mae: 2.1193 - val_loss: 11.3262 - val_mae: 2.6488\n",
            "Epoch 371/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.7584 - mae: 2.0170 - val_loss: 8.7535 - val_mae: 2.2476\n",
            "Epoch 372/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.6382 - mae: 1.8879 - val_loss: 12.2063 - val_mae: 2.6674\n",
            "Epoch 373/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.8289 - mae: 2.0449 - val_loss: 8.2813 - val_mae: 2.2029\n",
            "Epoch 374/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.2039 - mae: 2.0652 - val_loss: 21.2675 - val_mae: 3.8801\n",
            "Epoch 375/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.4723 - mae: 2.0154 - val_loss: 10.3869 - val_mae: 2.3967\n",
            "Epoch 376/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.6885 - mae: 1.8806 - val_loss: 9.2338 - val_mae: 2.2678\n",
            "Epoch 377/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.5634 - mae: 2.1428 - val_loss: 11.6001 - val_mae: 2.5584\n",
            "Epoch 378/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.4827 - mae: 2.1168 - val_loss: 10.1267 - val_mae: 2.4148\n",
            "Epoch 379/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.7670 - mae: 1.9394 - val_loss: 11.3050 - val_mae: 2.5721\n",
            "Epoch 380/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 7.6779 - mae: 1.9936 - val_loss: 16.5144 - val_mae: 3.2431\n",
            "Epoch 381/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.3448 - mae: 2.0874 - val_loss: 10.0826 - val_mae: 2.3290\n",
            "Epoch 382/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.8406 - mae: 2.0777 - val_loss: 13.8004 - val_mae: 2.9238\n",
            "Epoch 383/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.0966 - mae: 1.9828 - val_loss: 9.2570 - val_mae: 2.3272\n",
            "Epoch 384/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.4779 - mae: 1.9415 - val_loss: 12.7293 - val_mae: 2.7219\n",
            "Epoch 385/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.2280 - mae: 2.0020 - val_loss: 13.7418 - val_mae: 3.0041\n",
            "Epoch 386/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.9893 - mae: 1.9322 - val_loss: 11.0248 - val_mae: 2.5577\n",
            "Epoch 387/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.9670 - mae: 1.9643 - val_loss: 14.0687 - val_mae: 2.9392\n",
            "Epoch 388/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.3869 - mae: 2.0546 - val_loss: 10.1327 - val_mae: 2.4474\n",
            "Epoch 389/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.2948 - mae: 1.9470 - val_loss: 8.9726 - val_mae: 2.2959\n",
            "Epoch 390/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.4420 - mae: 1.9144 - val_loss: 12.4691 - val_mae: 2.7761\n",
            "Epoch 391/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.1976 - mae: 2.0011 - val_loss: 10.5446 - val_mae: 2.5083\n",
            "Epoch 392/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.8002 - mae: 1.9126 - val_loss: 8.6201 - val_mae: 2.2019\n",
            "Epoch 393/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.6542 - mae: 2.0857 - val_loss: 8.8160 - val_mae: 2.2278\n",
            "Epoch 394/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.8237 - mae: 1.9254 - val_loss: 15.6934 - val_mae: 3.0031\n",
            "Epoch 395/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.5021 - mae: 1.8961 - val_loss: 17.5132 - val_mae: 3.3484\n",
            "Epoch 396/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 8.3315 - mae: 2.0758 - val_loss: 10.2818 - val_mae: 2.5183\n",
            "Epoch 397/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.8834 - mae: 2.1078 - val_loss: 9.0082 - val_mae: 2.2449\n",
            "Epoch 398/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.7055 - mae: 2.0190 - val_loss: 14.1008 - val_mae: 3.0163\n",
            "Epoch 399/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.4053 - mae: 1.9106 - val_loss: 8.7212 - val_mae: 2.2178\n",
            "Epoch 400/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.2424 - mae: 2.0479 - val_loss: 10.4031 - val_mae: 2.4446\n",
            "Epoch 401/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.5936 - mae: 1.7478 - val_loss: 24.2844 - val_mae: 4.0745\n",
            "Epoch 402/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.3446 - mae: 2.0818 - val_loss: 12.0996 - val_mae: 2.6886\n",
            "Epoch 403/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.9170 - mae: 1.9744 - val_loss: 9.5607 - val_mae: 2.2927\n",
            "Epoch 404/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.4703 - mae: 1.8901 - val_loss: 30.4927 - val_mae: 4.7216\n",
            "Epoch 405/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.8280 - mae: 2.1507 - val_loss: 12.1989 - val_mae: 2.7136\n",
            "Epoch 406/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.4813 - mae: 1.9196 - val_loss: 8.9824 - val_mae: 2.2073\n",
            "Epoch 407/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.0143 - mae: 1.8686 - val_loss: 12.4119 - val_mae: 2.7185\n",
            "Epoch 408/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.4970 - mae: 1.9650 - val_loss: 8.9217 - val_mae: 2.3225\n",
            "Epoch 409/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 8.3590 - mae: 2.0933 - val_loss: 9.3802 - val_mae: 2.2787\n",
            "Epoch 410/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.5572 - mae: 1.7363 - val_loss: 9.2163 - val_mae: 2.2762\n",
            "Epoch 411/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.6777 - mae: 1.9114 - val_loss: 9.1320 - val_mae: 2.2869\n",
            "Epoch 412/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.5518 - mae: 1.9489 - val_loss: 10.8408 - val_mae: 2.5355\n",
            "Epoch 413/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.7733 - mae: 1.8812 - val_loss: 9.0232 - val_mae: 2.2713\n",
            "Epoch 414/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.4521 - mae: 1.8765 - val_loss: 13.3400 - val_mae: 2.8981\n",
            "Epoch 415/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.6223 - mae: 2.1085 - val_loss: 29.0059 - val_mae: 4.4771\n",
            "Epoch 416/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.8906 - mae: 1.9632 - val_loss: 18.8963 - val_mae: 3.5487\n",
            "Epoch 417/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.1811 - mae: 2.1568 - val_loss: 14.7773 - val_mae: 2.9917\n",
            "Epoch 418/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.5852 - mae: 1.8856 - val_loss: 9.7822 - val_mae: 2.2975\n",
            "Epoch 419/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.5050 - mae: 2.0444 - val_loss: 11.8087 - val_mae: 2.6556\n",
            "Epoch 420/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.3384 - mae: 1.9089 - val_loss: 9.0712 - val_mae: 2.2927\n",
            "Epoch 421/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.8815 - mae: 1.7875 - val_loss: 8.7210 - val_mae: 2.2459\n",
            "Epoch 422/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 7.0587 - mae: 2.0298 - val_loss: 9.3640 - val_mae: 2.3266\n",
            "Epoch 423/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.8101 - mae: 1.7678 - val_loss: 8.4984 - val_mae: 2.1853\n",
            "Epoch 424/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.4123 - mae: 1.8365 - val_loss: 8.9620 - val_mae: 2.1865\n",
            "Epoch 425/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.4698 - mae: 2.0260 - val_loss: 8.7745 - val_mae: 2.1883\n",
            "Epoch 426/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.3176 - mae: 1.8679 - val_loss: 8.7930 - val_mae: 2.2255\n",
            "Epoch 427/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.9239 - mae: 1.9127 - val_loss: 17.3153 - val_mae: 3.4571\n",
            "Epoch 428/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.9080 - mae: 1.9437 - val_loss: 11.2814 - val_mae: 2.5696\n",
            "Epoch 429/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.4552 - mae: 1.9698 - val_loss: 8.6230 - val_mae: 2.2177\n",
            "Epoch 430/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.2359 - mae: 1.7325 - val_loss: 8.6715 - val_mae: 2.2103\n",
            "Epoch 431/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.1811 - mae: 1.9816 - val_loss: 20.1879 - val_mae: 3.6301\n",
            "Epoch 432/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.9703 - mae: 1.9634 - val_loss: 12.5034 - val_mae: 2.7514\n",
            "Epoch 433/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.7136 - mae: 1.9381 - val_loss: 10.6625 - val_mae: 2.5770\n",
            "Epoch 434/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.4730 - mae: 2.0110 - val_loss: 11.4359 - val_mae: 2.6062\n",
            "Epoch 435/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.9998 - mae: 1.8987 - val_loss: 13.4280 - val_mae: 2.9727\n",
            "Epoch 436/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.3382 - mae: 1.9141 - val_loss: 15.4695 - val_mae: 3.1897\n",
            "Epoch 437/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.8854 - mae: 1.9387 - val_loss: 8.7923 - val_mae: 2.2232\n",
            "Epoch 438/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.3688 - mae: 1.8392 - val_loss: 8.5237 - val_mae: 2.2166\n",
            "Epoch 439/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.5191 - mae: 1.8853 - val_loss: 10.9998 - val_mae: 2.5537\n",
            "Epoch 440/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.9093 - mae: 1.9869 - val_loss: 8.6356 - val_mae: 2.2085\n",
            "Epoch 441/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.9343 - mae: 1.9202 - val_loss: 10.9585 - val_mae: 2.5729\n",
            "Epoch 442/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.6010 - mae: 1.9532 - val_loss: 8.4302 - val_mae: 2.2152\n",
            "Epoch 443/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 6.4010 - mae: 1.8868 - val_loss: 9.2963 - val_mae: 2.3480\n",
            "Epoch 444/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8.3359 - mae: 2.1301 - val_loss: 11.4112 - val_mae: 2.6998\n",
            "Epoch 445/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.9635 - mae: 1.9401 - val_loss: 9.8246 - val_mae: 2.4060\n",
            "Epoch 446/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.7629 - mae: 1.9155 - val_loss: 12.8237 - val_mae: 2.8375\n",
            "Epoch 447/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.2623 - mae: 1.8921 - val_loss: 8.4857 - val_mae: 2.1920\n",
            "Epoch 448/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.0190 - mae: 1.8955 - val_loss: 17.0708 - val_mae: 3.3840\n",
            "Epoch 449/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.4352 - mae: 2.0715 - val_loss: 11.8508 - val_mae: 2.7004\n",
            "Epoch 450/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.3310 - mae: 1.9766 - val_loss: 9.6355 - val_mae: 2.2418\n",
            "Epoch 451/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.5576 - mae: 1.7761 - val_loss: 9.1031 - val_mae: 2.2804\n",
            "Epoch 452/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.3125 - mae: 1.8510 - val_loss: 9.1972 - val_mae: 2.2259\n",
            "Epoch 453/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 7.1694 - mae: 1.9522 - val_loss: 8.8122 - val_mae: 2.2677\n",
            "Epoch 454/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.3379 - mae: 1.8339 - val_loss: 8.8469 - val_mae: 2.2955\n",
            "Epoch 455/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.4101 - mae: 1.8120 - val_loss: 13.7039 - val_mae: 2.9368\n",
            "Epoch 456/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.3946 - mae: 1.9666 - val_loss: 11.0844 - val_mae: 2.6038\n",
            "Epoch 457/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.1962 - mae: 1.9052 - val_loss: 9.7554 - val_mae: 2.3629\n",
            "Epoch 458/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.0821 - mae: 1.7919 - val_loss: 12.3184 - val_mae: 2.7140\n",
            "Epoch 459/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.0537 - mae: 1.8510 - val_loss: 11.7765 - val_mae: 2.6346\n",
            "Epoch 460/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.6126 - mae: 1.9994 - val_loss: 9.4348 - val_mae: 2.2204\n",
            "Epoch 461/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.0614 - mae: 1.8469 - val_loss: 9.8045 - val_mae: 2.3561\n",
            "Epoch 462/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.8236 - mae: 1.9331 - val_loss: 12.4775 - val_mae: 2.6654\n",
            "Epoch 463/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.2336 - mae: 1.8061 - val_loss: 12.9422 - val_mae: 2.7727\n",
            "Epoch 464/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.2585 - mae: 1.9008 - val_loss: 17.0849 - val_mae: 3.3852\n",
            "Epoch 465/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.8929 - mae: 1.8945 - val_loss: 17.3595 - val_mae: 3.2382\n",
            "Epoch 466/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 6.8009 - mae: 1.9173 - val_loss: 11.7716 - val_mae: 2.6141\n",
            "Epoch 467/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.7961 - mae: 1.8700 - val_loss: 8.8042 - val_mae: 2.2378\n",
            "Epoch 468/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.8088 - mae: 1.8332 - val_loss: 16.8706 - val_mae: 3.0407\n",
            "Epoch 469/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.2575 - mae: 1.8572 - val_loss: 9.2670 - val_mae: 2.2849\n",
            "Epoch 470/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.5018 - mae: 1.6997 - val_loss: 8.9268 - val_mae: 2.2464\n",
            "Epoch 471/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.1519 - mae: 1.9585 - val_loss: 12.4402 - val_mae: 2.8245\n",
            "Epoch 472/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.6356 - mae: 1.8636 - val_loss: 10.5438 - val_mae: 2.4236\n",
            "Epoch 473/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.5568 - mae: 1.8828 - val_loss: 12.1651 - val_mae: 2.5617\n",
            "Epoch 474/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.6147 - mae: 1.9387 - val_loss: 9.5423 - val_mae: 2.3298\n",
            "Epoch 475/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.9371 - mae: 1.8664 - val_loss: 11.9753 - val_mae: 2.7227\n",
            "Epoch 476/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.4490 - mae: 2.1152 - val_loss: 11.4213 - val_mae: 2.5667\n",
            "Epoch 477/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.1705 - mae: 1.7392 - val_loss: 15.8310 - val_mae: 3.0168\n",
            "Epoch 478/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.6014 - mae: 2.0016 - val_loss: 22.1474 - val_mae: 3.8798\n",
            "Epoch 479/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.2360 - mae: 1.9251 - val_loss: 9.3345 - val_mae: 2.3575\n",
            "Epoch 480/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.6847 - mae: 1.7286 - val_loss: 14.5203 - val_mae: 2.9473\n",
            "Epoch 481/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.1767 - mae: 1.9293 - val_loss: 9.2969 - val_mae: 2.3128\n",
            "Epoch 482/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.2158 - mae: 1.8913 - val_loss: 10.9609 - val_mae: 2.4617\n",
            "Epoch 483/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.9846 - mae: 1.8455 - val_loss: 9.8740 - val_mae: 2.3820\n",
            "Epoch 484/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.3186 - mae: 1.9099 - val_loss: 17.2148 - val_mae: 3.1694\n",
            "Epoch 485/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.2452 - mae: 1.9004 - val_loss: 9.3081 - val_mae: 2.2298\n",
            "Epoch 486/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.7445 - mae: 1.8356 - val_loss: 12.9249 - val_mae: 2.7783\n",
            "Epoch 487/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.6724 - mae: 1.7560 - val_loss: 9.8164 - val_mae: 2.4117\n",
            "Epoch 488/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.1882 - mae: 1.7269 - val_loss: 8.9005 - val_mae: 2.2372\n",
            "Epoch 489/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.0022 - mae: 1.9979 - val_loss: 12.4610 - val_mae: 2.7975\n",
            "Epoch 490/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.8569 - mae: 1.7642 - val_loss: 8.7382 - val_mae: 2.2889\n",
            "Epoch 491/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.7442 - mae: 1.7118 - val_loss: 8.4483 - val_mae: 2.1858\n",
            "Epoch 492/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.3816 - mae: 1.8747 - val_loss: 14.8475 - val_mae: 2.8544\n",
            "Epoch 493/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.1868 - mae: 1.8536 - val_loss: 10.8409 - val_mae: 2.4640\n",
            "Epoch 494/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.0128 - mae: 1.7936 - val_loss: 10.4911 - val_mae: 2.5468\n",
            "Epoch 495/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6.3619 - mae: 1.8656 - val_loss: 9.2207 - val_mae: 2.3313\n",
            "Epoch 496/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.9128 - mae: 1.8481 - val_loss: 16.8064 - val_mae: 3.3197\n",
            "Epoch 497/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 5.9327 - mae: 1.8287 - val_loss: 9.0995 - val_mae: 2.2008\n",
            "Epoch 498/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 5.4743 - mae: 1.8157 - val_loss: 8.3549 - val_mae: 2.1511\n",
            "Epoch 499/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7.3922 - mae: 2.0311 - val_loss: 8.8185 - val_mae: 2.2192\n",
            "Epoch 500/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5.1903 - mae: 1.6192 - val_loss: 8.9876 - val_mae: 2.2174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfSSQAsHUMyU"
      },
      "source": [
        "Visualize the model's training progress using the stats stored in the `history` object. We want to use this data to determine how long to train *before* the model stops making progress."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Ankh1GqBUSW7",
        "outputId": "c26b32d1-76a0-4a47-8faf-e36dae4c2db2"
      },
      "source": [
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGgdxha-UcEJ"
      },
      "source": [
        "The graph shows the average error **in Validation set** is about $2,400 dollars. Is this good? \n",
        "\n",
        "Well, \\$2,400 is not an insignificant amount when some of the labels are only $15,000.\n",
        "\n",
        "Let's see how did the model performs on the **Test set**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bD8boyEO-Y0",
        "outputId": "8f20c450-b513-4503-f363-50ae6d74bb6c"
      },
      "source": [
        "[loss, mae] = model_conv1D.evaluate(test_data_reshaped, test_labels, verbose=0)\n",
        "print(\"Testing set Mean Abs Error: ${:7.2f}\".format(mae * 1000))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing set Mean Abs Error: $2575.76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR5-DaUvUuMC"
      },
      "source": [
        "## Predict\n",
        "\n",
        "Finally, predict some housing prices using data in the testing set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "qC9sHFzIedd4",
        "outputId": "5ab28426-e865-4638-c383-704c9169aa42"
      },
      "source": [
        "test_predictions = model_conv1D.predict(test_data_reshaped).flatten()\n",
        "plot_prediction(test_labels, test_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5xddXnv8c8zF4aBJA6YkBMGQoLQECmSaIrQUI6gEsVbREWpnMYeBE+rVZQTSWpbwFoJxqK2p4cW0ILHFlIBAyI1IAn4EguSmHAJYQS5KENComQkwhjm8pw/1tqTPXvW2mvtPXvt6/f9eu3X7L327Zm8dp79m996fs/P3B0REWkdbbUOQEREqkuJX0SkxSjxi4i0GCV+EZEWo8QvItJiOmodQBrTp0/3OXPm1DoMEWlCvxsa5clf/RYDjpwxha6O5hkPb9q06VfuPqPweEMk/jlz5rBx48ZahyEiTaZvxx7Ovvo+jms3bjj/JOZOP7DWIVWUmT0Tdbx5vtpEREqQS/qdTZr0i1HiF5GW08pJH5T4RaTFtHrSByV+EWkhSvoBJX4RaQlK+vs0RFWPiEhaazf3s3pdH88NDHJoTzfLl8xj/qxpSvp5lPhFpGms3dzPypsfZnBoBID+gUEuuukhOtqNKV0dSvqhTBO/mT0N7AFGgGF3X2RmBwNrgDnA08BZ7r47yzhEpDWsXtc3lvRz9g6PMjQCt/3FHynph6oxx3+quy9w90Xh7RXAXe5+NHBXeFtEZNKeGxiMPD7qKOnnqcXJ3fcA14XXrwOW1iAGEWlCh/Z0Rx7vjTneqrJO/A7cYWabzOz88NhMd98eXt8BzIx6opmdb2YbzWzjrl27Mg5TRJrB8iXzJvTa6e5sZ/mSeTWKqD5lfXL3ZHfvN7NDgDvN7LH8O93dzSxy70d3vwq4CmDRokXaH1JEEs2fNY2OdmNoJJje6Q2repYu7K11aHUl08Tv7v3hz51m9h3gBOB5M5vl7tvNbBawM8sYRKQ15Or0p3R16ERugsymeszsQDObmrsOnA48AtwKLAsftgy4JasYRKQ1aHFWabIc8c8EvmNmuff5d3f/vpk9APyHmZ0LPAOclWEMItLklPRLl1nid/cngeMjjv8aeHNW7ysirSMq6Uet3NUc/3hauSsiDSku6Reu3F1588MASv551KRNRBpO3PRO1MrdwaERVq/rq0WYdUuJX0QaSrE5/biVu3HHW5USv4g0jKQTuXErd+OOtyolfhFpCGmqd5YvmUd3Z/u4Y1q5O5FO7opI3Utbspk7gauqnuKU+EWkrpVap790Ya8SfQJN9YhI3dLirGwo8YtIXVLSz44Sv4jUHSX9bCnxi0hdUdLPnhK/iNQNJf3qUOIXkbqgpF89SvwiUnNK+tWlxC8iNaWkX31K/CJSM0r6taHELyI1oaRfO0r8IlJ1Svq1pcQvIlWlpF97SvwiUjVK+vVBiV9EqkJJv34o8YtI5pT064sSv4hkSkm//ijxi0hmlPTrkxK/iGRCSb9+KfGLSMUp6dc3JX4RqSgl/fqnxC8iFaOk3xiU+EWkIpT0G4cSv4hMmpJ+Y1HiF5FJUdJvPEr8IlI2Jf3GpMQvImVR0m9cSvwiUjIl/cbWUesARKSxFEv6azf3s3pdH88NDHJoTzfLl8xj6cLeGkYrUZT4RSS1pKS/8uaHGRwaAaB/YJCVNz8MUNXkry+fZJrqEZFUkqZ3Vq/rG0v6OYNDI6xe11e1GHNfPv0Dgzj7vnzWbu6vWgyNIPPEb2btZrbZzG4Lb881s/vN7AkzW2Nm+2Udg4hMTpo5/ecGBiOfG3e8mLWb+1m8aj1zV3yPxavWp07c9fDl0wiqMeL/FLAt7/blwFfc/ShgN3BuFWIQkTKlPZF7aE93ScfjTGbUXskvn2aWaeI3s8OAdwDXhLcNOA24MXzIdcDSLGMQkfKVUr2zfMk8ujvbxx3r7mxn+ZJ5Jb3nZEbtlfryaXZZj/i/CnwWGA1vvxoYcPfh8PazgM66iNShUks2ly7s5bIzj6O3pxsDenu6uezM40o+sTqZUXulvnyaXWaJ38zeCex0901lPv98M9toZht37dpV4ehEpJhy6/SXLuxl+ZJ5HNrTzXMDg6xe11fyidXJjNor9eXT7LIs51wMvNvMzgD2B6YBXwN6zKwjHPUfBkR+Ktz9KuAqgEWLFnmGcYpInskszqpESefyJfPGvQaUNmpfurBXiT5BZiN+d1/p7oe5+xzgQ8B6d/8wsAF4f/iwZcAtWcUgIqWZ7IrcSlTVaNSevVos4LoIuMHMvgBsBr5egxhEpEAl2jBUqqpGo/ZsFU38ZvZQitfY5e5vLvYAd78buDu8/iRwQsr4RKQKKtV759CebvojkryqaupL0oi/HTijyP0G3Fq5cESk2irZcG2y8/NSHUmJ/2Pu/kyxB5jZn1cwHhGpokp32cxNz6hXTn0z9/ovmFm0aJFv3Lix1mGINBW1Vm5+ZrbJ3RcVHk+s6jGzU8MVuJjZEWb2AzO7z8xOySJQEcmekn5rS1POuQr4TXj9iwTtFj5FsCpXRBqMkr4kVfVcDBwOfDrss7MEeBKYCUw3s78B7nb3H2YeqUiCVuzDXurvrKQvkJD43f1SM3s7waKrQ4Afu/tfA5jZ6e7++SrEKJKoXjYBqaZSf2clfclJM9VzIfBlgumdzwKY2bHAlgzjEilJK/Zhj/udL/3u1gmPVdKXfImJ393vdfc3uvsp7v5YeGyru388+/BE0mnFPuxxv9vul4fGNUZT0pdCaap6jjGzi8zsH8LLRWY2vxrBiaTVin3Yi/1uub90lPQlStHEb2YXATcQrND9SXgx4HozW5F9eCLptGIf9mK/23MDg0r6EqvoAi4z+xlwrLsPFRzfD9jq7kdnHB+gBVySTitW9Sy49A4GBocmHD9kahfDo66k3+LiFnAltWwYBQ4FCts2zGLfrloidaEVOzpe8u5jJ/TG6epo46VXhpnS1aGkL5GSEv8FwF1m9jjwy/DYbOAo4BNZBiYiyQp748yY2qWkL4kSe/WYWRtBG+XcUKofeMDdR+KfVVma6hFJpjl9KVR2rx7AIy6a5hGpI7mkPzLq4HDal+9m8ar1Je93K60hqWXD6cD/BR5n3964hwFHmdmfu/sdGccnIgnyk/7vhkb4TXiytxVWL0t5kub4vwa8xd2fzj9oZnOB2wHV84vUUP70TmebjSX9nNzqZSV+yZeU+DuAZyOO9wOdlQ9HRNK6csMTrL6jj1EP5mzj5l+befWylCcp8X8DeMDMbmBfVc/hwIfQJukiNXPlhie4PK8PUbGTbs28elnKk9Sd8zIzuwV4N3BSeLgf+LC7P5p1cCIyUd+OPay+I13zuWZfvSzlSRrxEyb4R83s4PD2C5lHJSKRcnP6oyl2TO1tkdXLUrqkqp7ZwJeA0wh24TIzmwasB1YUnvQVkezkn8idObWL5/fsjX1sb0839644rYrRSSNJquNfA3wHmOXuR7v7UQTtGtYSNG8TkSooXJy18oz5E5rS5Wh6R5IkTfVMd/c1+QfCFbs3mNnfZheWSGuKajQ3f9a0CStyc6tyV6/ro39gkHYzRtw1vSOpJHXnvAF4AbiO8VU9ywi+FM7KPELUskFaQ+FWivkM+Msz5nPeKUdWPzBpWOV25/wT4FzgUvb16nkW+C4q55QWUa12z1FbKeY48KXvP8aMqV0azcukJZVzvgJcGV5EGkolEnY1N3FPWmg1NOpahSsVkaZJWyQz+5tKBiJSSbmE3T8wiLMvYZfatKyam7inWWilVbhSCWUnfuCjFYtCpMIqlbCruYn78iXz6Ooo/l9Sq3ClEpLq+F+MuwvQJ1DqVqUS9qE93fRHPCeLBDx/1jQ62o1XRiCq5qKzzVSmKRWRNOIfAI5292kFl6nA9irEJ1KWuMRcasKu1ibuuTr9KV0drL/wTXz1gws46IB9fRB7ujtZ/YHjNb8vFZFU1fNN4Ajg+Yj7/r3y4YhUxvIl8yaURpaTsAu3Nsyiqidq56y50w9UkpfMJG69WA9Uxy/lqFYZ5mRou0TJUll1/Gb239x9x2QfI1ILSxf21l2iz6ekL7WSNMd/e4rXSPMYEcmjpC+1lDTHf3yRyh4IqnuK3S/SdCY7haSkL7WWtHI3uv2fSIua7EpeJX2pB5NZwFWUme1vZj8xswfNbKuZXRoen2tm95vZE2a2xsz2yyoGkUqbzMIwJX2pF5klfmAvcJq7Hw8sAN5mZicClwNfCXv77yZoAifSEMpdGKakL/Uks8Tvgd+GNzvDixPs5nVjePw6YGlWMYhU0trN/bSZRd5XbGGYkr7Um1SJ38xeY2Zd4fU3mdknzawnxfPazWwLsBO4E/g5MODuw+FDnmVfu+fC555vZhvNbOOuXbvShCmSmdzc/kjEupdiC8OU9KUepR3x3wSMmNlRwFUEm7Ekrtx19xF3XwAcBpwAHJM2MHe/yt0XufuiGTNmpH2atKi1m/tZvGo9c1d8j8Wr1pfchTNJXK/8djMuO/O4yBO7SvpSr5LKOXNG3X3YzN4L/KO7/6OZbU77Ju4+YGYbgJOAHjPrCEf9hwGV/R8qLacaPfPj5vBH3ZX0peGkTfxDZnY2wZaL7wqPdRZ5PGY2AxgKk3438FaCE7sbgPcTbNa+DLilnMClNaSpmS9WaVOpxF+sS2dhjOe8cTZX/+ipokm/EdpJSPNKO9XzpwSj9b9z96fMbC7w/xKeMwvYYGYPAQ8Ad7r7bcBFwGfM7Ang1WgLR4mRdjOVavTMj+vSeeoxMybEePm6PkZGvWjSr8QmMSLlSjXid/dHgU/m3X6KYPRe7DkPAQsjjj9JMN8vUlTakXw1eubHdemMm/vfv6MtdnqnGn+hiBSTKvGb2WLgEoIWzR0ErRrc3Y/MLjRpdWlH8pVqwZwkqunbp9dsiXzszj17Y1+nmrt6iURJO8f/deDTwCZg4vBGJANpR/K5ZHzJrVsZGBwCYP/OLNcmjo+l1L82qrmrl0iUtP87fuPu/+nuO93917lLppFJyyt196u9w6Nj13e/PFSxefNipaILZ78q8jmnHhNfglytXb1E4qQd8W8ws9XAzQStGABw959mEpUIpe1+ldW8ebFS0fmzpnH7w9FbUWx4LH7RYTV29RIpJm3if2P4M38nl1z7BZHMpNlMZe3m/sipE5j8vHncF8oXb9/G8KgzGrOB3XMDg0VLNut9kxhpbmmrek7NOhCRcuRG5HEmO28e98Wxc89eZk7rYubULp6POJH7qu7OshaVqb5fqiFtr55XmdkVud45Zvb3ZhY9uSlSRXHllFCZefO4L442gxvOP4mVZ8yPnK83I/IvhQv/48HY8w6q75dqSXty9xvAHuCs8PIi8K9ZBSWSVrGpnLgeOqWIOhELsPLt85k7/UCWLuzlsjOPo7enGwN6e7q57MzjGHh5KPL1Rtxjk/lkev2LlCLtHP9r3P19ebcvDbtuitRUXGlkb093RaZIcq/xxdu3sXPPXtosSPrnnXLkuMdEtZGIO+8Qd9JZ9f1SLWlH/INmdnLuRrigS59GqblqlEbOnzWN4VFn5rQu7rrwTeOSfilx5YtK5nHTSqrvl0pLO+L/M+C6cF7fgBeAj2QVlEha5ZRGlnICtdwum0sX9rLxmRf41n2/iLw/KplXawWySNqqni3A8WY2Lbz9YqZRiZSglNLIUlo4T6a18trN/dy0KfqkbFwyV32/VEvRxG9m57j7t8zsMwXHAXD3KzKMTaTi0i70mmw//XI2bgHV90t1JI34c5/2qRH3xSxdEalfaU6g5if9j558JOdcc3/JI/BSN24Rqaaiid/d/yW8+gN3vzf/vvAEr0hDSWqQVpj0r7jzZ2Xt7KVGbFLP0lb1/GPKYyJ1LaraxgiaqhVO71z746fLrqtXIzapZ0lz/CcBfwjMKJjnnwbE16qJZKzc1ga5apt/u+8XY3OVDnzrvl/wrft+MVanP3f6gammheLi0IlaqWdJc/z7AVPCx+XP879IsG+uSNVNdnP1DY/tij1BNepwxZ0/Y8bUrsTpmqQ4dKJW6lXSHP89wD1mdq27P1OlmEQi5UbXUcm4lBbMSSthc6+VVFevLRSlUaWd47/GzHpyN8zsIDNbl1FMIhPkNzCLk7a1QZoTrM8NDMb24ckldbVYkEaVduXudHcfyN1w991mdkhGMYlMUKwLZ86hPd2p5v6XL5nHBTF75ea/FhSvq1fljjSqtCP+UTObnbthZkegOn6poqRRdHdnO6ceMyNVW+P5s6Ylvlaa6htV7kijSjvi/xzwIzO7h6D67Y+A8zOLSqRA3OgagimY5Uvmxc65f3rNFi5Ys4V2M0bcaTMwA48YuiStrM2nyh1pVOZRn/6oB5pNB04Mb97n7r/KLKoCixYt8o0bN1br7aQOFVbQQDC6zk/Sc1d8L/WfoR0G1mYMjex7RuHriTQ6M9vk7osKjxed6jGzY8KfrwdmA8+Fl9nhMZGqSDrRCqXNrQ87HLhfR9HXE2lWRUf8Zna1u59nZhsi7nZ3r8pm6xrxSxprN/cnnrTNZ8BTq96hfW6lacWN+JPq+M8Lf2qzdalb+Ym7zYJFWGnkqoAmsxhMpBEltWw4s9j97n5zZcMRKU1h4k55ymqs+kaLsKQVJVX1vCv8eQhBz5714e1TgR8DSvySuWJTMXH1/W3AKEH1zpT9Otizd3isqqc37zU+HTM1pEVY0sySpnr+FMDM7gBe6+7bw9uzgGszj05aXtJUTGzfe2DmtK6im6is3dxPW/hlUEiLsKSZpa3jPzyX9EPPE1T5iGQqaSomrr6/zeCjJx/Je//pXgYGhwA46IBOLn7XsSxd2Dv2hRKV9LUIS5pd2sR/V9ib5/rw9geBH2QTksg+Sf1wli+Zx/JvP8hQwRndd75uFl/6/mPjju9+eYgL1mxh4zMvcNuD28vaGlGkGaTdbP0TZvZe4JTw0FXu/p3swhIJpOqHY+Pv62iDH/7sVxO+DHK+dd8vYt+v0lsjqlRU6lHaXj0APwW+5+6fBtaZWdQ+vCIVldQPZ/W6vnGrbwGGRxmb3ilVm9mE3j7lyu8oWqx3kEi1pUr8ZnYecCOQ24O3F1ibVVAiObkVuz3dnWPH9u/c97Et1qa5HCPuFUvOxc5PiNRS2jn+jwMnAPcDuPvjasssWVi7uZ9Lv7uV3S8HI/ae7k7eefwsXnpleOwxu18eYvmND7K9xAVbaVWqjl/9+qVepZ3q2evur+RumFkHasssFbZ2cz/Lb3xwLOlDMGXzrft+MWE6Z2jEuXxdX1lJv7PN6Gy3oo+pRHKOKwlVqajUWtrEf4+Z/SXQbWZvBb4NfLfYE8zscDPbYGaPmtlWM/tUePxgM7vTzB4Pfx40uV9BmkXUfP1k9fZ089UPLhjXjG31B45n9fuPp7dIAq5Ecla/fqlXaad6LgI+CjwMfAy4Hbgm4TnDwIXu/tPwRPAmM7sT+Ahwl7uvMrMVwIrw9aXFVXoKpLPdxqpooqZt8uv54/bVnQz165d6lZj4zawd2OruxwBXp33hcMHX9vD6HjPbRnBS+D3Am8KHXQfcjRK/UHyzlbJE/PEQVV552ZnHZZaci23dKFIriYnf3UfMrM/MZrt7fAF0EWY2B1hIcHJ4Zt4q4B3AzJjnnE+4y9fs2Vok3AqWL5nH8hsfrNh0z9Coj1XQrF7XR//AIMa+74P+gUEuWLOFnu5OLnn3sUrQ0jJS7cBlZj8kSNw/AV7KHXf3d6d47hTgHuDv3P1mMxtw9568+3e7e9F5fvXjbx2l9tRPo7uzPXGjdu2+Jc2orH78ef66zDftBG4C/i2vhfPzZjbL3beHzd52lvPa0rzyR+WT1W6WmPRBrZiltSRtvbi/mV0AfAA4BrjX3e/JXRKea8DXgW3ufkXeXbcCy8Lry4Bbyo5ems6l390am/TPOXF20UqcQt2d7ZFN2OKovl5aRVI553XAIoJqnrcDf1/Cay8G/gdwmpltCS9nAKuAt5rZ48BbwtsirN3cP66Gv9AXlh7HvStOK2zNEynXbK2ULwrV10urSJrqea27HwdgZl8nmONPxd1/xIT2WWPenPZ1pHUUa2Vw0AGdLF61PlXVjwF/f9bxY9M2heWaUdKUcKrhmjSLpMQ/Nvxy9+Fg9kYkvVKSZbGplt/+brjoXwM5Bnz4xNlj7xFXSx91rFgS19680kyKVvWY2Qj7qngM6AZeDq+7u0/LPEJU1dOoohZHwfgNUfKd8Hc/YOeevWW/X2+Go/C4vzbazcb9dSFST8qq6nH39mL3ixQTtx/u7peHJoyW+3bsGdeILaezzWL76ucY8NSqd0w+4CLi/hrJdfMEjfylcZTSj1+kJMWmbvLbE/ft2MPZV9/HlK4OPnfG/HF9dabsn1xxXI2TssXeQ62WpdGkreMXKVlSC4bnBgbHkn5nu41tjH7eKUeOPWbuiu8VfY9qNT1bvmRe0ZPEKgWVRqIRv2QmqjtlvhlTuzjzynsZePkVnn9xL+dcc/+EDVCKjbR7e7qrtto2tyFMe0yBg0pBpZFoxC8Vl1/J86ruTgzn5aHRcY/p6mjjN4ND7B3edzyqUiZqpF2r9gpx5aFqtSyNRiN+qajCfWYHBodwbGzVrQGHTO2io90YGhmd8PzC+fLcSDt/3r+WPXXqLR6RcqRq0lZrKudsHHFlj7093dy74rRxc/rPvxhdulmNKh2RVhBXzqkRv1RUsX1mC0/kxrVTaDNj7orvsXjV+opsei4i4ynxS0XFneScMbVrQvVO3MnfEXecfXP+Sv4ilaXELxUVlcy7Otp46ZXhcUkfJs6XR9XLqEZepPJU1SOTVtiP531v6GXDY7t4bmCQGVO7eOmVYaZ0dYxL+oXP6zmgM7YXj2rkRSpLiV/KtnZzP5d+d+u4hN0/MMhNm/q57MzjmD9r2tiK3Kikn18WWawBm2rkRSpLiV/KEteADYLpmS/evo3hUZ8wvZMT18cnimrkRSpLiV9SKZzOeWnvcNHEvXPPXmZO64pM+pB++uagAzpVIy9SYUr8kiiqF32SNiM26UNyHx8IVsRe/K5jSw9YRIpSVY8kKmVaJmdKVwenffnu2Fr8qOqfznajp7tTK2JFMqYRvyQqp6rmxd8FvfXjdqqK2xlLiV4ke0r8kihuWuagAzp5cXCYkYS2H7la/MKkvnRhrxK9SA1oqkcmWLu5n8Wr1o+1TTj1mBl0to1fXtXZZlz8rmMTk36OavFF6odG/DJO1IncNT/5JRP6aBr8YNuO1K+rWnyR+qHE36AKyysrNT8edSI3as/boRHntofSJX71qxepL0r8DShqVF7Kht/FvjQmOyXTbsbZbzx8rGWDTtqK1B8l/gYUNSqPO4FaKOlLI019fTGj7nxh6XFlP19EsqeTuw0oblTePzA47qRsVP18sS8NiKmvbzM626P3mi2kuXyR+qfE34DikqvB2JaHcb3si22UAtFbC67+wPF85i2/R66wZ+bULs45cfaELwjN5Ys0Bk31NKCoDcgNKDwFGzX9EzeVk/9lUlhf37djD5+/7VFmTB3fe2fREQdrAZZIA1Lib0BRq17j5uULR/hRXxrFRuqF2yXm997RAiyRxqTE36AKk27cJueF00KltEoolvRFpHEp8TeJUkbyaUbqSvoizUuJv4EV2/JwMnPuSvoizU2Jv0FF1ePntjwsTPalrPJV0hdpfirnbFBJ9fg5uS+IpDJPUNIXaRVK/A0qqR4/J+0XhJK+SOtQ4m9QcYu4Co+n+YJQ0hdpLUr8DSqqtUJUFU/SF4SSvkjrUeJvUFGtFaJO7Bb7glDSF2lNmVX1mNk3gHcCO93998NjBwNrgDnA08BZ7r47qxiaXZp6/LgFW/NnTVPSF2lRWZZzXgv8H+CbecdWAHe5+yozWxHevijDGJpa2jLNwuT/xdu38dIrw0zp6lDSF2lBmU31uPsPgRcKDr8HuC68fh2wNKv3b3allGkWPnbnnr28tHeEj558pJK+SAuq9hz/THffHl7fAcyMe6CZnW9mG81s465du6oTXQNJW6YZ91iAa3/8dFbhiUgdq9nJXXd3JnYSzr//Kndf5O6LZsyYUcXIGkPaOv5ij81t3BL1V4KINK9qJ/7nzWwWQPhzZ5Xfv2mkreMHmDG1K/Z1ik0RiUhzqnbivxVYFl5fBtxS5fdvGmnr+Pt27OGlV4aLvlbcFJGINKfMEr+ZXQ/8FzDPzJ41s3OBVcBbzexx4C3hbSlDmjr+XJ3+lK4OPnfGfHqL7IcbNx0kIs0ns3JOdz875q43Z/WeraawTDM3al+6sDdycdZ5pxyZesMWEWleWrnbwOJKOq/c8ETs4qy0U0Qi0rzUj7+OJS3Qii3pvKNvwsboOaVsvSgizUmJv05FbbSy8uaHgX3JO25eftQpuiJXm6SLtDZN9dSpNAu04ublZ07t0opcEYmlxF+n0izQipqv7+poY+UZ8zONTUQamxJ/nUqzQGvpwl4+edpRtFlwe+bULi5/3+s0jSMiRWmOv04tXzJv3Bw/TKy+6duxh6t/9FTsiVwRkShK/HUqqfpGm6iISLmU+OtYXPWNkr6ITIbm+BuMkr6ITJYSfwNR0heRSlDibxBK+iJSKUr8DUBJX0QqSYm/zinpi0ilWbADYn0zs13AM7WOI8J04Fe1DqJMjRq74q6+Ro29UeOGysV+hLtP2Lu2IRJ/vTKzje6+qNZxlKNRY1fc1deosTdq3JB97JrqERFpMUr8IiItRol/cq6qdQCT0KixK+7qa9TYGzVuyDh2zfGLiLQYjfhFRFqMEr+ISItR4i+Tmb3NzPrM7AkzW1HreOKY2TfMbKeZPZJ37GAzu9PMHg9/HlTLGKOY2eFmtsHMHjWzrWb2qfB4I8S+v5n9xMweDGO/NDw+18zuDz8za8xsv1rHGsXM2s1ss5ndFt5ulLifNrOHzWyLmW0MjzXC56XHzG40s8fMbJuZnZR13Er8ZTCzduCfgLcDrwXONrPX1jaqWNcCbys4tgK4y92PBu4Kb9ebYeBCd38tcCLw8fDfuBFi3wuc5u7HAwuAt5nZicDlwFfc/ShgN3BuDWMs5lPAtrzbjRI3wKnuviCvBtsa16MAAAakSURBVL4RPi9fA77v7scAxxP822cbt7vrUuIFOAlYl3d7JbCy1nEViXcO8Eje7T5gVnh9FtBX6xhT/A63AG9ttNiBA4CfAm8kWInZEfUZqpcLcFiYaE4DbgOsEeIOY3samF5wrK4/L8CrgKcIC22qFbdG/OXpBX6Zd/vZ8FijmOnu28PrO4CZtQwmiZnNARYC99MgsYfTJVuAncCdwM+BAXcfDh9Sr5+ZrwKfBUbD26+mMeIGcOAOM9tkZueHx+r98zIX2AX8azi9do2ZHUjGcSvxtzgPhhR1W9NrZlOAm4AL3P3F/PvqOXZ3H3H3BQQj6BOAY2ocUiIzeyew09031TqWMp3s7q8nmIL9uJmdkn9nnX5eOoDXA1e6+0LgJQqmdbKIW4m/PP3A4Xm3DwuPNYrnzWwWQPhzZ43jiWRmnQRJ/9/c/ebwcEPEnuPuA8AGgimSHjPLbXdaj5+ZxcC7zexp4AaC6Z6vUf9xA+Du/eHPncB3CL5w6/3z8izwrLvfH96+keCLINO4lfjL8wBwdFjtsB/wIeDWGsdUiluBZeH1ZQTz53XFzAz4OrDN3a/Iu6sRYp9hZj3h9W6CcxPbCL4A3h8+rO5id/eV7n6Yu88h+Eyvd/cPU+dxA5jZgWY2NXcdOB14hDr/vLj7DuCXZjYvPPRm4FGyjrvWJzca9QKcAfyMYO72c7WOp0ic1wPbgSGC0cW5BPO2dwGPAz8ADq51nBFxn0zw5+1DwJbwckaDxP46YHMY+yPA34THjwR+AjwBfBvoqnWsRX6HNwG3NUrcYYwPhpetuf+TDfJ5WQBsDD8va4GDso5bLRtERFqMpnpERFqMEr+ISItR4hcRaTFK/CIiLUaJX0SkxSjxi4i0GCV+qQkze3XYPneLme0ws/6825Nu+2tmF5vZZQXHFpjZtiLPucTM/vdk37vI6+faBi8Kb38ibHXsZjY973FmZv8Q3veQmb0+775lYavex81sWd7xN4Sv/UT4XCv83Qpuvyb8t/5tVr+v1C8lfqkJd/+1B+1zFwD/TND2d0F4eSWvRUC5rgc+WHDsQ+HxWjrV3TeG1+8F3gI8U/CYtwNHh5fzgSsh6C0PXEzQ6fME4OK8Pu1XAuflPe9t4XNea2b3AP/LzH5qZmcDuPvPw397aUFK/FI3zOxaM/tnM7sf+FLhCNzMHgk7dWJm51iw2ckWM/uXcI+EMe7+M2C3mb0x7/BZwPVmdp6ZPWDBRik3mdkBEbHcnTcynx72r8l13VwdPv8hM/tYeHyWmf0wjOcRM/ujpN/X3Te7+9MRd70H+KYH7iPolTMLWALc6e4vuPtugq6fbwvvm+bu93mwIvObwNLwtS4BvkHw5bqYoN2ItDglfqk3hwF/6O6fiXuAmc0nGM0vDketI8CHIx56PcEon3AjlBfc/XHgZnf/Aw82StlGaRuLnAv8xt3/APgD4Dwzmwv8MUGf+gUEm2lsKeE1C8W1/S52/NmI4wCvANOBNncfdPcnJhGXNInJ/jktUmnfdveRhMe8GXgD8EA4ld1NdPfCNcCPzexCxk/z/L6ZfQHoAaYA60qI73TgdWaWa1r2KoKplQeAb4QdRde6+2QSfyVdBKwm+MtgIfBX7v5gjWOSGlPil3rzUt71Ycb/Vbp/+NOA69x9ZbEXcvdfmtlTwH8H3kfQGhmC7SiXuvuDZvYRgoZkhfLfe/+84wb8hbtP+LII+7+/A7jWzK5w928Wi6+IuLbf/QWxHgbcHR4/LOLxeNCq+I/N7PMEX043A68pMy5pEprqkXr2NEFvcsLKlrnh8buA95vZIeF9B5vZETGvcT3wFeBJd89Nh0wFtoej86gpotx7vyG8/v684+uAPwufi5n9XtgS+AjgeXe/GrgmF3eZbgX+JKzuOZFgaml7+N6nm9lB4Und0wmml7YDL5rZiWE1z58QtvE1s2PD1xwFNgEHTiIuaRJK/FLPbgIONrOtwCcI2mDj7o8Cf0Wwzd5DBCc5Z8W8xreBYxlfzfPXBNs43gs8FvO8LxMk+M0Ec+Q51xD0S/+pmT0C/AvBX85vAh4MH/9Bgg1MijKzT5rZswQj9IfM7JrwrtuBJwnaIF8N/Hn4e78A/C3ByP0B4PPhMcLHXBM+5+fAf4bH32tm/wX8T+AO4JNJcUnzU1tmkSoJK4MWufuvavDel7j7JRHHf+vuU6odj9SWRvwi1bMLuCtXJlpld+ffyC3gAp6vQSxSYxrxi4i0GI34RURajBK/iEiLUeIXEWkxSvwiIi3m/wNhiKpAyMMVagAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5QUx49xG7J6"
      },
      "source": [
        "## Observations\n",
        "\n",
        "So far, we implemented an ***MLP model*** and a ***Conv1D model*** to handle the \"**Boston House Prices**\" regression problem.\n",
        "\n",
        "MLP model generates Mean Absolute Error:\n",
        "* in Validation is around **\\$2,600** whereas in Testing, it is about **$2900**\n",
        "\n",
        "Conv1D model generates Mean Absolute Error:\n",
        "* in Validation is around **\\$2,400** whereas in Testing, it is about **$2,700**\n",
        "\n",
        "Thus, **Conv1D** model is a **competitive** approach considering **MLP** model in the regression problem at hand. \n",
        "\n",
        "To use a Conv1D model, you need to **reshape** the input as \n",
        "\n",
        "`[batch_size, time_steps, input_dimension]`\n",
        "\n",
        "**I hope this tutorial helps you to use Conv1D layer successfuly!**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06Y79egSDDfj"
      },
      "source": [
        "# Multi 1D Conv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_izo04gGDIKP",
        "outputId": "46bf460d-994e-4620-8162-fa1913ad8afd"
      },
      "source": [
        "def build_multi_conv1D_model():\n",
        "\n",
        "  n_timesteps = train_data_reshaped.shape[1] #13\n",
        "  n_features  = train_data_reshaped.shape[2] #1 \n",
        "  #(name=\"model_conv1D\")\n",
        "  \n",
        "  input = keras.layers.Input(shape=(n_timesteps,n_features))\n",
        "  \n",
        "  # Conv1D + global max pooling\n",
        "  x = keras.layers.Conv1D(32, 1, padding=\"valid\", activation=\"relu\", strides=1)(input)\n",
        "  x = keras.layers.Conv1D(32, 3, padding=\"valid\", activation=\"relu\", strides=1)(x)\n",
        "  x = keras.layers.Conv1D(32, 5, padding=\"valid\", activation=\"relu\", strides=1)(x)\n",
        "  x = keras.layers.GlobalMaxPooling1D()(x)\n",
        "\n",
        "  # We add a vanilla hidden layer:\n",
        "  x = keras.layers.Dense(32, activation=\"relu\")(x)\n",
        "  x = keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "  # We project onto a single unit output layer, and squash it with a sigmoid:\n",
        "  predictions = keras.layers.Dense(n_features, name=\"predictions\")(x)\n",
        "\n",
        "\n",
        "  model= Model(input,predictions)\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mse',optimizer=optimizer,metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "model_conv1D_2 = build_multi_conv1D_model()\n",
        "model_conv1D_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_38\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_26 (InputLayer)        [(None, 13, 1)]           0         \n",
            "_________________________________________________________________\n",
            "conv1d_43 (Conv1D)           (None, 13, 32)            64        \n",
            "_________________________________________________________________\n",
            "conv1d_44 (Conv1D)           (None, 11, 32)            3104      \n",
            "_________________________________________________________________\n",
            "conv1d_45 (Conv1D)           (None, 7, 32)             5152      \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 3, 32)             0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 3, 32)             1056      \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 3, 32)             0         \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 3, 1)              33        \n",
            "=================================================================\n",
            "Total params: 9,409\n",
            "Trainable params: 9,409\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEUa7SsCFWV_",
        "outputId": "c40909f3-09aa-4b1e-9848-11d105707589"
      },
      "source": [
        "# Store training stats\n",
        "history = model_conv1D_2.fit(train_data_reshaped, train_labels, epochs=500,\n",
        "                    validation_split=0.2, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 523.6261 - mae: 20.9406 - val_loss: 496.4939 - val_mae: 20.3442\n",
            "Epoch 2/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 327.1620 - mae: 15.2716 - val_loss: 219.1714 - val_mae: 12.4016\n",
            "Epoch 3/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 167.3079 - mae: 10.5164 - val_loss: 111.5339 - val_mae: 8.2405\n",
            "Epoch 4/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 134.3097 - mae: 8.8749 - val_loss: 111.0637 - val_mae: 8.0802\n",
            "Epoch 5/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 127.4469 - mae: 8.9468 - val_loss: 118.5534 - val_mae: 8.2197\n",
            "Epoch 6/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 112.3261 - mae: 8.2728 - val_loss: 84.9132 - val_mae: 6.7287\n",
            "Epoch 7/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 107.2930 - mae: 8.1011 - val_loss: 100.4646 - val_mae: 7.3448\n",
            "Epoch 8/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 105.6601 - mae: 7.5284 - val_loss: 105.7240 - val_mae: 7.5498\n",
            "Epoch 9/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 107.5689 - mae: 7.6667 - val_loss: 81.8777 - val_mae: 6.4470\n",
            "Epoch 10/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 105.2564 - mae: 7.6367 - val_loss: 79.4745 - val_mae: 6.4411\n",
            "Epoch 11/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 84.3962 - mae: 6.9559 - val_loss: 81.2600 - val_mae: 6.4194\n",
            "Epoch 12/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 98.9375 - mae: 7.2222 - val_loss: 76.5547 - val_mae: 6.2692\n",
            "Epoch 13/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 101.3094 - mae: 7.6673 - val_loss: 80.4259 - val_mae: 6.6386\n",
            "Epoch 14/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 87.0228 - mae: 7.0388 - val_loss: 83.9851 - val_mae: 6.4913\n",
            "Epoch 15/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 92.4584 - mae: 7.2045 - val_loss: 83.3262 - val_mae: 6.4529\n",
            "Epoch 16/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 93.2869 - mae: 7.0119 - val_loss: 98.1332 - val_mae: 7.1217\n",
            "Epoch 17/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 98.2883 - mae: 7.4023 - val_loss: 85.9865 - val_mae: 6.5659\n",
            "Epoch 18/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 92.3382 - mae: 6.9167 - val_loss: 78.2162 - val_mae: 6.1997\n",
            "Epoch 19/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 83.0670 - mae: 6.7036 - val_loss: 72.7844 - val_mae: 5.9138\n",
            "Epoch 20/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 86.5121 - mae: 6.9132 - val_loss: 70.3908 - val_mae: 5.9519\n",
            "Epoch 21/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 91.3064 - mae: 7.1970 - val_loss: 77.0170 - val_mae: 6.1522\n",
            "Epoch 22/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 82.1255 - mae: 6.9045 - val_loss: 73.5569 - val_mae: 6.0041\n",
            "Epoch 23/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 82.8127 - mae: 6.8087 - val_loss: 97.2087 - val_mae: 7.1061\n",
            "Epoch 24/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 90.5480 - mae: 7.1895 - val_loss: 68.4892 - val_mae: 5.7641\n",
            "Epoch 25/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 84.0355 - mae: 6.6912 - val_loss: 81.4710 - val_mae: 6.3761\n",
            "Epoch 26/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 79.9634 - mae: 6.5421 - val_loss: 80.0938 - val_mae: 6.2920\n",
            "Epoch 27/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 82.1676 - mae: 6.6662 - val_loss: 69.3849 - val_mae: 6.2837\n",
            "Epoch 28/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 77.6959 - mae: 6.5931 - val_loss: 96.3022 - val_mae: 7.0545\n",
            "Epoch 29/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 80.2619 - mae: 6.4737 - val_loss: 65.9014 - val_mae: 5.6999\n",
            "Epoch 30/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 75.9388 - mae: 6.5379 - val_loss: 86.8329 - val_mae: 6.6378\n",
            "Epoch 31/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 71.2229 - mae: 6.0797 - val_loss: 69.1565 - val_mae: 5.7980\n",
            "Epoch 32/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 86.7735 - mae: 6.8657 - val_loss: 61.7303 - val_mae: 5.5254\n",
            "Epoch 33/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 77.5038 - mae: 6.5693 - val_loss: 61.3885 - val_mae: 5.7731\n",
            "Epoch 34/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 71.7931 - mae: 6.2454 - val_loss: 64.8193 - val_mae: 5.6229\n",
            "Epoch 35/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 71.5498 - mae: 6.1004 - val_loss: 58.5322 - val_mae: 5.4504\n",
            "Epoch 36/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 61.9807 - mae: 5.9053 - val_loss: 58.6270 - val_mae: 5.4096\n",
            "Epoch 37/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 73.9111 - mae: 6.4959 - val_loss: 62.6534 - val_mae: 5.5357\n",
            "Epoch 38/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 64.5350 - mae: 5.9985 - val_loss: 81.9920 - val_mae: 6.4507\n",
            "Epoch 39/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 65.6994 - mae: 5.6117 - val_loss: 56.9838 - val_mae: 5.2887\n",
            "Epoch 40/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 68.3276 - mae: 6.0715 - val_loss: 75.3464 - val_mae: 6.1464\n",
            "Epoch 41/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 71.8203 - mae: 6.2979 - val_loss: 69.4374 - val_mae: 5.8412\n",
            "Epoch 42/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 66.9639 - mae: 5.9076 - val_loss: 51.8473 - val_mae: 5.2163\n",
            "Epoch 43/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 65.7932 - mae: 5.9517 - val_loss: 51.3532 - val_mae: 5.2105\n",
            "Epoch 44/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 62.1190 - mae: 5.7426 - val_loss: 50.3683 - val_mae: 5.2737\n",
            "Epoch 45/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 60.6995 - mae: 5.6733 - val_loss: 50.7710 - val_mae: 4.9576\n",
            "Epoch 46/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 71.3987 - mae: 6.2536 - val_loss: 68.8505 - val_mae: 5.8742\n",
            "Epoch 47/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 55.9450 - mae: 5.5569 - val_loss: 56.8944 - val_mae: 5.2768\n",
            "Epoch 48/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 67.4777 - mae: 5.8165 - val_loss: 49.1449 - val_mae: 5.2308\n",
            "Epoch 49/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 72.6804 - mae: 6.3202 - val_loss: 50.5567 - val_mae: 5.4787\n",
            "Epoch 50/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 58.4846 - mae: 5.4978 - val_loss: 49.1969 - val_mae: 4.8686\n",
            "Epoch 51/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 62.8274 - mae: 5.5902 - val_loss: 45.3888 - val_mae: 4.8287\n",
            "Epoch 52/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 58.6404 - mae: 5.6362 - val_loss: 51.2867 - val_mae: 5.0413\n",
            "Epoch 53/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 65.6147 - mae: 5.7670 - val_loss: 46.2108 - val_mae: 4.7130\n",
            "Epoch 54/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 48.2989 - mae: 5.2033 - val_loss: 42.6251 - val_mae: 4.7452\n",
            "Epoch 55/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 54.5806 - mae: 5.4305 - val_loss: 44.5338 - val_mae: 5.0643\n",
            "Epoch 56/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 55.5427 - mae: 5.5190 - val_loss: 65.0299 - val_mae: 5.8308\n",
            "Epoch 57/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 57.5604 - mae: 5.6508 - val_loss: 42.3835 - val_mae: 4.5708\n",
            "Epoch 58/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 56.2510 - mae: 5.4138 - val_loss: 43.7841 - val_mae: 4.6257\n",
            "Epoch 59/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 55.7545 - mae: 5.4546 - val_loss: 44.5424 - val_mae: 4.6550\n",
            "Epoch 60/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 55.6654 - mae: 5.5143 - val_loss: 87.6564 - val_mae: 7.1948\n",
            "Epoch 61/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 59.8367 - mae: 5.6540 - val_loss: 38.7327 - val_mae: 4.3163\n",
            "Epoch 62/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 49.3508 - mae: 5.0672 - val_loss: 60.0348 - val_mae: 5.5738\n",
            "Epoch 63/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 54.6431 - mae: 5.3177 - val_loss: 46.3711 - val_mae: 4.7642\n",
            "Epoch 64/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 53.6080 - mae: 5.5120 - val_loss: 77.0858 - val_mae: 6.6888\n",
            "Epoch 65/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 49.3504 - mae: 5.2565 - val_loss: 38.3349 - val_mae: 4.5225\n",
            "Epoch 66/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 48.2832 - mae: 5.1138 - val_loss: 48.7621 - val_mae: 4.9716\n",
            "Epoch 67/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 53.5046 - mae: 5.2364 - val_loss: 56.2939 - val_mae: 5.5095\n",
            "Epoch 68/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 51.8655 - mae: 5.3177 - val_loss: 51.7941 - val_mae: 5.2347\n",
            "Epoch 69/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 42.9736 - mae: 4.7233 - val_loss: 67.1144 - val_mae: 6.2125\n",
            "Epoch 70/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 48.9706 - mae: 5.2087 - val_loss: 35.8499 - val_mae: 4.1091\n",
            "Epoch 71/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 46.6846 - mae: 4.8924 - val_loss: 50.2337 - val_mae: 5.1164\n",
            "Epoch 72/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 47.1276 - mae: 5.0556 - val_loss: 36.9329 - val_mae: 4.5244\n",
            "Epoch 73/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 51.4504 - mae: 5.1781 - val_loss: 46.0379 - val_mae: 5.3789\n",
            "Epoch 74/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 45.6375 - mae: 5.0545 - val_loss: 36.6615 - val_mae: 4.3440\n",
            "Epoch 75/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 48.2148 - mae: 4.9889 - val_loss: 57.3889 - val_mae: 5.6370\n",
            "Epoch 76/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 50.8479 - mae: 5.3966 - val_loss: 84.4523 - val_mae: 7.4017\n",
            "Epoch 77/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 44.6492 - mae: 5.0558 - val_loss: 68.5453 - val_mae: 6.4473\n",
            "Epoch 78/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 45.3842 - mae: 4.9039 - val_loss: 40.5493 - val_mae: 4.4263\n",
            "Epoch 79/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 41.8479 - mae: 4.9364 - val_loss: 37.5077 - val_mae: 4.2259\n",
            "Epoch 80/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 40.8193 - mae: 4.7630 - val_loss: 71.7417 - val_mae: 6.6474\n",
            "Epoch 81/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 48.1111 - mae: 5.0181 - val_loss: 86.9379 - val_mae: 7.5755\n",
            "Epoch 82/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 45.9557 - mae: 5.2309 - val_loss: 32.3251 - val_mae: 3.9208\n",
            "Epoch 83/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 44.0476 - mae: 4.7153 - val_loss: 36.8361 - val_mae: 4.2045\n",
            "Epoch 84/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 42.1325 - mae: 4.7673 - val_loss: 32.6773 - val_mae: 4.1147\n",
            "Epoch 85/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 41.4665 - mae: 4.8497 - val_loss: 33.6829 - val_mae: 3.9540\n",
            "Epoch 86/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 42.0926 - mae: 5.0813 - val_loss: 48.0523 - val_mae: 5.6618\n",
            "Epoch 87/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 49.2726 - mae: 5.2132 - val_loss: 31.0398 - val_mae: 3.8665\n",
            "Epoch 88/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 43.6506 - mae: 4.7433 - val_loss: 41.6251 - val_mae: 4.7556\n",
            "Epoch 89/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 49.8546 - mae: 5.1561 - val_loss: 40.8129 - val_mae: 4.6595\n",
            "Epoch 90/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 36.0600 - mae: 4.4271 - val_loss: 31.4122 - val_mae: 3.8672\n",
            "Epoch 91/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 45.1567 - mae: 5.0928 - val_loss: 48.8861 - val_mae: 5.6876\n",
            "Epoch 92/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 39.4786 - mae: 4.6896 - val_loss: 57.5568 - val_mae: 6.3206\n",
            "Epoch 93/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 41.8398 - mae: 4.6409 - val_loss: 38.0541 - val_mae: 4.3813\n",
            "Epoch 94/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 38.7576 - mae: 4.6498 - val_loss: 96.2459 - val_mae: 8.2847\n",
            "Epoch 95/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 43.8231 - mae: 5.0352 - val_loss: 35.9191 - val_mae: 4.1539\n",
            "Epoch 96/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 45.4002 - mae: 5.0631 - val_loss: 46.2836 - val_mae: 4.9990\n",
            "Epoch 97/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 41.2109 - mae: 4.6181 - val_loss: 62.9168 - val_mae: 6.3054\n",
            "Epoch 98/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 42.6498 - mae: 4.7829 - val_loss: 38.5057 - val_mae: 4.6091\n",
            "Epoch 99/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 40.8246 - mae: 4.9524 - val_loss: 35.9688 - val_mae: 4.1550\n",
            "Epoch 100/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 37.3366 - mae: 4.4741 - val_loss: 32.1295 - val_mae: 4.0442\n",
            "Epoch 101/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33.9576 - mae: 4.4523 - val_loss: 31.0170 - val_mae: 3.9161\n",
            "Epoch 102/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 40.2784 - mae: 4.8355 - val_loss: 34.8591 - val_mae: 4.4460\n",
            "Epoch 103/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 44.7577 - mae: 4.9478 - val_loss: 47.6316 - val_mae: 5.6538\n",
            "Epoch 104/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 46.8464 - mae: 4.9926 - val_loss: 37.5439 - val_mae: 4.4206\n",
            "Epoch 105/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 37.4158 - mae: 4.6359 - val_loss: 32.5022 - val_mae: 4.0394\n",
            "Epoch 106/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 40.8107 - mae: 4.8189 - val_loss: 34.7442 - val_mae: 4.3151\n",
            "Epoch 107/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 40.8890 - mae: 4.7358 - val_loss: 34.2830 - val_mae: 4.1568\n",
            "Epoch 108/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 37.7084 - mae: 4.5840 - val_loss: 61.5201 - val_mae: 6.3410\n",
            "Epoch 109/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 49.6491 - mae: 5.0595 - val_loss: 66.6168 - val_mae: 6.6477\n",
            "Epoch 110/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 45.8111 - mae: 4.9567 - val_loss: 30.2559 - val_mae: 3.7707\n",
            "Epoch 111/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 42.3734 - mae: 4.9870 - val_loss: 37.0561 - val_mae: 4.3542\n",
            "Epoch 112/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 42.9893 - mae: 4.8683 - val_loss: 28.6794 - val_mae: 3.6808\n",
            "Epoch 113/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 38.7009 - mae: 4.6134 - val_loss: 62.3611 - val_mae: 6.2673\n",
            "Epoch 114/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 42.0897 - mae: 4.7633 - val_loss: 30.4535 - val_mae: 3.7327\n",
            "Epoch 115/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 35.9190 - mae: 4.5979 - val_loss: 75.5424 - val_mae: 7.1983\n",
            "Epoch 116/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 41.5904 - mae: 4.8063 - val_loss: 38.2202 - val_mae: 4.5067\n",
            "Epoch 117/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 36.2792 - mae: 4.5949 - val_loss: 51.2803 - val_mae: 5.8477\n",
            "Epoch 118/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 41.0665 - mae: 4.7709 - val_loss: 30.2087 - val_mae: 3.6573\n",
            "Epoch 119/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 37.7893 - mae: 4.5176 - val_loss: 31.9470 - val_mae: 3.8684\n",
            "Epoch 120/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 42.8125 - mae: 4.7194 - val_loss: 28.7712 - val_mae: 3.8008\n",
            "Epoch 121/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 41.8725 - mae: 4.8495 - val_loss: 45.7145 - val_mae: 5.2711\n",
            "Epoch 122/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 42.4312 - mae: 4.9395 - val_loss: 29.3464 - val_mae: 3.8801\n",
            "Epoch 123/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 41.3014 - mae: 4.7469 - val_loss: 43.2693 - val_mae: 5.0658\n",
            "Epoch 124/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 45.9518 - mae: 5.0144 - val_loss: 38.1646 - val_mae: 4.6190\n",
            "Epoch 125/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 39.0726 - mae: 4.7531 - val_loss: 40.7324 - val_mae: 4.8817\n",
            "Epoch 126/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 35.0122 - mae: 4.5274 - val_loss: 43.1811 - val_mae: 4.9840\n",
            "Epoch 127/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 33.6589 - mae: 4.3442 - val_loss: 29.3836 - val_mae: 3.7730\n",
            "Epoch 128/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 38.5362 - mae: 4.7328 - val_loss: 27.3482 - val_mae: 3.5722\n",
            "Epoch 129/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 33.8337 - mae: 4.3944 - val_loss: 31.2489 - val_mae: 4.0541\n",
            "Epoch 130/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 36.9405 - mae: 4.4482 - val_loss: 38.1153 - val_mae: 4.6751\n",
            "Epoch 131/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 36.7307 - mae: 4.5092 - val_loss: 30.6126 - val_mae: 3.9232\n",
            "Epoch 132/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33.4779 - mae: 4.4348 - val_loss: 32.4559 - val_mae: 4.1408\n",
            "Epoch 133/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32.2626 - mae: 4.3096 - val_loss: 29.3530 - val_mae: 3.6478\n",
            "Epoch 134/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 42.0309 - mae: 4.8025 - val_loss: 53.4746 - val_mae: 6.0754\n",
            "Epoch 135/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 44.3111 - mae: 4.9762 - val_loss: 72.0722 - val_mae: 7.2184\n",
            "Epoch 136/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 50.4478 - mae: 5.2017 - val_loss: 33.7969 - val_mae: 4.2278\n",
            "Epoch 137/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 38.1997 - mae: 4.5642 - val_loss: 28.7940 - val_mae: 3.7298\n",
            "Epoch 138/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 31.2001 - mae: 4.3790 - val_loss: 59.2961 - val_mae: 6.2723\n",
            "Epoch 139/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 38.3108 - mae: 4.6209 - val_loss: 41.1706 - val_mae: 4.9159\n",
            "Epoch 140/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 41.9689 - mae: 4.9927 - val_loss: 35.5340 - val_mae: 4.4140\n",
            "Epoch 141/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 40.0397 - mae: 4.6298 - val_loss: 31.7690 - val_mae: 4.2398\n",
            "Epoch 142/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34.3597 - mae: 4.3673 - val_loss: 40.4784 - val_mae: 4.9215\n",
            "Epoch 143/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 37.7914 - mae: 4.6390 - val_loss: 31.3217 - val_mae: 4.2062\n",
            "Epoch 144/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 37.3578 - mae: 4.5617 - val_loss: 30.5501 - val_mae: 4.0231\n",
            "Epoch 145/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 35.5993 - mae: 4.4826 - val_loss: 26.4911 - val_mae: 3.6190\n",
            "Epoch 146/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 37.3205 - mae: 4.5123 - val_loss: 45.1768 - val_mae: 5.3475\n",
            "Epoch 147/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 39.4247 - mae: 4.6945 - val_loss: 28.5311 - val_mae: 3.8112\n",
            "Epoch 148/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 36.0505 - mae: 4.4140 - val_loss: 41.2564 - val_mae: 5.0195\n",
            "Epoch 149/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 40.0347 - mae: 4.6610 - val_loss: 45.7128 - val_mae: 5.4267\n",
            "Epoch 150/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 43.7470 - mae: 4.8010 - val_loss: 28.2511 - val_mae: 3.7526\n",
            "Epoch 151/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 38.6406 - mae: 4.6939 - val_loss: 28.4607 - val_mae: 3.7089\n",
            "Epoch 152/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 42.7802 - mae: 4.8315 - val_loss: 26.8680 - val_mae: 3.6774\n",
            "Epoch 153/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 38.2801 - mae: 4.4768 - val_loss: 26.3195 - val_mae: 3.4985\n",
            "Epoch 154/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 37.4103 - mae: 4.6846 - val_loss: 27.4020 - val_mae: 3.5414\n",
            "Epoch 155/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 35.1450 - mae: 4.6346 - val_loss: 28.3286 - val_mae: 3.7260\n",
            "Epoch 156/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34.0606 - mae: 4.4771 - val_loss: 71.3981 - val_mae: 7.1535\n",
            "Epoch 157/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 39.5101 - mae: 4.7746 - val_loss: 41.3114 - val_mae: 5.0937\n",
            "Epoch 158/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32.2505 - mae: 4.2314 - val_loss: 27.7381 - val_mae: 3.5859\n",
            "Epoch 159/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 34.7217 - mae: 4.4196 - val_loss: 28.0025 - val_mae: 3.7098\n",
            "Epoch 160/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 35.1335 - mae: 4.5265 - val_loss: 27.1774 - val_mae: 3.5711\n",
            "Epoch 161/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 41.8849 - mae: 4.7323 - val_loss: 28.2236 - val_mae: 3.6105\n",
            "Epoch 162/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34.9866 - mae: 4.2159 - val_loss: 48.3506 - val_mae: 5.5814\n",
            "Epoch 163/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 38.9373 - mae: 4.6854 - val_loss: 30.6102 - val_mae: 3.8757\n",
            "Epoch 164/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 44.7249 - mae: 4.8299 - val_loss: 37.0254 - val_mae: 4.5726\n",
            "Epoch 165/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 38.1549 - mae: 4.6607 - val_loss: 31.2956 - val_mae: 4.0189\n",
            "Epoch 166/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 45.2478 - mae: 4.8118 - val_loss: 26.8730 - val_mae: 3.5251\n",
            "Epoch 167/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 37.5351 - mae: 4.7668 - val_loss: 71.9872 - val_mae: 7.2386\n",
            "Epoch 168/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 41.4698 - mae: 4.8108 - val_loss: 34.2117 - val_mae: 4.4051\n",
            "Epoch 169/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 38.8553 - mae: 4.5275 - val_loss: 36.3365 - val_mae: 4.5400\n",
            "Epoch 170/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 36.7951 - mae: 4.3312 - val_loss: 41.7100 - val_mae: 4.9504\n",
            "Epoch 171/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34.9617 - mae: 4.4908 - val_loss: 29.0438 - val_mae: 3.8885\n",
            "Epoch 172/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 37.9897 - mae: 4.6959 - val_loss: 28.9411 - val_mae: 3.8275\n",
            "Epoch 173/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 34.5147 - mae: 4.3367 - val_loss: 47.6672 - val_mae: 5.4378\n",
            "Epoch 174/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 37.5293 - mae: 4.6120 - val_loss: 27.6592 - val_mae: 3.6052\n",
            "Epoch 175/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 32.3747 - mae: 4.3346 - val_loss: 43.4511 - val_mae: 5.1314\n",
            "Epoch 176/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 43.4172 - mae: 4.9169 - val_loss: 32.1795 - val_mae: 4.1226\n",
            "Epoch 177/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 40.6279 - mae: 4.6523 - val_loss: 29.8167 - val_mae: 3.8242\n",
            "Epoch 178/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 39.0111 - mae: 4.6207 - val_loss: 30.1427 - val_mae: 3.9881\n",
            "Epoch 179/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 38.4714 - mae: 4.6813 - val_loss: 28.3887 - val_mae: 3.6040\n",
            "Epoch 180/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 38.3555 - mae: 4.7682 - val_loss: 30.6533 - val_mae: 3.9561\n",
            "Epoch 181/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 29.2852 - mae: 4.2393 - val_loss: 29.7495 - val_mae: 4.0372\n",
            "Epoch 182/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 31.1112 - mae: 4.2390 - val_loss: 27.0360 - val_mae: 3.6335\n",
            "Epoch 183/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 39.6425 - mae: 4.5752 - val_loss: 39.3477 - val_mae: 4.8367\n",
            "Epoch 184/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 38.8428 - mae: 4.6484 - val_loss: 26.3018 - val_mae: 3.5849\n",
            "Epoch 185/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 30.1264 - mae: 4.1422 - val_loss: 26.8380 - val_mae: 3.6437\n",
            "Epoch 186/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 44.9194 - mae: 4.8189 - val_loss: 27.0597 - val_mae: 3.6172\n",
            "Epoch 187/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34.8966 - mae: 4.5820 - val_loss: 46.4819 - val_mae: 5.3947\n",
            "Epoch 188/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 29.8330 - mae: 4.1823 - val_loss: 30.8699 - val_mae: 3.9877\n",
            "Epoch 189/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 27.3538 - mae: 3.9119 - val_loss: 29.1351 - val_mae: 3.8510\n",
            "Epoch 190/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 37.0884 - mae: 4.6329 - val_loss: 42.5774 - val_mae: 5.1329\n",
            "Epoch 191/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 30.7421 - mae: 4.3223 - val_loss: 66.0275 - val_mae: 6.8747\n",
            "Epoch 192/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 36.7793 - mae: 4.6712 - val_loss: 29.3396 - val_mae: 3.8123\n",
            "Epoch 193/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 32.4165 - mae: 4.2920 - val_loss: 26.6477 - val_mae: 3.5887\n",
            "Epoch 194/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 40.7340 - mae: 4.6882 - val_loss: 26.2317 - val_mae: 3.5424\n",
            "Epoch 195/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 35.7779 - mae: 4.4800 - val_loss: 60.6663 - val_mae: 6.5087\n",
            "Epoch 196/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 39.0227 - mae: 4.4656 - val_loss: 44.4034 - val_mae: 5.3177\n",
            "Epoch 197/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 38.9773 - mae: 4.5960 - val_loss: 29.3888 - val_mae: 3.9215\n",
            "Epoch 198/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 35.9033 - mae: 4.4339 - val_loss: 30.9976 - val_mae: 4.0486\n",
            "Epoch 199/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 34.6656 - mae: 4.3614 - val_loss: 40.5411 - val_mae: 5.0544\n",
            "Epoch 200/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 35.1656 - mae: 4.3792 - val_loss: 27.1065 - val_mae: 3.6664\n",
            "Epoch 201/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 30.0134 - mae: 4.0929 - val_loss: 26.8475 - val_mae: 3.5740\n",
            "Epoch 202/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34.3019 - mae: 4.4542 - val_loss: 30.2639 - val_mae: 3.8326\n",
            "Epoch 203/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34.7944 - mae: 4.3785 - val_loss: 27.6871 - val_mae: 3.6354\n",
            "Epoch 204/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33.0971 - mae: 4.2184 - val_loss: 42.5521 - val_mae: 5.1167\n",
            "Epoch 205/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 26.5724 - mae: 4.0443 - val_loss: 45.0278 - val_mae: 5.3807\n",
            "Epoch 206/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 40.1636 - mae: 4.7439 - val_loss: 31.3320 - val_mae: 3.9753\n",
            "Epoch 207/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34.6575 - mae: 4.2792 - val_loss: 31.5684 - val_mae: 4.1619\n",
            "Epoch 208/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 37.0119 - mae: 4.6193 - val_loss: 43.2405 - val_mae: 5.1764\n",
            "Epoch 209/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 29.4581 - mae: 4.2325 - val_loss: 30.9032 - val_mae: 4.0543\n",
            "Epoch 210/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 31.3673 - mae: 4.2287 - val_loss: 35.0746 - val_mae: 4.4799\n",
            "Epoch 211/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 31.2857 - mae: 4.3959 - val_loss: 27.7715 - val_mae: 3.7999\n",
            "Epoch 212/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33.2941 - mae: 4.3568 - val_loss: 33.7207 - val_mae: 4.3883\n",
            "Epoch 213/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 37.8414 - mae: 4.4499 - val_loss: 51.1687 - val_mae: 5.7821\n",
            "Epoch 214/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 42.7213 - mae: 4.8534 - val_loss: 28.4330 - val_mae: 3.6549\n",
            "Epoch 215/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 31.7806 - mae: 4.2227 - val_loss: 32.3187 - val_mae: 4.0990\n",
            "Epoch 216/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33.5195 - mae: 4.5154 - val_loss: 43.4400 - val_mae: 5.0808\n",
            "Epoch 217/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 37.9763 - mae: 4.6348 - val_loss: 29.7627 - val_mae: 3.8101\n",
            "Epoch 218/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 35.7746 - mae: 4.3248 - val_loss: 30.2956 - val_mae: 3.8288\n",
            "Epoch 219/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 29.5923 - mae: 4.0774 - val_loss: 30.0649 - val_mae: 3.8016\n",
            "Epoch 220/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34.0620 - mae: 4.3704 - val_loss: 65.8439 - val_mae: 6.7262\n",
            "Epoch 221/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 41.7368 - mae: 4.7257 - val_loss: 30.1035 - val_mae: 3.6856\n",
            "Epoch 222/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 35.8566 - mae: 4.3861 - val_loss: 32.3475 - val_mae: 4.0619\n",
            "Epoch 223/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 36.7875 - mae: 4.4634 - val_loss: 29.3799 - val_mae: 3.8734\n",
            "Epoch 224/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34.6094 - mae: 4.4856 - val_loss: 27.9081 - val_mae: 3.7534\n",
            "Epoch 225/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 30.4671 - mae: 4.0571 - val_loss: 27.1991 - val_mae: 3.5496\n",
            "Epoch 226/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33.2859 - mae: 4.2039 - val_loss: 46.2526 - val_mae: 5.3015\n",
            "Epoch 227/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 35.9983 - mae: 4.4616 - val_loss: 30.0224 - val_mae: 3.8106\n",
            "Epoch 228/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32.6090 - mae: 4.2525 - val_loss: 54.3396 - val_mae: 6.0125\n",
            "Epoch 229/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 33.2173 - mae: 4.2639 - val_loss: 46.8419 - val_mae: 5.4758\n",
            "Epoch 230/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 31.7638 - mae: 4.2835 - val_loss: 37.9126 - val_mae: 4.7114\n",
            "Epoch 231/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 37.4282 - mae: 4.6029 - val_loss: 30.1535 - val_mae: 3.9377\n",
            "Epoch 232/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 31.4423 - mae: 4.3871 - val_loss: 39.3954 - val_mae: 4.7728\n",
            "Epoch 233/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33.6490 - mae: 4.4322 - val_loss: 48.7853 - val_mae: 5.6397\n",
            "Epoch 234/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32.0162 - mae: 4.2481 - val_loss: 27.8424 - val_mae: 3.5868\n",
            "Epoch 235/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34.4903 - mae: 4.3763 - val_loss: 47.1566 - val_mae: 5.5472\n",
            "Epoch 236/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 37.0065 - mae: 4.2561 - val_loss: 35.0722 - val_mae: 4.3825\n",
            "Epoch 237/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34.5934 - mae: 4.3942 - val_loss: 38.4024 - val_mae: 4.5209\n",
            "Epoch 238/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 36.5669 - mae: 4.6606 - val_loss: 27.1019 - val_mae: 3.6046\n",
            "Epoch 239/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 27.6590 - mae: 3.9572 - val_loss: 60.6128 - val_mae: 6.3908\n",
            "Epoch 240/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 35.0998 - mae: 4.2841 - val_loss: 30.1878 - val_mae: 3.9518\n",
            "Epoch 241/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 29.7638 - mae: 4.1075 - val_loss: 26.9929 - val_mae: 3.5708\n",
            "Epoch 242/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 34.3446 - mae: 4.5437 - val_loss: 34.3912 - val_mae: 4.4192\n",
            "Epoch 243/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33.4277 - mae: 4.4629 - val_loss: 27.4217 - val_mae: 3.4934\n",
            "Epoch 244/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32.7844 - mae: 4.1680 - val_loss: 25.5373 - val_mae: 3.5744\n",
            "Epoch 245/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 36.4805 - mae: 4.4412 - val_loss: 28.4797 - val_mae: 3.9079\n",
            "Epoch 246/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 30.9557 - mae: 4.0664 - val_loss: 29.8234 - val_mae: 3.7051\n",
            "Epoch 247/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 36.0973 - mae: 4.4375 - val_loss: 30.9040 - val_mae: 4.0576\n",
            "Epoch 248/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 32.5853 - mae: 4.1700 - val_loss: 41.0102 - val_mae: 5.0160\n",
            "Epoch 249/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33.2463 - mae: 4.3169 - val_loss: 27.8108 - val_mae: 3.7382\n",
            "Epoch 250/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 30.6622 - mae: 4.0587 - val_loss: 26.0613 - val_mae: 3.5638\n",
            "Epoch 251/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34.6761 - mae: 4.4520 - val_loss: 41.7435 - val_mae: 5.2945\n",
            "Epoch 252/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 35.2421 - mae: 4.4502 - val_loss: 23.4767 - val_mae: 3.3221\n",
            "Epoch 253/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 30.7190 - mae: 4.0337 - val_loss: 29.4583 - val_mae: 4.0048\n",
            "Epoch 254/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 38.6455 - mae: 4.5176 - val_loss: 24.5609 - val_mae: 3.4214\n",
            "Epoch 255/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 40.5383 - mae: 4.6670 - val_loss: 26.0145 - val_mae: 3.5386\n",
            "Epoch 256/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 29.8990 - mae: 4.0867 - val_loss: 52.5371 - val_mae: 5.9580\n",
            "Epoch 257/500\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 34.5827 - mae: 4.2374 - val_loss: 26.6675 - val_mae: 3.6305\n",
            "Epoch 258/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33.8143 - mae: 4.3784 - val_loss: 34.4092 - val_mae: 4.3137\n",
            "Epoch 259/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.0172 - mae: 4.0101 - val_loss: 37.2954 - val_mae: 4.7377\n",
            "Epoch 260/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.7918 - mae: 3.9505 - val_loss: 27.0883 - val_mae: 3.4709\n",
            "Epoch 261/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 36.4581 - mae: 4.4764 - val_loss: 26.3126 - val_mae: 3.5945\n",
            "Epoch 262/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32.1077 - mae: 4.1566 - val_loss: 39.4366 - val_mae: 4.8912\n",
            "Epoch 263/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 30.7066 - mae: 4.0490 - val_loss: 28.9237 - val_mae: 3.7081\n",
            "Epoch 264/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 41.1501 - mae: 4.6580 - val_loss: 32.2775 - val_mae: 4.2216\n",
            "Epoch 265/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 31.5085 - mae: 4.0103 - val_loss: 25.6364 - val_mae: 3.5387\n",
            "Epoch 266/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 31.2032 - mae: 4.1938 - val_loss: 30.8612 - val_mae: 3.9975\n",
            "Epoch 267/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32.9799 - mae: 4.1227 - val_loss: 72.3255 - val_mae: 7.3707\n",
            "Epoch 268/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33.8205 - mae: 4.4886 - val_loss: 26.5862 - val_mae: 3.4557\n",
            "Epoch 269/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 29.7574 - mae: 4.1850 - val_loss: 26.9467 - val_mae: 3.7863\n",
            "Epoch 270/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 29.8995 - mae: 4.1381 - val_loss: 36.9051 - val_mae: 4.5574\n",
            "Epoch 271/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 29.3995 - mae: 3.9289 - val_loss: 29.9063 - val_mae: 3.9929\n",
            "Epoch 272/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 24.0546 - mae: 3.6763 - val_loss: 28.8167 - val_mae: 3.9302\n",
            "Epoch 273/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 31.1802 - mae: 4.0937 - val_loss: 32.0380 - val_mae: 4.2437\n",
            "Epoch 274/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34.1817 - mae: 4.2817 - val_loss: 27.6508 - val_mae: 3.8231\n",
            "Epoch 275/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.2989 - mae: 4.0701 - val_loss: 28.3734 - val_mae: 3.5748\n",
            "Epoch 276/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32.4530 - mae: 4.2179 - val_loss: 25.5516 - val_mae: 3.4858\n",
            "Epoch 277/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33.3537 - mae: 4.3368 - val_loss: 30.1878 - val_mae: 3.7199\n",
            "Epoch 278/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33.4433 - mae: 4.3521 - val_loss: 24.7012 - val_mae: 3.3868\n",
            "Epoch 279/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 29.5931 - mae: 4.1886 - val_loss: 27.0603 - val_mae: 3.6723\n",
            "Epoch 280/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 26.6147 - mae: 3.8628 - val_loss: 26.3028 - val_mae: 3.8043\n",
            "Epoch 281/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 30.6021 - mae: 4.1337 - val_loss: 29.9490 - val_mae: 4.1074\n",
            "Epoch 282/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 29.5142 - mae: 4.0890 - val_loss: 37.4843 - val_mae: 4.8378\n",
            "Epoch 283/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32.3307 - mae: 4.1660 - val_loss: 33.7801 - val_mae: 4.3154\n",
            "Epoch 284/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 35.2164 - mae: 4.3226 - val_loss: 28.6343 - val_mae: 3.5869\n",
            "Epoch 285/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 26.8589 - mae: 3.9430 - val_loss: 32.3920 - val_mae: 4.3031\n",
            "Epoch 286/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33.0675 - mae: 4.3574 - val_loss: 37.4012 - val_mae: 4.8478\n",
            "Epoch 287/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34.5865 - mae: 4.4814 - val_loss: 32.3792 - val_mae: 4.1313\n",
            "Epoch 288/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 29.2084 - mae: 4.0788 - val_loss: 23.9941 - val_mae: 3.4614\n",
            "Epoch 289/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 34.9539 - mae: 4.4595 - val_loss: 50.7112 - val_mae: 5.9259\n",
            "Epoch 290/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 41.0026 - mae: 4.5362 - val_loss: 45.5462 - val_mae: 5.5195\n",
            "Epoch 291/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34.6860 - mae: 4.2871 - val_loss: 24.7061 - val_mae: 3.4952\n",
            "Epoch 292/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.2435 - mae: 3.9702 - val_loss: 28.1813 - val_mae: 3.7962\n",
            "Epoch 293/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 32.9204 - mae: 4.3370 - val_loss: 27.1931 - val_mae: 3.6413\n",
            "Epoch 294/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 33.2145 - mae: 4.0682 - val_loss: 23.6786 - val_mae: 3.4317\n",
            "Epoch 295/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 32.1984 - mae: 4.3379 - val_loss: 36.2486 - val_mae: 4.8442\n",
            "Epoch 296/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 30.3757 - mae: 4.1129 - val_loss: 25.4779 - val_mae: 3.3856\n",
            "Epoch 297/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 31.3634 - mae: 4.2299 - val_loss: 23.4992 - val_mae: 3.4197\n",
            "Epoch 298/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 26.3556 - mae: 3.6450 - val_loss: 29.6152 - val_mae: 3.6905\n",
            "Epoch 299/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.2694 - mae: 3.9644 - val_loss: 31.3570 - val_mae: 4.2764\n",
            "Epoch 300/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 27.5675 - mae: 3.8271 - val_loss: 45.0889 - val_mae: 5.5079\n",
            "Epoch 301/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 38.9868 - mae: 4.6814 - val_loss: 31.6254 - val_mae: 3.9437\n",
            "Epoch 302/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32.4596 - mae: 4.3141 - val_loss: 31.3782 - val_mae: 4.0152\n",
            "Epoch 303/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34.8921 - mae: 4.3382 - val_loss: 29.5004 - val_mae: 3.9140\n",
            "Epoch 304/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 31.8717 - mae: 4.2936 - val_loss: 27.7752 - val_mae: 3.8372\n",
            "Epoch 305/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34.0563 - mae: 4.5044 - val_loss: 24.4259 - val_mae: 3.3581\n",
            "Epoch 306/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 29.6816 - mae: 3.9813 - val_loss: 27.5292 - val_mae: 3.8712\n",
            "Epoch 307/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 27.1872 - mae: 3.8544 - val_loss: 44.9190 - val_mae: 5.4535\n",
            "Epoch 308/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 35.0398 - mae: 4.4153 - val_loss: 34.2659 - val_mae: 4.4488\n",
            "Epoch 309/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 29.0407 - mae: 4.1064 - val_loss: 24.9082 - val_mae: 3.5239\n",
            "Epoch 310/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 28.1834 - mae: 4.0397 - val_loss: 28.8872 - val_mae: 3.9786\n",
            "Epoch 311/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 29.1343 - mae: 3.9787 - val_loss: 33.7442 - val_mae: 4.3355\n",
            "Epoch 312/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 28.6879 - mae: 4.0287 - val_loss: 24.6153 - val_mae: 3.3932\n",
            "Epoch 313/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 24.1433 - mae: 3.6531 - val_loss: 26.5094 - val_mae: 3.6991\n",
            "Epoch 314/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 27.8882 - mae: 3.8354 - val_loss: 33.7842 - val_mae: 4.1837\n",
            "Epoch 315/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 29.5741 - mae: 4.0666 - val_loss: 46.4090 - val_mae: 5.6471\n",
            "Epoch 316/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 33.1391 - mae: 4.3628 - val_loss: 23.6299 - val_mae: 3.3438\n",
            "Epoch 317/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 41.3492 - mae: 4.5990 - val_loss: 33.6324 - val_mae: 4.4430\n",
            "Epoch 318/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 29.4681 - mae: 3.9255 - val_loss: 25.3971 - val_mae: 3.5661\n",
            "Epoch 319/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 30.8257 - mae: 4.0446 - val_loss: 33.9077 - val_mae: 4.5179\n",
            "Epoch 320/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 31.6707 - mae: 4.2725 - val_loss: 24.4524 - val_mae: 3.3442\n",
            "Epoch 321/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 32.6772 - mae: 4.3354 - val_loss: 24.6189 - val_mae: 3.3422\n",
            "Epoch 322/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 29.4561 - mae: 4.1763 - val_loss: 27.6489 - val_mae: 3.8451\n",
            "Epoch 323/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 31.9318 - mae: 4.3076 - val_loss: 28.2637 - val_mae: 3.8856\n",
            "Epoch 324/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 33.0007 - mae: 4.3075 - val_loss: 38.0301 - val_mae: 4.8702\n",
            "Epoch 325/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 26.3971 - mae: 3.9825 - val_loss: 24.4961 - val_mae: 3.3553\n",
            "Epoch 326/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 32.2301 - mae: 4.3175 - val_loss: 23.9131 - val_mae: 3.4095\n",
            "Epoch 327/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 36.4925 - mae: 4.3854 - val_loss: 32.3831 - val_mae: 4.3678\n",
            "Epoch 328/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 27.6566 - mae: 3.8467 - val_loss: 34.5239 - val_mae: 4.6550\n",
            "Epoch 329/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.2175 - mae: 4.1512 - val_loss: 52.2652 - val_mae: 6.0848\n",
            "Epoch 330/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 31.3098 - mae: 4.2427 - val_loss: 25.6165 - val_mae: 3.5466\n",
            "Epoch 331/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 22.2490 - mae: 3.5197 - val_loss: 28.1675 - val_mae: 3.8191\n",
            "Epoch 332/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 31.8114 - mae: 4.1913 - val_loss: 27.8449 - val_mae: 3.8996\n",
            "Epoch 333/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 31.8423 - mae: 4.1743 - val_loss: 25.1237 - val_mae: 3.5513\n",
            "Epoch 334/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 35.9919 - mae: 4.2887 - val_loss: 36.7462 - val_mae: 4.8910\n",
            "Epoch 335/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 30.9642 - mae: 4.1658 - val_loss: 29.9431 - val_mae: 3.9062\n",
            "Epoch 336/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 29.6582 - mae: 4.1451 - val_loss: 27.1387 - val_mae: 3.6347\n",
            "Epoch 337/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 26.4203 - mae: 3.9232 - val_loss: 51.0235 - val_mae: 5.9991\n",
            "Epoch 338/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 37.1146 - mae: 4.3368 - val_loss: 26.7970 - val_mae: 3.6467\n",
            "Epoch 339/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 24.3233 - mae: 3.7076 - val_loss: 25.5959 - val_mae: 3.6661\n",
            "Epoch 340/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 26.8485 - mae: 3.8973 - val_loss: 32.0883 - val_mae: 3.9910\n",
            "Epoch 341/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 33.2969 - mae: 4.4523 - val_loss: 27.6784 - val_mae: 3.6001\n",
            "Epoch 342/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 29.1605 - mae: 4.0108 - val_loss: 29.8593 - val_mae: 3.8454\n",
            "Epoch 343/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 29.5153 - mae: 4.0192 - val_loss: 24.0505 - val_mae: 3.5161\n",
            "Epoch 344/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 29.7713 - mae: 4.1278 - val_loss: 48.8350 - val_mae: 5.8369\n",
            "Epoch 345/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 28.9022 - mae: 4.0682 - val_loss: 28.5675 - val_mae: 3.7750\n",
            "Epoch 346/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 31.4055 - mae: 4.0800 - val_loss: 23.5617 - val_mae: 3.4442\n",
            "Epoch 347/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 26.5839 - mae: 3.8411 - val_loss: 24.2312 - val_mae: 3.4224\n",
            "Epoch 348/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 34.7477 - mae: 4.2191 - val_loss: 32.6127 - val_mae: 4.3481\n",
            "Epoch 349/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 28.5375 - mae: 3.9145 - val_loss: 46.5909 - val_mae: 5.6486\n",
            "Epoch 350/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 27.9653 - mae: 3.9697 - val_loss: 26.6914 - val_mae: 3.3604\n",
            "Epoch 351/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 29.8233 - mae: 4.1463 - val_loss: 44.4531 - val_mae: 5.6024\n",
            "Epoch 352/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 29.8776 - mae: 4.0756 - val_loss: 23.4458 - val_mae: 3.2390\n",
            "Epoch 353/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 31.0050 - mae: 4.0342 - val_loss: 30.0278 - val_mae: 4.0679\n",
            "Epoch 354/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 25.8747 - mae: 4.0420 - val_loss: 31.4204 - val_mae: 3.9684\n",
            "Epoch 355/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.5921 - mae: 4.0984 - val_loss: 25.2516 - val_mae: 3.5599\n",
            "Epoch 356/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34.3892 - mae: 4.4049 - val_loss: 28.1053 - val_mae: 3.9593\n",
            "Epoch 357/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 24.8969 - mae: 3.7292 - val_loss: 26.0302 - val_mae: 3.5366\n",
            "Epoch 358/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.1168 - mae: 3.8758 - val_loss: 26.4319 - val_mae: 3.7187\n",
            "Epoch 359/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 26.3214 - mae: 3.7651 - val_loss: 32.0508 - val_mae: 4.2478\n",
            "Epoch 360/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33.2734 - mae: 4.2735 - val_loss: 25.2513 - val_mae: 3.6378\n",
            "Epoch 361/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 33.9540 - mae: 4.2517 - val_loss: 31.2248 - val_mae: 4.0748\n",
            "Epoch 362/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 30.0185 - mae: 4.0150 - val_loss: 23.5580 - val_mae: 3.4786\n",
            "Epoch 363/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 30.5759 - mae: 4.2568 - val_loss: 25.6019 - val_mae: 3.5180\n",
            "Epoch 364/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 41.5447 - mae: 4.5293 - val_loss: 35.3744 - val_mae: 4.3802\n",
            "Epoch 365/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 27.6906 - mae: 3.9332 - val_loss: 28.0376 - val_mae: 3.9971\n",
            "Epoch 366/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 33.7346 - mae: 4.3032 - val_loss: 23.4128 - val_mae: 3.3405\n",
            "Epoch 367/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 23.9567 - mae: 3.6828 - val_loss: 24.8953 - val_mae: 3.3846\n",
            "Epoch 368/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 27.9748 - mae: 4.0587 - val_loss: 33.3972 - val_mae: 4.4781\n",
            "Epoch 369/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.9717 - mae: 3.8575 - val_loss: 25.9212 - val_mae: 3.7031\n",
            "Epoch 370/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 28.0197 - mae: 3.8245 - val_loss: 32.9850 - val_mae: 4.4226\n",
            "Epoch 371/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 29.4015 - mae: 4.0268 - val_loss: 55.8718 - val_mae: 6.2963\n",
            "Epoch 372/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33.5203 - mae: 4.3390 - val_loss: 33.1298 - val_mae: 4.3864\n",
            "Epoch 373/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 29.6794 - mae: 4.1223 - val_loss: 37.0049 - val_mae: 4.4256\n",
            "Epoch 374/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.5576 - mae: 3.8528 - val_loss: 27.8442 - val_mae: 3.5819\n",
            "Epoch 375/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.2567 - mae: 3.7432 - val_loss: 38.1905 - val_mae: 4.8013\n",
            "Epoch 376/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 30.1688 - mae: 4.2578 - val_loss: 24.8795 - val_mae: 3.3310\n",
            "Epoch 377/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 29.9612 - mae: 3.9815 - val_loss: 26.3953 - val_mae: 3.6222\n",
            "Epoch 378/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 24.5956 - mae: 3.7896 - val_loss: 28.2570 - val_mae: 3.9696\n",
            "Epoch 379/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 23.7496 - mae: 3.7861 - val_loss: 25.2504 - val_mae: 3.5954\n",
            "Epoch 380/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33.1392 - mae: 4.1723 - val_loss: 26.8342 - val_mae: 3.4704\n",
            "Epoch 381/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.0070 - mae: 3.8429 - val_loss: 27.0791 - val_mae: 3.6702\n",
            "Epoch 382/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 23.4278 - mae: 3.6013 - val_loss: 31.7641 - val_mae: 4.2574\n",
            "Epoch 383/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 27.6456 - mae: 3.9127 - val_loss: 25.8150 - val_mae: 3.5950\n",
            "Epoch 384/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 26.5924 - mae: 3.8758 - val_loss: 36.5700 - val_mae: 4.6471\n",
            "Epoch 385/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 26.2407 - mae: 3.8317 - val_loss: 23.7719 - val_mae: 3.3717\n",
            "Epoch 386/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 26.7007 - mae: 3.9373 - val_loss: 27.9032 - val_mae: 3.7743\n",
            "Epoch 387/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.4434 - mae: 3.8648 - val_loss: 28.1654 - val_mae: 3.8655\n",
            "Epoch 388/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 23.0808 - mae: 3.7104 - val_loss: 28.1922 - val_mae: 3.8531\n",
            "Epoch 389/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 24.9471 - mae: 4.0315 - val_loss: 24.5255 - val_mae: 3.4148\n",
            "Epoch 390/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 29.8134 - mae: 4.1957 - val_loss: 26.5587 - val_mae: 3.6540\n",
            "Epoch 391/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33.1458 - mae: 4.2280 - val_loss: 24.9180 - val_mae: 3.4452\n",
            "Epoch 392/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.9438 - mae: 4.0122 - val_loss: 28.8363 - val_mae: 3.7678\n",
            "Epoch 393/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 22.6103 - mae: 3.6975 - val_loss: 51.9048 - val_mae: 5.5579\n",
            "Epoch 394/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 30.9408 - mae: 4.2491 - val_loss: 32.5730 - val_mae: 4.0041\n",
            "Epoch 395/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 21.5400 - mae: 3.4538 - val_loss: 41.2527 - val_mae: 5.1862\n",
            "Epoch 396/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 29.8033 - mae: 4.2285 - val_loss: 23.3878 - val_mae: 3.2975\n",
            "Epoch 397/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 36.0592 - mae: 4.3053 - val_loss: 23.7079 - val_mae: 3.3838\n",
            "Epoch 398/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.3252 - mae: 3.9121 - val_loss: 24.7276 - val_mae: 3.4674\n",
            "Epoch 399/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 27.9445 - mae: 4.0509 - val_loss: 26.7190 - val_mae: 3.5742\n",
            "Epoch 400/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 26.8609 - mae: 3.8959 - val_loss: 26.3162 - val_mae: 3.5026\n",
            "Epoch 401/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32.3528 - mae: 4.0698 - val_loss: 27.3724 - val_mae: 3.5601\n",
            "Epoch 402/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 26.2084 - mae: 3.8979 - val_loss: 25.1610 - val_mae: 3.3649\n",
            "Epoch 403/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.1250 - mae: 3.9699 - val_loss: 23.6848 - val_mae: 3.2695\n",
            "Epoch 404/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.3895 - mae: 3.8888 - val_loss: 27.4071 - val_mae: 3.5793\n",
            "Epoch 405/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.7873 - mae: 3.8726 - val_loss: 27.8108 - val_mae: 3.6303\n",
            "Epoch 406/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 27.7436 - mae: 3.7917 - val_loss: 26.2751 - val_mae: 3.5240\n",
            "Epoch 407/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 31.3905 - mae: 4.2375 - val_loss: 27.0306 - val_mae: 3.6156\n",
            "Epoch 408/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 27.0837 - mae: 3.8587 - val_loss: 26.4600 - val_mae: 3.7151\n",
            "Epoch 409/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 29.5661 - mae: 3.9575 - val_loss: 24.7363 - val_mae: 3.4209\n",
            "Epoch 410/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32.1863 - mae: 4.0746 - val_loss: 28.2898 - val_mae: 3.6817\n",
            "Epoch 411/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 28.9655 - mae: 4.0655 - val_loss: 24.2737 - val_mae: 3.3637\n",
            "Epoch 412/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.1351 - mae: 3.7575 - val_loss: 22.3547 - val_mae: 3.1997\n",
            "Epoch 413/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 30.6729 - mae: 4.0890 - val_loss: 20.5656 - val_mae: 3.2316\n",
            "Epoch 414/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 27.1111 - mae: 3.8360 - val_loss: 22.4762 - val_mae: 3.4095\n",
            "Epoch 415/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.6806 - mae: 3.6571 - val_loss: 28.2327 - val_mae: 3.8832\n",
            "Epoch 416/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 27.7353 - mae: 4.0686 - val_loss: 24.6535 - val_mae: 3.5506\n",
            "Epoch 417/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 29.8411 - mae: 3.9187 - val_loss: 29.3582 - val_mae: 4.0992\n",
            "Epoch 418/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 27.0047 - mae: 3.9042 - val_loss: 23.7152 - val_mae: 3.2725\n",
            "Epoch 419/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 26.1472 - mae: 3.6405 - val_loss: 28.8405 - val_mae: 3.7267\n",
            "Epoch 420/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 24.1441 - mae: 3.7892 - val_loss: 35.5649 - val_mae: 4.2908\n",
            "Epoch 421/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.5709 - mae: 4.0529 - val_loss: 28.6802 - val_mae: 3.7984\n",
            "Epoch 422/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 26.1165 - mae: 3.8864 - val_loss: 26.7360 - val_mae: 3.6434\n",
            "Epoch 423/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.2722 - mae: 3.9880 - val_loss: 25.7904 - val_mae: 3.5904\n",
            "Epoch 424/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 23.9221 - mae: 3.7701 - val_loss: 24.4452 - val_mae: 3.4200\n",
            "Epoch 425/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 29.6292 - mae: 4.0182 - val_loss: 25.4863 - val_mae: 3.5778\n",
            "Epoch 426/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32.3445 - mae: 4.1046 - val_loss: 25.9118 - val_mae: 3.6091\n",
            "Epoch 427/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.8910 - mae: 4.0027 - val_loss: 25.1352 - val_mae: 3.4377\n",
            "Epoch 428/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 21.7325 - mae: 3.5295 - val_loss: 30.8301 - val_mae: 4.0417\n",
            "Epoch 429/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 29.4461 - mae: 4.0268 - val_loss: 37.3309 - val_mae: 4.8512\n",
            "Epoch 430/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 32.0502 - mae: 4.1756 - val_loss: 25.4491 - val_mae: 3.3607\n",
            "Epoch 431/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.4064 - mae: 3.9283 - val_loss: 28.8036 - val_mae: 3.8117\n",
            "Epoch 432/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.4019 - mae: 3.8800 - val_loss: 29.7631 - val_mae: 3.9265\n",
            "Epoch 433/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 29.3450 - mae: 4.0929 - val_loss: 25.8450 - val_mae: 3.4551\n",
            "Epoch 434/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 26.6131 - mae: 3.8382 - val_loss: 32.1922 - val_mae: 4.4288\n",
            "Epoch 435/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 27.4739 - mae: 3.9483 - val_loss: 30.9153 - val_mae: 4.1700\n",
            "Epoch 436/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 27.3230 - mae: 3.9571 - val_loss: 35.7908 - val_mae: 4.3672\n",
            "Epoch 437/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 26.8154 - mae: 4.0599 - val_loss: 22.7725 - val_mae: 3.2726\n",
            "Epoch 438/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 29.2960 - mae: 4.0924 - val_loss: 25.0305 - val_mae: 3.6837\n",
            "Epoch 439/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 24.4745 - mae: 3.7079 - val_loss: 39.1367 - val_mae: 5.1779\n",
            "Epoch 440/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32.5670 - mae: 4.1803 - val_loss: 33.3751 - val_mae: 4.3012\n",
            "Epoch 441/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 32.2691 - mae: 4.1859 - val_loss: 26.1316 - val_mae: 3.5620\n",
            "Epoch 442/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.3343 - mae: 3.7965 - val_loss: 26.0960 - val_mae: 3.7652\n",
            "Epoch 443/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 27.4207 - mae: 3.8120 - val_loss: 23.9941 - val_mae: 3.5403\n",
            "Epoch 444/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 30.6807 - mae: 4.0073 - val_loss: 22.7936 - val_mae: 3.3396\n",
            "Epoch 445/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 30.6881 - mae: 4.0853 - val_loss: 27.7089 - val_mae: 3.9007\n",
            "Epoch 446/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 29.9368 - mae: 4.1391 - val_loss: 21.3386 - val_mae: 3.2324\n",
            "Epoch 447/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 23.7840 - mae: 3.6836 - val_loss: 24.3660 - val_mae: 3.6133\n",
            "Epoch 448/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 24.0574 - mae: 3.6851 - val_loss: 22.8621 - val_mae: 3.3611\n",
            "Epoch 449/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 25.6084 - mae: 3.6689 - val_loss: 25.9318 - val_mae: 3.7231\n",
            "Epoch 450/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 33.1779 - mae: 4.2440 - val_loss: 27.2121 - val_mae: 3.8919\n",
            "Epoch 451/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 30.2608 - mae: 3.8996 - val_loss: 34.4827 - val_mae: 4.3800\n",
            "Epoch 452/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 31.4280 - mae: 3.9705 - val_loss: 24.9163 - val_mae: 3.3668\n",
            "Epoch 453/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 25.1234 - mae: 3.8261 - val_loss: 23.7800 - val_mae: 3.2581\n",
            "Epoch 454/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 27.7252 - mae: 3.9916 - val_loss: 39.9650 - val_mae: 5.1743\n",
            "Epoch 455/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 28.2821 - mae: 4.0303 - val_loss: 26.1379 - val_mae: 3.4913\n",
            "Epoch 456/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 26.8536 - mae: 3.9438 - val_loss: 26.1782 - val_mae: 3.5228\n",
            "Epoch 457/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 26.0967 - mae: 3.8191 - val_loss: 25.8613 - val_mae: 3.6958\n",
            "Epoch 458/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.2273 - mae: 3.9912 - val_loss: 28.0631 - val_mae: 3.5133\n",
            "Epoch 459/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 27.4858 - mae: 3.9732 - val_loss: 25.0470 - val_mae: 3.3781\n",
            "Epoch 460/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 27.9935 - mae: 3.8358 - val_loss: 26.2436 - val_mae: 3.3409\n",
            "Epoch 461/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 27.4674 - mae: 3.8050 - val_loss: 30.0639 - val_mae: 3.6881\n",
            "Epoch 462/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 29.9398 - mae: 4.0836 - val_loss: 33.7778 - val_mae: 4.6557\n",
            "Epoch 463/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 26.8745 - mae: 3.7038 - val_loss: 25.4381 - val_mae: 3.6107\n",
            "Epoch 464/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 23.9701 - mae: 3.7010 - val_loss: 22.5188 - val_mae: 3.3895\n",
            "Epoch 465/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.1997 - mae: 3.8396 - val_loss: 23.0482 - val_mae: 3.3516\n",
            "Epoch 466/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.7769 - mae: 3.8459 - val_loss: 27.2224 - val_mae: 3.8280\n",
            "Epoch 467/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 23.7331 - mae: 3.5888 - val_loss: 27.0813 - val_mae: 3.7712\n",
            "Epoch 468/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 20.6013 - mae: 3.4353 - val_loss: 45.3998 - val_mae: 5.6778\n",
            "Epoch 469/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 27.5263 - mae: 3.9010 - val_loss: 25.7898 - val_mae: 3.6958\n",
            "Epoch 470/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.6472 - mae: 4.0750 - val_loss: 23.2934 - val_mae: 3.5112\n",
            "Epoch 471/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 27.7733 - mae: 4.0452 - val_loss: 22.5371 - val_mae: 3.2837\n",
            "Epoch 472/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.2682 - mae: 3.7801 - val_loss: 22.1823 - val_mae: 3.2407\n",
            "Epoch 473/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 27.5018 - mae: 3.8916 - val_loss: 24.7848 - val_mae: 3.6501\n",
            "Epoch 474/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 23.4411 - mae: 3.6715 - val_loss: 25.5761 - val_mae: 3.4866\n",
            "Epoch 475/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.6801 - mae: 3.9714 - val_loss: 30.0030 - val_mae: 4.1866\n",
            "Epoch 476/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 24.4040 - mae: 3.8416 - val_loss: 23.1004 - val_mae: 3.2930\n",
            "Epoch 477/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 28.8253 - mae: 3.8419 - val_loss: 34.2268 - val_mae: 4.6084\n",
            "Epoch 478/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 24.6787 - mae: 3.7788 - val_loss: 20.9697 - val_mae: 3.2509\n",
            "Epoch 479/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.9130 - mae: 3.8286 - val_loss: 22.3348 - val_mae: 3.2964\n",
            "Epoch 480/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.9325 - mae: 4.0208 - val_loss: 29.1731 - val_mae: 4.0590\n",
            "Epoch 481/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 34.4054 - mae: 4.2860 - val_loss: 32.2866 - val_mae: 4.4550\n",
            "Epoch 482/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 24.4563 - mae: 3.7537 - val_loss: 22.5463 - val_mae: 3.2495\n",
            "Epoch 483/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 27.3364 - mae: 3.7470 - val_loss: 29.5635 - val_mae: 4.0492\n",
            "Epoch 484/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 25.1119 - mae: 3.8799 - val_loss: 31.3539 - val_mae: 4.4103\n",
            "Epoch 485/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.4478 - mae: 3.9103 - val_loss: 22.5317 - val_mae: 3.3126\n",
            "Epoch 486/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 26.6133 - mae: 3.7129 - val_loss: 21.8070 - val_mae: 3.2312\n",
            "Epoch 487/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.4385 - mae: 3.8965 - val_loss: 24.2567 - val_mae: 3.6684\n",
            "Epoch 488/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.0688 - mae: 3.9985 - val_loss: 22.0614 - val_mae: 3.2316\n",
            "Epoch 489/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.4799 - mae: 3.7248 - val_loss: 23.1247 - val_mae: 3.3049\n",
            "Epoch 490/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 24.5136 - mae: 3.6110 - val_loss: 29.4827 - val_mae: 4.0021\n",
            "Epoch 491/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 31.8644 - mae: 4.2679 - val_loss: 23.9263 - val_mae: 3.5631\n",
            "Epoch 492/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 28.8107 - mae: 3.8907 - val_loss: 24.8088 - val_mae: 3.6491\n",
            "Epoch 493/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 33.8756 - mae: 4.1229 - val_loss: 24.5710 - val_mae: 3.5839\n",
            "Epoch 494/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 26.3681 - mae: 3.8645 - val_loss: 28.0025 - val_mae: 3.9654\n",
            "Epoch 495/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.0664 - mae: 3.5823 - val_loss: 24.5703 - val_mae: 3.3962\n",
            "Epoch 496/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 25.4136 - mae: 3.8295 - val_loss: 23.6462 - val_mae: 3.4102\n",
            "Epoch 497/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 25.8742 - mae: 3.6802 - val_loss: 24.2099 - val_mae: 3.4703\n",
            "Epoch 498/500\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 26.8939 - mae: 3.8647 - val_loss: 31.1397 - val_mae: 4.2996\n",
            "Epoch 499/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 25.5954 - mae: 3.7680 - val_loss: 24.3670 - val_mae: 3.5709\n",
            "Epoch 500/500\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 29.0467 - mae: 4.0456 - val_loss: 23.9919 - val_mae: 3.4420\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud_tq1A0Ffvl",
        "outputId": "852ffee7-43f5-4f20-e0f8-f6ebb31ee0dd"
      },
      "source": [
        "[loss, mae] = model_conv1D_2.evaluate(test_data_reshaped, test_labels, verbose=0)\n",
        "print(\"Testing set Mean Abs Error: ${:7.2f}\".format(mae * 1000))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing set Mean Abs Error: $3973.17\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}